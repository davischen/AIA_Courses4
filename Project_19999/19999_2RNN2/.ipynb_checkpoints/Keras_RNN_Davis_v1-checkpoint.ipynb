{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential, load_model,Model\n",
    "from keras.layers.core import Dense, Dropout, Activation,Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM,GRU\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding,GRU,Conv1D, MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from keras.utils import np_utils\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import adam\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# import urllib.request\n",
    "import os\n",
    "import tarfile\n",
    "np.random.seed(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(\"../\")\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from data_utils import cut_to_word,covert_sequences,get_word2vec_embeddings\n",
    "#from data_utils import get_average_word2vec,produce_cbowfile,JiebaSegmentor,data_reduction,seperatedata\n",
    "from data_utils import *\n",
    "from data_utils import JiebaSegmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /project/at081-group3/Project_19999/19999_2RNN/jieba/dict_taiwan.txt ...\n",
      "Loading model from cache /tmp/jieba.u5f4d4d2a4ebf6cacbf248ccc4ee696aa.cache\n",
      "Loading model cost 0.516 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jieba/userdict.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jieba/dict_system.txt\n",
      "<data_utils.JiebaSegmentor object at 0x7f3fec63f518>\n"
     ]
    }
   ],
   "source": [
    "jieba_dict_path1 = \"jieba/dict_taiwan.txt\"\n",
    "jieba_dict_path2 = \"jieba/userdict.txt\"\n",
    "jieba_dict_path3 = \"jieba/dict.txt.big\"\n",
    "jieba_dict_path4 = \"jieba/dict.txt.small\"\n",
    "jieba_dict_path5 = \"jieba/dict_system.txt\"\n",
    "jieba_stopwords_path = \"jieba/stopwords.txt\"\n",
    "\n",
    "js = JiebaSegmentor(dict_path=jieba_dict_path1,\n",
    "                    userdict=[jieba_dict_path2,jieba_dict_path5],\n",
    "                    stopwords=True,\n",
    "                    stopwords_path=jieba_stopwords_path)\n",
    "\n",
    "print(js)\n",
    "# js = JiebaSegmentor(jieba_dict_path1, [jieba_dict_path2, jieba_dict_path3, jieba_dict_path4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\n"
     ]
    }
   ],
   "source": [
    "test_cut_raw_0 = js.lcut('BPM系統有問題', cut_type='df')\n",
    "# test_cut_raw_0\n",
    "for x in test_cut_raw_0:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BPM系統</td>\n",
       "      <td>ns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>無法</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>使用</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word tag\n",
       "0  BPM系統  ns\n",
       "1     無法   n\n",
       "2          x\n",
       "3     使用   n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cut_raw_0 = js.pseg_lcut('BPM系統有問題，無法 使用')\n",
    "test_cut_raw_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R&amp;D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>系統</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>無法使用</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word\n",
       "0   R&D\n",
       "1    系統\n",
       "2  無法使用"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cut_raw_0 = js.lcut('R&D系統有問題，無法使用')\n",
    "test_cut_raw_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先讀取所有文章建立字典，限制字典的數量為nb_words=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/19999_question_category_a_v11_test.csv')#usecols=['description','category_a', 'category_a_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>category_a</th>\n",
       "      <th>category_b</th>\n",
       "      <th>category_c</th>\n",
       "      <th>category_d</th>\n",
       "      <th>category</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>category_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>無法會員登入,顯示訊息:無效的帳號或使用者不存在。帳號:96122401</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>資訊系統</td>\n",
       "      <td>無法會員登入 顯示訊息 無效的帳號或不存在 帳號</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>因今天有事請假，要補登先前的加班，但開啟camp後，出勤表單顯示的內容看起來像測試的，沒有最...</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>資訊系統</td>\n",
       "      <td>因有事請假 要補登先前的加班 但開啟camp後 出勤表單顯示的內容像測試的 沒有的時間也沒辦...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>手機簽核BPM有問題,都顯示亂碼  #18227</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>資訊系統</td>\n",
       "      <td>簽核BPM有問題 都顯示亂碼</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>無法在手機上面使用CAMP進行表單簽核動作。分機：17132</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>資訊系統</td>\n",
       "      <td>無法在上面使用CAMP進行表單簽核動作</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>出差同仁無法登入camp, 委請同事詢問</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>資訊系統</td>\n",
       "      <td>出差同仁無法登入camp  委請同事詢問</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>請問一下，為什麼我進入CAMP，在會員中心點選\"應用程式\"卻找不到\"研發服務雲\"可點選?  ...</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>資訊系統</td>\n",
       "      <td>請問一下 我進入CAMP 在會員中心點選 應用程式 卻找不到 研發服務雲 可點選   該解決</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>用手機CAMP要簽核電腦外帶攜出申請單，出現應用程式發生錯誤 #15189</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>資訊系統</td>\n",
       "      <td>用CAMP要簽核電腦外帶攜出申請單 出現應用程式發生錯誤</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>研發服務雲 &gt; 偕同開發 &gt; 新增專案 : 無法新增 J51 or J51D 專案 for ...</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>資訊系統</td>\n",
       "      <td>研發服務雲   偕同開發   新增專案   無法新增 J51 or J51D 專案 for ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>進入 CAMP 「研發服務雲」的icon 沒有進一步的資訊 , 畫面空白,沒有發包選單</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>資訊系統</td>\n",
       "      <td>進入 CAMP 「研發服務雲」的icon 沒有進一步的資訊   畫面空白 沒有發包選單</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>在CAMP平台點選\"應用程式\"找不到\"研發服務雲\"可以點選，請問該如何解決?</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>資訊系統</td>\n",
       "      <td>在CAMP平臺點選 應用程式 找不到 研發服務雲 可以點選</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description category_a category_b  \\\n",
       "0               無法會員登入,顯示訊息:無效的帳號或使用者不存在。帳號:96122401       CAMP       CAMP   \n",
       "1  因今天有事請假，要補登先前的加班，但開啟camp後，出勤表單顯示的內容看起來像測試的，沒有最...       CAMP       CAMP   \n",
       "2                           手機簽核BPM有問題,都顯示亂碼  #18227       CAMP       CAMP   \n",
       "3                     無法在手機上面使用CAMP進行表單簽核動作。分機：17132       CAMP       CAMP   \n",
       "4                               出差同仁無法登入camp, 委請同事詢問       CAMP       CAMP   \n",
       "5  請問一下，為什麼我進入CAMP，在會員中心點選\"應用程式\"卻找不到\"研發服務雲\"可點選?  ...       CAMP       CAMP   \n",
       "6              用手機CAMP要簽核電腦外帶攜出申請單，出現應用程式發生錯誤 #15189       CAMP       CAMP   \n",
       "7  研發服務雲 > 偕同開發 > 新增專案 : 無法新增 J51 or J51D 專案 for ...       CAMP       CAMP   \n",
       "8        進入 CAMP 「研發服務雲」的icon 沒有進一步的資訊 , 畫面空白,沒有發包選單       CAMP       CAMP   \n",
       "9             在CAMP平台點選\"應用程式\"找不到\"研發服務雲\"可以點選，請問該如何解決?       CAMP       CAMP   \n",
       "\n",
       "  category_c category_d category  \\\n",
       "0       CAMP       CAMP     資訊系統   \n",
       "1       CAMP       CAMP     資訊系統   \n",
       "2       CAMP       CAMP     資訊系統   \n",
       "3       CAMP       CAMP     資訊系統   \n",
       "4       CAMP       CAMP     資訊系統   \n",
       "5       CAMP       CAMP     資訊系統   \n",
       "6       CAMP       CAMP     資訊系統   \n",
       "7       CAMP       CAMP     資訊系統   \n",
       "8       CAMP       CAMP     資訊系統   \n",
       "9       CAMP       CAMP     資訊系統   \n",
       "\n",
       "                                   description_clean  category_target  \n",
       "0                           無法會員登入 顯示訊息 無效的帳號或不存在 帳號                4  \n",
       "1  因有事請假 要補登先前的加班 但開啟camp後 出勤表單顯示的內容像測試的 沒有的時間也沒辦...                4  \n",
       "2                                     簽核BPM有問題 都顯示亂碼                4  \n",
       "3                                無法在上面使用CAMP進行表單簽核動作                4  \n",
       "4                               出差同仁無法登入camp  委請同事詢問                4  \n",
       "5     請問一下 我進入CAMP 在會員中心點選 應用程式 卻找不到 研發服務雲 可點選   該解決                4  \n",
       "6                       用CAMP要簽核電腦外帶攜出申請單 出現應用程式發生錯誤                4  \n",
       "7  研發服務雲   偕同開發   新增專案   無法新增 J51 or J51D 專案 for ...                4  \n",
       "8        進入 CAMP 「研發服務雲」的icon 沒有進一步的資訊   畫面空白 沒有發包選單                4  \n",
       "9                      在CAMP平臺點選 應用程式 找不到 研發服務雲 可以點選                4  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8384 entries, 0 to 8383\n",
      "Data columns (total 8 columns):\n",
      "description          8384 non-null object\n",
      "category_a           8384 non-null object\n",
      "category_b           8384 non-null object\n",
      "category_c           8384 non-null object\n",
      "category_d           8384 non-null object\n",
      "category             8384 non-null object\n",
      "description_clean    8384 non-null object\n",
      "category_target      8384 non-null int64\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 524.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.shape\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['description'].str.len()<5].category_a_target.value_counts()/df.category_a_target.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Outlook與郵件', 'SAP', '其他', '網路', '資訊系統'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index to categories mapping\n",
    "mapping = df.category.astype('category').cat.categories\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df=data_reduction(df)\n",
    "#df = df.drop( labels = df[(df['category_target'] != 6) & (df['category_target'] != 0) & (df['category_target'] != 3) \n",
    "#                          & (df['category_target'] != 1) & (df['category_target'] != 7)].index, axis = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Outlook與郵件    1778\n",
       "SAP           1443\n",
       "其他            1470\n",
       "網路            2314\n",
       "資訊系統          1379\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"category\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "聯絡\n"
     ]
    }
   ],
   "source": [
    "print (cut_to_word('可以幫我聯絡'.strip(),js))\n",
    "#df['cut_words'] = df['description_add_category'].apply(lambda s: cut_to_word(s.strip(),js))\n",
    "#df['cut_words'] = df['description_add_category'].apply(lambda s: cut_to_word(s.strip(),js))\n",
    "#df['cut_words_clean'] = df['description_clean'].apply(lambda s: cut_to_word(s.strip(),js))\n",
    "#df['cut_words_clean'] = df['description_clean'].apply(lambda s: cut_to_word(s.strip(),js))\n",
    "\n",
    "#df['cut_words'] = df['description'].apply(lambda s: cut_to_word(s.strip(),js))\n",
    "#df['cut_words'] = df['description'].apply(lambda s: cut_to_word(s.strip(),js))\n",
    "df['cut_words'] = df['description_clean'].apply(lambda s: cut_to_word(s.strip(),js))\n",
    "#df['cut_words'] = df['description_clean_add_category_abcd'].apply(lambda s: cut_to_word(s.strip(),js))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 拿掉時間,人名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b719305472d442dd8ff11918d0e76561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8384), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data,word2vec=produce_cbowfile(df.description_clean ,jieba_stopwords_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>category_a</th>\n",
       "      <th>category_b</th>\n",
       "      <th>category_c</th>\n",
       "      <th>category_d</th>\n",
       "      <th>category</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>category_target</th>\n",
       "      <th>cut_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>無法會員登入,顯示訊息:無效的帳號或使用者不存在。帳號:96122401</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>資訊系統</td>\n",
       "      <td>無法會員登入 顯示訊息 無效的帳號或不存在 帳號</td>\n",
       "      <td>4</td>\n",
       "      <td>無法,會員,無法會員,登入,顯示,訊息,無效,帳號,不存,帳號</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>因今天有事請假，要補登先前的加班，但開啟camp後，出勤表單顯示的內容看起來像測試的，沒有最...</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>資訊系統</td>\n",
       "      <td>因有事請假 要補登先前的加班 但開啟camp後 出勤表單顯示的內容像測試的 沒有的時間也沒辦...</td>\n",
       "      <td>4</td>\n",
       "      <td>有事,請假,補登,先前,加班,開啟,camp,出勤,表單,顯示,內容,測試,時間,使用,登出...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>手機簽核BPM有問題,都顯示亂碼  #18227</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>資訊系統</td>\n",
       "      <td>簽核BPM有問題 都顯示亂碼</td>\n",
       "      <td>4</td>\n",
       "      <td>簽核,BPM,顯示,亂碼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>無法在手機上面使用CAMP進行表單簽核動作。分機：17132</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>資訊系統</td>\n",
       "      <td>無法在上面使用CAMP進行表單簽核動作</td>\n",
       "      <td>4</td>\n",
       "      <td>無法,上面,無法上面,使用,CAMP,進行,表單,簽核,動作</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>出差同仁無法登入camp, 委請同事詢問</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>CAMP</td>\n",
       "      <td>資訊系統</td>\n",
       "      <td>出差同仁無法登入camp  委請同事詢問</td>\n",
       "      <td>4</td>\n",
       "      <td>出差,同仁,無法登入,camp,委請,同事,詢問</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description category_a category_b  \\\n",
       "0               無法會員登入,顯示訊息:無效的帳號或使用者不存在。帳號:96122401       CAMP       CAMP   \n",
       "1  因今天有事請假，要補登先前的加班，但開啟camp後，出勤表單顯示的內容看起來像測試的，沒有最...       CAMP       CAMP   \n",
       "2                           手機簽核BPM有問題,都顯示亂碼  #18227       CAMP       CAMP   \n",
       "3                     無法在手機上面使用CAMP進行表單簽核動作。分機：17132       CAMP       CAMP   \n",
       "4                               出差同仁無法登入camp, 委請同事詢問       CAMP       CAMP   \n",
       "\n",
       "  category_c category_d category  \\\n",
       "0       CAMP       CAMP     資訊系統   \n",
       "1       CAMP       CAMP     資訊系統   \n",
       "2       CAMP       CAMP     資訊系統   \n",
       "3       CAMP       CAMP     資訊系統   \n",
       "4       CAMP       CAMP     資訊系統   \n",
       "\n",
       "                                   description_clean  category_target  \\\n",
       "0                           無法會員登入 顯示訊息 無效的帳號或不存在 帳號                4   \n",
       "1  因有事請假 要補登先前的加班 但開啟camp後 出勤表單顯示的內容像測試的 沒有的時間也沒辦...                4   \n",
       "2                                     簽核BPM有問題 都顯示亂碼                4   \n",
       "3                                無法在上面使用CAMP進行表單簽核動作                4   \n",
       "4                               出差同仁無法登入camp  委請同事詢問                4   \n",
       "\n",
       "                                           cut_words  \n",
       "0                    無法,會員,無法會員,登入,顯示,訊息,無效,帳號,不存,帳號  \n",
       "1  有事,請假,補登,先前,加班,開啟,camp,出勤,表單,顯示,內容,測試,時間,使用,登出...  \n",
       "2                                       簽核,BPM,顯示,亂碼  \n",
       "3                     無法,上面,無法上面,使用,CAMP,進行,表單,簽核,動作  \n",
       "4                           出差,同仁,無法登入,camp,委請,同事,詢問  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec.wv.most_similar(positive=['outlook'], negative=['網路'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingMatrix=get_embedding_martrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df\n",
    "y = df.category_target\n",
    "#将数据划分为训练集和验证集\n",
    "#注意要打乱数据，因为原始数据是分类排好序的\n",
    "x_train,x_test,y_train,y_test =seperatedata(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1759\n",
       "0    1358\n",
       "2    1078\n",
       "1    1066\n",
       "4    1027\n",
       "Name: category_target, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    555\n",
       "0    420\n",
       "2    392\n",
       "1    377\n",
       "4    352\n",
       "Name: category_target, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le = LabelEncoder()  \n",
    "#y_test = le.fit_transform(y_test) # 這邊Y.shape = (84020, )\n",
    "#y_test = y_test.reshape(-1,1) # 將Y的shape轉換成： Y.shape= (84020, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0.]\n",
      "num_classes = 5\n"
     ]
    }
   ],
   "source": [
    "# label 做 onehot\n",
    "y_one_hot,num_classes = labelEncoding(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 做 onehot\n",
    "#training_embeddings = get_word2vec_embeddings(word2vec, x_train, generate_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2865    3\n",
       "8175    2\n",
       "5933    0\n",
       "4857    3\n",
       "6859    0\n",
       "2031    4\n",
       "1056    3\n",
       "2858    3\n",
       "7216    2\n",
       "4038    3\n",
       "Name: category_target, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>category_a</th>\n",
       "      <th>category_b</th>\n",
       "      <th>category_c</th>\n",
       "      <th>category_d</th>\n",
       "      <th>category</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>category_target</th>\n",
       "      <th>cut_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>使用者反應無法連線 Internet。(Ext.15518)</td>\n",
       "      <td>網管</td>\n",
       "      <td>網路</td>\n",
       "      <td>無法連到大陸或其他分公司</td>\n",
       "      <td>連線分公司網路問題</td>\n",
       "      <td>網路</td>\n",
       "      <td>無法連線 Internet</td>\n",
       "      <td>3</td>\n",
       "      <td>無法連線,Internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8175</th>\n",
       "      <td>分機: 15354  問題: 印表機的文件都在等候列印中，無法列印</td>\n",
       "      <td>網管</td>\n",
       "      <td>作業系統與印表機</td>\n",
       "      <td>印表機問題</td>\n",
       "      <td>印表機無法列印</td>\n",
       "      <td>其他</td>\n",
       "      <td>印表機的文件都在等候列印中 無法列印</td>\n",
       "      <td>2</td>\n",
       "      <td>印表機,文件,等候,列印,無法,列印,無法列印</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>Microsot Outlook 認證視窗不斷跳出，要求填列相關認證資訊(QUANTA\\Qu...</td>\n",
       "      <td>網管</td>\n",
       "      <td>Outlook與郵件</td>\n",
       "      <td>Outlook</td>\n",
       "      <td>其他問題</td>\n",
       "      <td>Outlook與郵件</td>\n",
       "      <td>Microsot Outlook 認證視窗不斷跳出 要求填列相關認證資訊 QUANTA\\Qu...</td>\n",
       "      <td>0</td>\n",
       "      <td>Microsot,Outlook,認證,視窗,不斷,跳出,要求,填列,認證,資訊,QUANT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>有線網路無法連線 , Proxy憑證無法辨識</td>\n",
       "      <td>網管</td>\n",
       "      <td>網路</td>\n",
       "      <td>電腦網路不通</td>\n",
       "      <td>網路不斷出現驗證訊息</td>\n",
       "      <td>網路</td>\n",
       "      <td>有線網路無法連線   Proxy憑證無法辨識</td>\n",
       "      <td>3</td>\n",
       "      <td>網路無法連線,Proxy,憑證,無法,辨識,無法辨識</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6859</th>\n",
       "      <td>郵件異常，開了網頁後郵件就無法收發，甚至無法收信  #3825-623106</td>\n",
       "      <td>網管</td>\n",
       "      <td>Outlook與郵件</td>\n",
       "      <td>Outlook</td>\n",
       "      <td>郵件無法收發</td>\n",
       "      <td>Outlook與郵件</td>\n",
       "      <td>郵件異常 開了網頁後郵件就無法收發 無法收信</td>\n",
       "      <td>0</td>\n",
       "      <td>郵件,異常,網頁,郵件,無法收發,無法收信</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>請問一下當初QSIT設計時，上傳檔案的大小限制是多少呢  還有command欄位好像有字串長...</td>\n",
       "      <td>R&amp;D資訊系統</td>\n",
       "      <td>測試相關服務</td>\n",
       "      <td>【QSIT】系統整合測試系統</td>\n",
       "      <td>相關操作詢問</td>\n",
       "      <td>資訊系統</td>\n",
       "      <td>請問一下當初QSIT設計時 上傳檔案的大小限制是呢  command欄位有字串長度限制 是可...</td>\n",
       "      <td>4</td>\n",
       "      <td>請問,當初,QSIT,計時,上傳,檔案,限制,command,欄位,字串,長度,限制,填多長,字串</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>使用Open VPN 時連上MyBPM 首頁但無法再Link進去 請協助處理  EXT:15306</td>\n",
       "      <td>網管</td>\n",
       "      <td>VPN連線</td>\n",
       "      <td>SSLVPN問題</td>\n",
       "      <td>無法登入</td>\n",
       "      <td>網路</td>\n",
       "      <td>使用Open VPN 時連上MyBPM 首頁但無法再Link</td>\n",
       "      <td>3</td>\n",
       "      <td>使用,Open,VPN,連上,My,BPM,首頁,無法,Link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>無法連線到上海模具廠的FTP。</td>\n",
       "      <td>網管</td>\n",
       "      <td>網路</td>\n",
       "      <td>無法連到大陸或其他分公司</td>\n",
       "      <td>連線分公司網路問題</td>\n",
       "      <td>網路</td>\n",
       "      <td>無法連線到模具廠的FTP</td>\n",
       "      <td>3</td>\n",
       "      <td>無法連線,模具廠,FTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>Outlook可以登入及MVPN也可以使用，但是商用Skype無法登入使用。</td>\n",
       "      <td>網管</td>\n",
       "      <td>商務用Skype</td>\n",
       "      <td>無法登入</td>\n",
       "      <td>無法登入</td>\n",
       "      <td>其他</td>\n",
       "      <td>Outlook可以登入及也可以使用 商用Skype無法登入使用</td>\n",
       "      <td>2</td>\n",
       "      <td>Outlook,登入,使用,商用,Skype,無法登入,使用</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4038</th>\n",
       "      <td>因工作需要，下在中國人民共和國知識產權局的專利文件，因故無法下載，錯誤訊息如下：  錯誤碼：...</td>\n",
       "      <td>網管</td>\n",
       "      <td>網路</td>\n",
       "      <td>無法連到某台Server</td>\n",
       "      <td>無法連到某些Server</td>\n",
       "      <td>網路</td>\n",
       "      <td>因工作需要 下在中國人民共和國知識產權局的專利文件 因故無法下載 錯誤訊息   錯誤碼 64...</td>\n",
       "      <td>3</td>\n",
       "      <td>工作,中國人,共和國,知識產權,專利,文件,因故,無法,下載,無法下載,錯誤訊息,錯誤碼,6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description category_a  \\\n",
       "2865                     使用者反應無法連線 Internet。(Ext.15518)         網管   \n",
       "8175                  分機: 15354  問題: 印表機的文件都在等候列印中，無法列印         網管   \n",
       "5933  Microsot Outlook 認證視窗不斷跳出，要求填列相關認證資訊(QUANTA\\Qu...         網管   \n",
       "4857                             有線網路無法連線 , Proxy憑證無法辨識         網管   \n",
       "6859             郵件異常，開了網頁後郵件就無法收發，甚至無法收信  #3825-623106         網管   \n",
       "2031  請問一下當初QSIT設計時，上傳檔案的大小限制是多少呢  還有command欄位好像有字串長...    R&D資訊系統   \n",
       "1056  使用Open VPN 時連上MyBPM 首頁但無法再Link進去 請協助處理  EXT:15306         網管   \n",
       "2858                                    無法連線到上海模具廠的FTP。         網管   \n",
       "7216             Outlook可以登入及MVPN也可以使用，但是商用Skype無法登入使用。         網管   \n",
       "4038  因工作需要，下在中國人民共和國知識產權局的專利文件，因故無法下載，錯誤訊息如下：  錯誤碼：...         網管   \n",
       "\n",
       "      category_b      category_c    category_d    category  \\\n",
       "2865          網路    無法連到大陸或其他分公司     連線分公司網路問題          網路   \n",
       "8175    作業系統與印表機           印表機問題       印表機無法列印          其他   \n",
       "5933  Outlook與郵件         Outlook          其他問題  Outlook與郵件   \n",
       "4857          網路          電腦網路不通    網路不斷出現驗證訊息          網路   \n",
       "6859  Outlook與郵件         Outlook        郵件無法收發  Outlook與郵件   \n",
       "2031      測試相關服務  【QSIT】系統整合測試系統        相關操作詢問        資訊系統   \n",
       "1056       VPN連線        SSLVPN問題          無法登入          網路   \n",
       "2858          網路    無法連到大陸或其他分公司     連線分公司網路問題          網路   \n",
       "7216    商務用Skype            無法登入          無法登入          其他   \n",
       "4038          網路    無法連到某台Server  無法連到某些Server          網路   \n",
       "\n",
       "                                      description_clean  category_target  \\\n",
       "2865                                      無法連線 Internet                3   \n",
       "8175                                 印表機的文件都在等候列印中 無法列印                2   \n",
       "5933  Microsot Outlook 認證視窗不斷跳出 要求填列相關認證資訊 QUANTA\\Qu...                0   \n",
       "4857                             有線網路無法連線   Proxy憑證無法辨識                3   \n",
       "6859                             郵件異常 開了網頁後郵件就無法收發 無法收信                0   \n",
       "2031  請問一下當初QSIT設計時 上傳檔案的大小限制是呢  command欄位有字串長度限制 是可...                4   \n",
       "1056                     使用Open VPN 時連上MyBPM 首頁但無法再Link                3   \n",
       "2858                                       無法連線到模具廠的FTP                3   \n",
       "7216                    Outlook可以登入及也可以使用 商用Skype無法登入使用                2   \n",
       "4038  因工作需要 下在中國人民共和國知識產權局的專利文件 因故無法下載 錯誤訊息   錯誤碼 64...                3   \n",
       "\n",
       "                                              cut_words  \n",
       "2865                                      無法連線,Internet  \n",
       "8175                            印表機,文件,等候,列印,無法,列印,無法列印  \n",
       "5933  Microsot,Outlook,認證,視窗,不斷,跳出,要求,填列,認證,資訊,QUANT...  \n",
       "4857                         網路無法連線,Proxy,憑證,無法,辨識,無法辨識  \n",
       "6859                              郵件,異常,網頁,郵件,無法收發,無法收信  \n",
       "2031  請問,當初,QSIT,計時,上傳,檔案,限制,command,欄位,字串,長度,限制,填多長,字串  \n",
       "1056                   使用,Open,VPN,連上,My,BPM,首頁,無法,Link  \n",
       "2858                                       無法連線,模具廠,FTP  \n",
       "7216                     Outlook,登入,使用,商用,Skype,無法登入,使用  \n",
       "4038  工作,中國人,共和國,知識產權,專利,文件,因故,無法,下載,無法下載,錯誤訊息,錯誤碼,6...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_y=y_test\n",
    "df_test_x=x_test\n",
    "df_test_x.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8741 unique tokens.\n",
      "Found 4253 unique tokens.\n",
      "Found 8741 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# 標點符號過濾\n",
    "WORD_FILTERS = '!\"#$&()*+,-./:;<=>?@[\\\\]^_{|}~\\t\\n'\n",
    "# 字典數量\n",
    "#只考虑数据集中前10000个最常见的单词\n",
    "NUM_WORDS = 5000\n",
    "# 向量長度\n",
    "#100个单词后截断评论，这个参数非常影响准确度\n",
    "MAX_LEN = 30\n",
    "\n",
    "embedding_dim=256\n",
    "\n",
    "x_train2=x_train\n",
    "#将整数列表转化成形状为（samples，maxlen）的二维整数张量\n",
    "x_train,train_word_index = covert_sequences(x_train.cut_words,NUM_WORDS, MAX_LEN)\n",
    "x_test,train_word_index = covert_sequences(x_test.cut_words,NUM_WORDS, MAX_LEN)\n",
    "x_train2,train_word_index = covert_sequences(x_train2.cut_words,NUM_WORDS, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token for \"the\" 7\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/jannesklaas/17-nlp-and-word-embeddings\n",
    "print('Token for \"the\"',train_word_index.get(\"系統\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,   24,  493],\n",
       "       [   0,    0,    0, ...,    1,   68,  147],\n",
       "       [   0,    0,    0, ..., 1107,  389, 1108],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  353,    3,  378],\n",
       "       [   0,    0,    0, ...,  166,   80,    3],\n",
       "       [   0,    0,    0, ...,    9,   10,   51]], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.43198535 -0.45890471  0.1615601  ...  0.06966524  0.11873438\n",
      "  -0.45133391]\n",
      " [ 0.3179037  -0.33691368  0.11977738 ...  0.05055702  0.08750065\n",
      "  -0.33338067]\n",
      " ...\n",
      " [ 0.13899864  0.46566343  0.96458152 ...  0.17579288  0.17860688\n",
      "   0.64794416]\n",
      " [ 0.34751926  0.27848674  0.872602   ...  0.47948263  0.72211493\n",
      "   0.36880417]\n",
      " [ 0.44574838  0.74316155  0.89275476 ...  0.62990687  0.77434593\n",
      "   0.75087547]]\n",
      "-----------=====-----------\n",
      "(8742, 256)\n"
     ]
    }
   ],
   "source": [
    "train_embedding_weights = np.zeros((len(train_word_index)+1, embedding_dim))\n",
    "\n",
    "for word,index in train_word_index.items():\n",
    "    train_embedding_weights[index,:] = word2vec[word] if word in word2vec else np.random.rand(embedding_dim)\n",
    "    #if word in word2vec:\n",
    "    #    print(word2vec[word])\n",
    "print(train_embedding_weights)\n",
    "print(\"-----------=====-----------\")\n",
    "print(train_embedding_weights.shape)\n",
    "# 字典數量\n",
    "#NUM_WORDS = train_embedding_weights.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words = min(NUM_WORDS, len(train_word_index)) # How many words are there actually\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, embedding_dim))\n",
    "\n",
    "# The vectors need to be in the same position as their index. \n",
    "# Meaning a word with token 1 needs to be in the second row (rows start with zero) and so on\n",
    "\n",
    "# Loop over all words in the word index\n",
    "for word, i in train_word_index.items():\n",
    "    # If we are above the amount of words we want to use we do nothing\n",
    "    if i >= NUM_WORDS: \n",
    "        continue\n",
    "    \n",
    "    if word in word2vec:\n",
    "        embedding_vector=word2vec[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    # Get the embedding vector for the word\n",
    "    #embedding_vector = df.cut_words.get(word)\n",
    "    #print(word)\n",
    "    # If there is an embedding vector, put it in the embedding matrix\n",
    "    #if embedding_vector is not None: \n",
    "    #    embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.43198535, -0.45890471,  0.1615601 , ...,  0.06966524,\n",
       "         0.11873438, -0.45133391],\n",
       "       [ 0.3179037 , -0.33691368,  0.11977738, ...,  0.05055702,\n",
       "         0.08750065, -0.33338067],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...  285  562   37]\n",
      " [   0    0    0 ...  849   24  411]\n",
      " [   0    0    0 ...   75 1401   22]\n",
      " ...\n",
      " [   0    0    0 ...   12    2   32]\n",
      " [   0    0    0 ...  932  154  688]\n",
      " [   0    0    0 ...  143  322  763]]\n"
     ]
    }
   ],
   "source": [
    "print (x_train)\n",
    "# x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2096, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,   24,  493],\n",
       "       [   0,    0,    0, ...,    1,   68,  147],\n",
       "       [   0,    0,    0, ..., 1107,  389, 1108],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  353,    3,  378],\n",
       "       [   0,    0,    0, ...,  166,   80,    3],\n",
       "       [   0,    0,    0, ...,    9,   10,   51]], dtype=int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (x_test.shape)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6288, 30), (8384,), (2096, 30))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "5\n",
      "30\n",
      "(1815, 256)\n"
     ]
    }
   ],
   "source": [
    "print(NUM_WORDS)\n",
    "print(num_classes)\n",
    "print(MAX_LEN)\n",
    "print(embeddingMatrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BidLSTM(num_classes, vocab_size, sentence_max_len,embedding_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, \n",
    "                        output_dim=embedding_dim, \n",
    "                        input_length=sentence_max_len))\n",
    "    model.add(Bidirectional(LSTM(128,implementation=2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    #model.add(Flatten())\n",
    "    model.add(Dense(256,activation='tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "    #model.add(Dense(50,activation='tanh'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM(num_classes, vocab_size, sentence_max_len,embedding_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_dim, input_length=sentence_max_len))\n",
    "    model.add(SpatialDropout1D(0.7))\n",
    "    model.add(LSTM(64, dropout=0.7, recurrent_dropout=0.7))\n",
    "    model.add(Dense(50,activation='tanh'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    " \n",
    " \n",
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    " \n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    " \n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    " \n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    " \n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    " \n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    " \n",
    "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    " \n",
    "        self.u = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    " \n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    " \n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    " \n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    " \n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    " \n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    " \n",
    "        a = K.exp(ait)\n",
    " \n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    " \n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    " \n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    " \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras import backend as K\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/suicaokhoailang/lstm-attention-baseline-0-672-lb\n",
    "#NUM_WORDS=embedding_matrix.shape[0]\n",
    "from keras.layers import core,BatchNormalization\n",
    "#CuDNNLSTM比較厲害\n",
    "from keras.layers import CuDNNLSTM\n",
    "def BidCuDNNLSTM(num_classes, vocab_size, sentence_max_len,embedding_dim):\n",
    "    SEQ_LEN = 40  # magic number - length to truncate sequences of words\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, \n",
    "                        output_dim=embedding_dim, \n",
    "                        #weights=[embedding_matrix],#需要研究如何用, 結果會變差\n",
    "                        input_length=sentence_max_len,trainable = False))\n",
    "    model.add(Bidirectional(CuDNNLSTM(256, return_sequences=True)))\n",
    "    model.add(Bidirectional(CuDNNLSTM(128,return_sequences=True)))\n",
    "    model.add(Attention(SEQ_LEN))\n",
    "    #model.add(AttentionWithContext())\n",
    "    model.add(Dropout(0.5))\n",
    "    #model.add(Flatten())\n",
    "    #model.add(Dense(256,activation='tanh'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dense(50,activation='tanh'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/takuok/bidirectional-lstm-and-attention-lb-0-043\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import LSTM, Bidirectional, Dropout\n",
    "\n",
    "#速度有點慢，不建議\n",
    "def BidLstm(num_classes, vocab_size, sentence_max_len,embedding_dim):\n",
    "    inp = Input(shape=(sentence_max_len, ))\n",
    "    x = Embedding(vocab_size, embedding_dim, #weights=[embedding_matrix],\n",
    "                  trainable=False)(inp)\n",
    "    x = Bidirectional(LSTM(300, return_sequences=True, dropout=0.25,\n",
    "                           recurrent_dropout=0.25))(x)\n",
    "    x = Attention(sentence_max_len)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    #x = Dense(256, activation=\"tanh\")(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    #x = Dense(num_classes, activation=\"sigmoid\")(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout,Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "#https://www.kaggle.com/fareise/multi-head-self-attention-for-text-classification\n",
    "\n",
    "def CNNText(num_classes, vocab_size, max_sequence_length, embedding_dim):\n",
    "    \n",
    "    model = Sequential()\n",
    "    inp = Input(shape=(max_sequence_length,))\n",
    "    x = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix])(inp)\n",
    "    x = Reshape((max_sequence_length, embedding_dim, 1))(x)\n",
    "    \n",
    "    x = Attention(vocab_size)(x)  #output: [batch_size, time_step, nb_head*size_per_head]\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    x = Dense(num_classes, activation='sigmsoftmaxoid')(x)\n",
    "    \n",
    "    model = Model(inputs = inp, outputs = x)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://mlwhiz.com/blog/2019/03/09/deeplearning_architectures_text_classification/\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.pooling import MaxPool2D\n",
    "def CCN_Conv2D(num_classes, vocab_size, max_sequence_length, embedding_dim):\n",
    "    filter_sizes = [1,2,3,5]\n",
    "    num_filters = vocab_size\n",
    "\n",
    "    inp = Input(shape=(max_sequence_length,))\n",
    "    x = Embedding(vocab_size, embedding_dim#, weights=[embedding_matrix]\n",
    "                 )(inp)\n",
    "    x = Reshape((max_sequence_length, embedding_dim, 1))(x)\n",
    "\n",
    "    maxpool_pool = []\n",
    "    for i in range(len(filter_sizes)):\n",
    "        conv = Conv2D(num_filters, kernel_size=(filter_sizes[i], embedding_dim),\n",
    "                                     kernel_initializer='he_normal', activation='relu')(x)\n",
    "        maxpool_pool.append(MaxPool2D(pool_size=(max_sequence_length - filter_sizes[i] + 1, 1))(conv))\n",
    "\n",
    "    z = concatenate(axis=1)(maxpool_pool)   \n",
    "    z = Flatten()(z)\n",
    "    z = Dropout(0.1)(z)\n",
    "\n",
    "    #outp = Dense(1, activation=\"sigmoid\")(z)\n",
    "    outp = Dense(num_classes, activation='sigmsoftmaxoid')(z)\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.merge import concatenate, add\n",
    "from keras.layers import CuDNNGRU\n",
    "#https://www.kaggle.com/kakiac/deep-learning-4-text-classification-cnn-bi-lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/ngyptr/multi-class-classification-with-lstm\n",
    "#https://www.kaggle.com/eashish/bidirectional-gru-with-convolution\n",
    "#https://stackoverflow.com/questions/53904688/using-keras-to-build-a-lstmconv2d-model\n",
    "#效果也不錯\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "def GRU(num_classes, vocab_size, max_sequence_length, embedding_dim):\n",
    "    inp = Input(shape = (max_sequence_length,))\n",
    "    x = Embedding(vocab_size, embedding_dim, weights = [embedding_matrix], trainable = False)(inp)\n",
    "    \n",
    "    #組合1\n",
    "    #x = SpatialDropout1D(0.7)(x)\n",
    "    #x = Bidirectional(CuDNNGRU(128, return_sequences=True))(x)\n",
    "    #x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)  \n",
    "    \n",
    "    #組合2\n",
    "    #https://www.kaggle.com/eashish/bidirectional-gru-with-convolution\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x = Bidirectional(CuDNNGRU(128,return_sequences=True))(x)\n",
    "    x = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
    "    \n",
    "    #組合3\n",
    "    #https://www.kaggle.com/taindow/simple-cudnngru-python-keras#Model-Architecture\n",
    "    #x = SpatialDropout1D(0.2)(x)\n",
    "    #x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)   \n",
    "    #x = Conv1D(64, kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x)\n",
    "    \n",
    "    att = Attention(38)(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x) \n",
    "    conc = concatenate([att,avg_pool, max_pool])\n",
    "    \n",
    "    output = Dropout(0.5)(conc)\n",
    "    output = Dense(units=64)(output)\n",
    "    output = Activation('relu')(output)\n",
    "    preds=Dense(num_classes, activation='softmax')(output)\n",
    "    model = Model(inputs = inp, outputs = preds)\n",
    "    print(model.summary())\n",
    "    return model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lstm_du(num_classes, vocab_size, max_sequence_length, embedding_dim):\n",
    "    #跑的比較慢，準確率也滿高的\n",
    "    #https://mlwhiz.com/blog/2019/03/09/deeplearning_architectures_text_classification/\n",
    "    #https://www.kaggle.com/sanket30/cudnnlstm-lstm-99-accuracy\n",
    "    #https://www.kaggle.com/suicaokhoailang/10-fold-lstm-with-attention-0-991-lb\n",
    "    #無法用predict_classes\n",
    "    inp = Input(shape=(max_sequence_length,))\n",
    "    x = Embedding(num_classes, embedding_dim#, weights=[embedding_matrix]\n",
    "                 ,trainable=False)(inp)\n",
    "    '''\n",
    "    Here 64 is the size(dim) of the hidden state vector as well as the output vector. Keeping return_sequence we want the output for the entire sequence. So what is the dimension of output for this layer?\n",
    "        64*70(maxlen)*2(bidirection concat)\n",
    "    CuDNNLSTM is fast implementation of LSTM layer in Keras which only runs on GPU\n",
    "    '''\n",
    "    \n",
    "    x = Bidirectional(LSTM(256,dropout=0.4,recurrent_dropout=0.4,activation='relu', return_sequences=True))(x)\n",
    "    x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    att = Attention(max_sequence_length)(x)\n",
    "    conc = concatenate([att,avg_pool, max_pool])\n",
    "    conc = Dense(64, activation=\"relu\")(conc)\n",
    "    conc = Dropout(0.5)(conc)\n",
    "    outp = Dense(num_classes, activation=\"softmax\")(conc)\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes, vocab_size, max_sequence_length, embedding_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, \n",
    "                        output_dim=256, \n",
    "                        input_length=max_sequence_length))\n",
    "    model.add(Bidirectional(LSTM(128,implementation=2)))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 256)           1280000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 1,675,525\n",
      "Trainable params: 1,675,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(num_classes, NUM_WORDS,MAX_LEN,embedding_dim)\n",
    "\n",
    "model_name = '1999-Fine-Tune'\n",
    "lr = 2e-5\n",
    "optimizer = adam(lr=lr,beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5659 samples, validate on 629 samples\n",
      "Epoch 1/10\n",
      "5659/5659 [==============================] - 20s 3ms/step - loss: 0.8697 - acc: 0.6717 - val_loss: 0.6048 - val_acc: 0.7933\n",
      "Epoch 2/10\n",
      "5659/5659 [==============================] - 17s 3ms/step - loss: 0.3568 - acc: 0.8851 - val_loss: 0.5830 - val_acc: 0.8013\n",
      "Epoch 3/10\n",
      "3700/5659 [==================>...........] - ETA: 5s - loss: 0.1988 - acc: 0.9332"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-fee79c7c1781>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                             \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                             \u001b[0;31m#callbacks = [ checkpoint,earlystop]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                          )\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = 'intent_model'\n",
    "model_path = 'saved_models/{}.h5'.format(model_name)\n",
    "epochs =10\n",
    "batch_size = 20\n",
    "train_ratio = 0.9\n",
    "\n",
    "\n",
    "#model_path = './saved_models/DensetNet_0524001.h5'.format(model_name)\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_acc', save_best_only=True, verbose=1)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.1, min_lr=0.000001, cooldown=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=6, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "model_history = model.fit(x=x_train, y=y_one_hot,\n",
    "                            batch_size=batch_size, \n",
    "                            epochs=epochs,\n",
    "                            validation_split= 1 - train_ratio\n",
    "                            #callbacks = [ checkpoint,earlystop]\n",
    "                         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "def show_train_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_train_history(model_history,'acc','val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_train_history(model_history,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(model_path)\n",
    "x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_name, y_predict, predict_arr,y_predict_probability = predict(model,x_test,mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_predict_probability2=y_predict_probability.astype(float)\n",
    "#y_predict_probability3 = pd.Series(['{0:.2f}%'.format(val * 100) for val in y_predict_probability2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test_y\n",
    "#x_test\n",
    "#x_test,train_word_index = covert_sequences(x_test,NUM_WORDS, MAX_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cat_name(x): \n",
    "        return mapping[x]\n",
    "    \n",
    "def predict(test):\n",
    "#     model = load_model(model_path)\n",
    "    y_predict_probability = model.predict(test)\n",
    "    y_predict = model.predict_classes(test)\n",
    "\n",
    "    return to_cat_name(y_predict), y_predict, y_predict_probability\n",
    "\n",
    "y_predict_name, y_predict, y_predict_probability = predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_name = to_cat_name(df_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pd.DataFrame({'1_sentence':df_test_x.description_clean,'2_sentence':df_test_x.cut_words,\n",
    "              '3_y_predict':y_predict,\n",
    "              '4_y_predict_name':y_predict_name,\n",
    "              '5_answer':df_test_y,\n",
    "              '6_answer':mapping[df_test_y],\n",
    "              '7_y_predict_probability':list(predict_arr),\n",
    "              })\n",
    "#print( format(y_predict_probability, '.3%'))\n",
    "predict_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "accuracy = 1 - (float(len(predict_df[predict_df['3_y_predict'] != predict_df['5_answer']])))/(len(predict_df))\n",
    "print ('accuracy : {} !!!!!!!!'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differ_ans=predict_df[predict_df['3_y_predict'] != predict_df['5_answer']]\n",
    "differ_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(differ_ans).to_csv('differ_ans_ab_Network2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "def to_cat_name(x): \n",
    "        return mapping[x]\n",
    "pd.crosstab(np.array(y_predict_name), to_cat_name(np.array(df_test_y)),\n",
    "            rownames=['3_y_predict'], colnames=['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = pd.read_csv('Project_19999/data/19999_test_question_v1.csv')#usecols=['description','category_a', 'category_a_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest['cut_words'] = dfTest['description_clean'].apply(lambda s: cut_to_word(s.strip(),js))+','+dfTest['category_a_b'].apply(lambda s: cut_to_word(s.strip(),js))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_new,train_word_index_new = covert_sequences(dfTest.cut_words,NUM_WORDS, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_new=dfTest.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_name_new, y_predict_new, predict_arr_new,y_predict_probability_new = predict_class2(model,x_test_new,64,mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pd.DataFrame({'1_sentence':dfTest.description_clean,'2_sentence':dfTest.cut_words,\n",
    "              '3_y_predict':y_predict_new,\n",
    "              '4_y_predict_name':y_predict_name_new,\n",
    "              '5_answer':y_test_new,\n",
    "              '6_answer':mapping[y_test_new],\n",
    "              '7_y_predict_probability':list(predict_arr_new),\n",
    "              })\n",
    "#print( format(y_predict_probability, '.3%'))\n",
    "predict_df[:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predict_df).to_csv('differ_test_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(self,epochs=50):\n",
    "#     print 'building model ...'\n",
    "#     self.model = SentimentLSTM.build_model()\n",
    "\n",
    "#     print 'loading data ...'\n",
    "#     (text_train, rate_train), (text_test, rate_text) = self.load_data()\n",
    "\n",
    "#     print 'training model ...'\n",
    "#     self.model.fit(text_train, rate_train,batch_size=1000,epochs=epochs)\n",
    "#     self.model.save('model/keras.model')\n",
    "#     score = self.model.evaluate(text_test,rate_text)\n",
    "#     print score\n",
    "\n",
    "# def load_trained_model(self,path):\n",
    "#     model = SentimentLSTM.build_model()\n",
    "#     model.load_weights(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
