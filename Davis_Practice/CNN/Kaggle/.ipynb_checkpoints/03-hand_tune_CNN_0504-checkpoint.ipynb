{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import load_data, load_test_data\n",
    "from utils import num_classes, epochs, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TerminateOnNaN, CSVLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import load_data, load_test_data\n",
    "from utils import num_classes, epochs, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = load_data(test_size=0.2, img_size=224,Gray2RGB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test, X_id = load_test_data(Gray2RGB=True)\n",
    "#model_name = 'classic_CNN_GlobalAveragePooling2D'\n",
    "#model_path = './saved_models/{}_0426.h5'.format(model_name)\n",
    "#model = load_model(model_path)\n",
    "\n",
    "#scores = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "#print('Validation loss:', scores[0])\n",
    "#print('Validation accuracy:', scores[1])\n",
    "\n",
    "#y_test_pred = model.predict_classes(X_test)\n",
    "#y_test_pred_df = pd.DataFrame({'id': np.array(X_id), 'class':y_test_pred}).sort_values(by='id')\n",
    "#y_test_pred_df.to_csv('submissions_0426.csv'.format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2388, 224, 224, 3)\n",
      "(2388, 15)\n",
      "(597, 224, 224, 3)\n",
      "(597, 15)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 224, 224, 32)      128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 224, 224, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 112, 112, 128)     512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 512)       590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 56, 56, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                975       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 15)                60        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 15)                0         \n",
      "=================================================================\n",
      "Total params: 10,308,523\n",
      "Trainable params: 10,302,733\n",
      "Non-trainable params: 5,790\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# a classic CNN model\n",
    "model_name = 'classic_CNN_GlobalAveragePooling2D'\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=X_train.shape[1:], activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (5, 5), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512,  (3, 3), padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512,  (3, 3), padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512,  (3, 3), padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512,  (3, 3), padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512,  (3, 3), padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(num_classes, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "73/74 [============================>.] - ETA: 0s - loss: 2.6030 - acc: 0.1949\n",
      "Epoch 00001: val_acc improved from -inf to 0.07370, saving model to ./saved_models/CNN_0505-.h5\n",
      "74/74 [==============================] - 48s 652ms/step - loss: 2.5997 - acc: 0.1961 - val_loss: 6.3033 - val_acc: 0.0737\n",
      "Epoch 2/400\n",
      "73/74 [============================>.] - ETA: 0s - loss: 2.0357 - acc: 0.3583\n",
      "Epoch 00002: val_acc improved from 0.07370 to 0.07873, saving model to ./saved_models/CNN_0505-.h5\n",
      "74/74 [==============================] - 37s 494ms/step - loss: 2.0358 - acc: 0.3579 - val_loss: 5.7181 - val_acc: 0.0787\n",
      "Epoch 3/400\n",
      "73/74 [============================>.] - ETA: 0s - loss: 1.6464 - acc: 0.4948\n",
      "Epoch 00003: val_acc improved from 0.07873 to 0.12563, saving model to ./saved_models/CNN_0505-.h5\n",
      "74/74 [==============================] - 36s 487ms/step - loss: 1.6464 - acc: 0.4949 - val_loss: 3.5732 - val_acc: 0.1256\n",
      "Epoch 4/400\n",
      "73/74 [============================>.] - ETA: 0s - loss: 1.4313 - acc: 0.5677\n",
      "Epoch 00004: val_acc did not improve from 0.12563\n",
      "74/74 [==============================] - 36s 482ms/step - loss: 1.4288 - acc: 0.5691 - val_loss: 5.7891 - val_acc: 0.0787\n",
      "Epoch 5/400\n",
      "73/74 [============================>.] - ETA: 0s - loss: 1.2503 - acc: 0.6434\n",
      "Epoch 00005: val_acc improved from 0.12563 to 0.13065, saving model to ./saved_models/CNN_0505-.h5\n",
      "74/74 [==============================] - 36s 491ms/step - loss: 1.2485 - acc: 0.6434 - val_loss: 3.3483 - val_acc: 0.1307\n",
      "Epoch 6/400\n",
      "73/74 [============================>.] - ETA: 0s - loss: 1.1429 - acc: 0.6658\n",
      "Epoch 00006: val_acc improved from 0.13065 to 0.17420, saving model to ./saved_models/CNN_0505-.h5\n",
      "74/74 [==============================] - 36s 489ms/step - loss: 1.1412 - acc: 0.6662 - val_loss: 3.7293 - val_acc: 0.1742\n",
      "Epoch 7/400\n",
      "73/74 [============================>.] - ETA: 0s - loss: 1.0557 - acc: 0.6961\n",
      "Epoch 00007: val_acc improved from 0.17420 to 0.27638, saving model to ./saved_models/CNN_0505-.h5\n",
      "74/74 [==============================] - 36s 486ms/step - loss: 1.0564 - acc: 0.6959 - val_loss: 2.5788 - val_acc: 0.2764\n",
      "Epoch 8/400\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.9527 - acc: 0.7193\n",
      "Epoch 00008: val_acc improved from 0.27638 to 0.37521, saving model to ./saved_models/CNN_0505-.h5\n",
      "74/74 [==============================] - 37s 499ms/step - loss: 0.9519 - acc: 0.7190 - val_loss: 2.0487 - val_acc: 0.3752\n",
      "Epoch 9/400\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.8754 - acc: 0.7582\n",
      "Epoch 00009: val_acc improved from 0.37521 to 0.50084, saving model to ./saved_models/CNN_0505-.h5\n",
      "74/74 [==============================] - 38s 509ms/step - loss: 0.8720 - acc: 0.7596 - val_loss: 1.6585 - val_acc: 0.5008\n",
      "Epoch 10/400\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.8324 - acc: 0.7632\n",
      "Epoch 00010: val_acc improved from 0.50084 to 0.52429, saving model to ./saved_models/CNN_0505-.h5\n",
      "74/74 [==============================] - 36s 486ms/step - loss: 0.8330 - acc: 0.7626 - val_loss: 1.6135 - val_acc: 0.5243\n",
      "Epoch 11/400\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.8005 - acc: 0.7711\n",
      "Epoch 00011: val_acc improved from 0.52429 to 0.68677, saving model to ./saved_models/CNN_0505-.h5\n",
      "74/74 [==============================] - 36s 491ms/step - loss: 0.7970 - acc: 0.7724 - val_loss: 1.0242 - val_acc: 0.6868\n",
      "Epoch 12/400\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7155 - acc: 0.7950\n",
      "Epoch 00012: val_acc did not improve from 0.68677\n",
      "74/74 [==============================] - 36s 486ms/step - loss: 0.7140 - acc: 0.7950 - val_loss: 1.1067 - val_acc: 0.6683\n",
      "Epoch 13/400\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6852 - acc: 0.8101\n",
      "Epoch 00013: val_acc improved from 0.68677 to 0.74707, saving model to ./saved_models/CNN_0505-.h5\n",
      "74/74 [==============================] - 36s 486ms/step - loss: 0.6840 - acc: 0.8095 - val_loss: 0.8230 - val_acc: 0.7471\n",
      "Epoch 14/400\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6360 - acc: 0.8182\n",
      "Epoch 00014: val_acc improved from 0.74707 to 0.76214, saving model to ./saved_models/CNN_0505-.h5\n",
      "74/74 [==============================] - 37s 498ms/step - loss: 0.6361 - acc: 0.8184 - val_loss: 0.8025 - val_acc: 0.7621\n",
      "Epoch 15/400\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6012 - acc: 0.8362\n",
      "Epoch 00015: val_acc did not improve from 0.76214\n",
      "74/74 [==============================] - 36s 480ms/step - loss: 0.5986 - acc: 0.8372 - val_loss: 0.8078 - val_acc: 0.7504\n",
      "Epoch 16/400\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5649 - acc: 0.8431\n",
      "Epoch 00016: val_acc did not improve from 0.76214\n",
      "74/74 [==============================] - 36s 485ms/step - loss: 0.5644 - acc: 0.8427 - val_loss: 0.8192 - val_acc: 0.7420\n",
      "Epoch 17/400\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5587 - acc: 0.8452\n",
      "Epoch 00017: val_acc did not improve from 0.76214\n",
      "74/74 [==============================] - 36s 486ms/step - loss: 0.5584 - acc: 0.8450 - val_loss: 1.0056 - val_acc: 0.7102\n",
      "Epoch 18/400\n",
      "29/74 [==========>...................] - ETA: 19s - loss: 0.5310 - acc: 0.8483"
     ]
    }
   ],
   "source": [
    "# Data generator with augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='constant',\n",
    "    cval=0)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=10e-4)\n",
    "\n",
    "#model_path = './saved_models/weights-improvement-{epoch:02d}-{val_acc:.2f}.h5'.format(model_name)\n",
    "\n",
    "model_path = './saved_models/CNN_0505-.h5'.format(model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_acc', save_best_only=True, verbose=1)\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=16, verbose=1)\n",
    "# 動態調整 learning rate\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                       factor=0.1,\n",
    "                                       patience=3,\n",
    "                                       min_lr=0.5e-6)\n",
    "        \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, metrics=['accuracy'])\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "batch_size = 64\n",
    "aug_ratio = 2\n",
    "epochs = 400\n",
    "steps_per_epoch = int(aug_ratio * X_train.shape[0] / batch_size)\n",
    "validation_steps = int(aug_ratio * X_valid.shape[0] / batch_size)\n",
    "model_history = model.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size),\n",
    "                                    epochs = epochs,\n",
    "                                    validation_data = (X_valid, y_valid),\n",
    "                                    callbacks = [checkpoint,earlystop],\n",
    "                                    steps_per_epoch=steps_per_epoch,\n",
    "                                    validation_steps=validation_steps,\n",
    "                                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪製學習曲線\n",
    "#display_curve(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.plot(training_loss, 'b', label=\"training_loss\")\n",
    "plt.plot(val_loss, 'r', label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc = model_history.history['acc']\n",
    "val_acc = model_history.history['val_acc']\n",
    "\n",
    "plt.plot(training_acc, 'b', label=\"training_acc\")\n",
    "plt.plot(val_acc, 'r', label=\"validation_acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_id = load_test_data(Gray2RGB=True)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './saved_models/CNN_0505002.h5'.format(model_name)\n",
    "model = load_model(model_path)\n",
    "\n",
    "scores = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('Validation loss:', scores[0])\n",
    "print('Validation accuracy:', scores[1])\n",
    "\n",
    "y_test_pred = model.predict_classes(X_test)\n",
    "y_test_pred_df = pd.DataFrame({'id': np.array(X_id), 'class':y_test_pred}).sort_values(by='id')\n",
    "y_test_pred_df.to_csv('submissions_0505002.csv'.format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a classic CNN model\n",
    "model_name = 'classic_CNN_GlobalAveragePooling2D'\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=X_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator with augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='constant',\n",
    "    cval=0)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=10e-6)\n",
    "\n",
    "model_path = './saved_models/{}.h5'.format(model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, metrics=['accuracy'])\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "batch_size = 16\n",
    "aug_ratio = 1\n",
    "epochs = 200\n",
    "steps_per_epoch = int(aug_ratio * X_train.shape[0] / batch_size)\n",
    "validation_steps = int(aug_ratio * X_valid.shape[0] / batch_size)\n",
    "model_history = model.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size),\n",
    "                                    epochs = epochs,\n",
    "                                    validation_data = (X_valid, y_valid),\n",
    "                                    callbacks = [checkpoint, earlystop],\n",
    "                                    steps_per_epoch=steps_per_epoch,\n",
    "                                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc = model_history.history['acc']\n",
    "val_acc = model_history.history['val_acc']\n",
    "\n",
    "plt.plot(training_acc, label=\"training_acc\")\n",
    "plt.plot(val_acc, label=\"validation_acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_id = load_test_data()\n",
    "\n",
    "model_path = './saved_models/{}.h5'.format(model_name)\n",
    "model = load_model(model_path)\n",
    "\n",
    "scores = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('Validation loss:', scores[0])\n",
    "print('Validation accuracy:', scores[1])\n",
    "\n",
    "y_test_pred = model.predict_classes(X_test)\n",
    "y_test_pred_df = pd.DataFrame({'id': np.array(X_id), 'class':y_test_pred}).sort_values(by='id')\n",
    "y_test_pred_df.to_csv('./submissions/{}.csv'.format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
