{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hgp6rgtLqGxe"
   },
   "source": [
    "![](https://cdn-images-1.medium.com/max/1600/1*jX6Gwn1rt4da7e-yUj84IQ.png)\n",
    "\n",
    "### 這只是對分類特徵做 Likelihood Encoding \n",
    "\n",
    "### 也稱為Impact Encoding 或 Mean Encoding 或 Target Encoding。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yYtah12ZqGxf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2pf-UUq9qGxj"
   },
   "outputs": [],
   "source": [
    "PATH = 'data/'\n",
    "train_data = pd.read_table(PATH + 'train.tsv', engine='c')\n",
    "train_data.rename(index=str, columns={'price':'y'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_table(PATH + 'test.tsv',  engine='c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JQjM6m3WqGxl"
   },
   "source": [
    "# 抓出Category dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "naLcIH0xqGxm",
    "outputId": "6b137c1f-6bc5-4caa-e6df-f8e9eaa5044c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'category_name', 'brand_name', 'item_description']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = []\n",
    "\n",
    "for dtype, feature in zip(train_data.dtypes, train_data.columns):\n",
    "    if dtype == object:\n",
    "        categorical_features.append(feature)\n",
    "\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HEeCIDtbqGxs",
    "outputId": "5dd6a32c-05fa-40e9-e435-297cacf292f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name has 1225273 unique items\n",
      "category_name has 1287 unique items\n",
      "brand_name has 4809 unique items\n",
      "item_description has 1281426 unique items\n"
     ]
    }
   ],
   "source": [
    "for f_ in categorical_features:   \n",
    "    print('{} has {} unique items'.format(f_, train_data[f_].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0NsKU24bqGxu"
   },
   "source": [
    "## name, item_description 是文字特徵，所以不能算在內\n",
    "- 請記住 **band_name** 缺失值多達42%，本不應該拿去做target encoding\n",
    "- 為了教學，我們先移除這些NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YeepRs_LqGxw",
    "outputId": "d2ed2353-2914-430e-bef4-ffdd561bbedf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['category_name', 'brand_name']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data[train_data['brand_name'].notnull()]\n",
    "train_data = train_data[train_data['category_name'].notnull()]\n",
    "\n",
    "\n",
    "categorical_features.remove('name')\n",
    "categorical_features.remove('item_description')\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GyyXfhW2qGxz"
   },
   "source": [
    "# Mean encodings without regularization\n",
    "   - 範例1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZkpqUSOlqGxz",
    "outputId": "c1a3a778-4606-41d5-8de5-e59510bc2f3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corr between category_name and target is: 0.4465404391861943\n",
      "Corr between brand_name and target is: 0.48512436987737967\n"
     ]
    }
   ],
   "source": [
    "for f_ in categorical_features:    \n",
    "    global_mean = train_data['y'].mean()\n",
    "    # Calculate a mapping: {item_id: target_mean}\n",
    "    item_id_target_mean = train_data.groupby(f_).y.mean()\n",
    "\n",
    "    # In our non-regularized case we just *map* the computed means to the `item_id`'s\n",
    "    train_data['item_target_enc'] = train_data[f_].map(item_id_target_mean)\n",
    "\n",
    "    # Fill NaNs\n",
    "    train_data['item_target_enc'].fillna(global_mean, inplace=True) \n",
    "\n",
    "    # Print correlation\n",
    "    encoded_feature = train_data['item_target_enc'].values\n",
    "    print('Corr between {} and target is: {}'.format(f_ ,np.corrcoef(train_data['y'].values, encoded_feature)[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sO0ZcN1IqGx3"
   },
   "source": [
    "   - 範例2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4bPa8MZNqGx3",
    "outputId": "7b69da5d-fea3-46a1-fbe7-42c5d532a7c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corr between category_name and target is: 0.4465404391861943\n",
      "Corr between brand_name and target is: 0.48512436987737967\n"
     ]
    }
   ],
   "source": [
    "for f_ in categorical_features:    \n",
    "    global_mean = train_data['y'].mean()\n",
    "    # Calculate a mapping: {item_id: target_mean}\n",
    "    item_id_target_mean = train_data.groupby(f_).y.mean()\n",
    "    train_data['item_target_enc'] = train_data.groupby(f_)['y'].transform('mean')\n",
    "\n",
    "    # Fill NaNs\n",
    "    train_data['item_target_enc'].fillna(global_mean, inplace=True) \n",
    "\n",
    "    # Print correlation\n",
    "    encoded_feature = train_data['item_target_enc'].values\n",
    "    print('Corr between {} and target is: {}'.format(f_ ,np.corrcoef(train_data['y'].values, encoded_feature)[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jo_jLzkNqGx7"
   },
   "source": [
    "# 練習時間：\n",
    "## Mean encodings with Regularization\n",
    "###   1. 引入regularization 避免 Overfitting\n",
    "    - 此Regularization並不是L1, L2 Penalty\n",
    "    \n",
    "###   2. 參考指標，檢視跟Target的相關性。 \n",
    "   - 謹記，您的作業的相關性，不應該高過全域的相關性，就是範例1, 2的相關性\n",
    "   - 謹記，低於全域的相關性，不等於一定不會Overfitting\n",
    "   \n",
    "### 3. 請基於 範例1 or 範例2 完成以下\n",
    "1. KFold scheme\n",
    "2. Smoothing\n",
    "3. Smoothing and noising\n",
    "\n",
    "### 4. 練習題採取雙刀流，即簡單的「兩行內」就可以搞定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-4lrJZ_qGx9"
   },
   "source": [
    "## 1. KFold scheme\n",
    "\n",
    "- Hint: 本例，在測試是否了解kold機制，因為之後很多練習都是基於Kfold，去做處理，請學員務必務必弄懂。\n",
    "- 作法：假設切成N個fold，每次fold loop 取(N-1)份fold 資訊，去套用在剩下的那一份，vice versa.\n",
    "- 只有兩行\n",
    "    - 第一行：指派切割位置\n",
    "    - 第二行：使用條件取代，套用在範例1 or 2 方法\n",
    "\n",
    "您可能會用到，**pandas conditional replace** (google it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bVF5wWqCqGx-",
    "outputId": "4bd8825e-260e-4668-b53b-63a3710e4ce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corr between category_name and target is: 0.4448439052519598\n",
      "Corr between brand_name and target is: 0.4778697947432403\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5, shuffle = False) \n",
    "global_mean = train_data['y'].mean()\n",
    "\n",
    "for f_ in categorical_features:    \n",
    "    \n",
    "    train_data['item_target_enc'] = np.nan\n",
    "    for tr_ind, val_ind in kf.split(train_data):\n",
    "        X_tr, X_val = train_data.iloc[tr_ind], train_data.iloc[val_ind]\n",
    "        train_data.loc[train_data.index[val_ind], 'item_target_enc'] = X_val[f_ ].map(X_tr.groupby(f_ ).y.mean())\n",
    "\n",
    "    train_data['item_target_enc'].fillna(global_mean, inplace = True)\n",
    "    encoded_feature = train_data['item_target_enc'].values\n",
    "    # You will need to compute correlation like that\n",
    "    corr = np.corrcoef(train_data['y'].values, encoded_feature)[0][1]\n",
    "    print('Corr between {} and target is: {}'.format(f_ ,np.corrcoef(train_data['y'].values, encoded_feature)[0][1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XISbA2joqGyD"
   },
   "source": [
    "## 2. Smoothing\n",
    "#### Hint:\n",
    "- 第一行：請參考Slide數學公式的分子\n",
    "    - 您可能會用到 `np.multiply` \n",
    "- 第二行：請參考Slide數學公式的分母"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6kjEm96sqGyD",
    "outputId": "f878f3ed-1731-4700-fffc-7431c789efed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corr between category_name and target is: 0.4462495699282723\n",
      "Corr between brand_name and target is: 0.4819742303440905\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "alpha = 10\n",
    "global_mean = train_data['y'].mean()\n",
    "\n",
    "for f_ in categorical_features:    \n",
    "\n",
    "    train_data['item_target_mean'] = train_data.groupby(f_)['y'].transform('mean')\n",
    "    train_data['target_count'] = train_data.groupby(f_)['y'].transform('count')\n",
    "    train_data['item_target_enc_smg'] = np.multiply(train_data['item_target_mean'] ,train_data['target_count'] ) + global_mean * alpha\n",
    "    train_data['item_target_enc_smg'] = train_data['item_target_enc_smg'] / (train_data['target_count'] + alpha)\n",
    "\n",
    "    encoded_feature = train_data['item_target_enc_smg'].values\n",
    "    corr = np.corrcoef(train_data['y'].values, encoded_feature)[0][1]\n",
    "    print('Corr between {} and target is: {}'.format(f_ ,np.corrcoef(train_data['y'].values, encoded_feature)[0][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFMZzUKcqGyI"
   },
   "source": [
    "## 2-1. Smoothing paper [Daniele Micci-Barreca](https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf)\n",
    "- Hint:\n",
    "1. 練習題的 Equation 4 解釋: \n",
    "    - n 為 個數，\n",
    "    - k 為 min_samples_leaf（設好了，可自行調整）\n",
    "    - f 為 smoothing（設好了，可自行調整）\n",
    "2. 練習題的 Equation 5 解釋: \n",
    "    - B 為 smoothing\n",
    "    - y head 以及 y 為 ？您應該要想想"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "106YCNABqGyI",
    "outputId": "a1c1ab7d-f7eb-4000-b299-b4e88ca88412"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corr between category_name and target is: 0.4439601079786596\n",
      "Corr between brand_name and target is: 0.4569492306386533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: overflow encountered in exp\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "global_mean = train_data['y'].mean()\n",
    "smoothing= 5\n",
    "min_samples_leaf=100\n",
    "\n",
    "for f_ in categorical_features:    \n",
    "\n",
    "    train_data['item_target_mean'] = train_data.groupby(f_)['y'].transform('mean')\n",
    "    train_data['target_count'] = train_data.groupby(f_)['y'].transform('count')\n",
    "    # YOUR CODE GOES HERE \n",
    "    \n",
    "    # Please refer Paper equation 4\n",
    "    smoothing = 1 / (1 + np.exp(-(train_data['target_count'] - min_samples_leaf) / smoothing))\n",
    "    \n",
    "    # Please refer Paper equation 5\n",
    "    train_data['item_target_enc_smg'] = global_mean * (1 - smoothing) + train_data['item_target_mean'] * smoothing\n",
    "    \n",
    "    encoded_feature = train_data['item_target_enc_smg'].values\n",
    "    corr = np.corrcoef(train_data['y'].values, encoded_feature)[0][1]\n",
    "    print('Corr between {} and target is: {}'.format(f_ ,np.corrcoef(train_data['y'].values, encoded_feature)[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZNa0PazqGyL"
   },
   "source": [
    "## 3. Smoothing and Noising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "G8osa-K7qGyM",
    "outputId": "23b4f035-d007-4bb3-e16d-0500896bd7e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corr between category_name and target is: 0.44204948101833325\n",
      "Corr between brand_name and target is: 0.4665217775920104\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "Factor = 100\n",
    "global_mean = train_data['y'].mean()\n",
    "noise_level = 0.05 # 可以調整這裡 (standard dev)\n",
    "\n",
    "for f_ in categorical_features:    \n",
    "\n",
    "    train_data['item_target_mean'] = train_data.groupby(f_)['y'].transform('mean')\n",
    "    train_data['target_count'] = train_data.groupby(f_)['y'].transform('count')\n",
    "    train_data['item_target_enc_smg'] = np.multiply(train_data['item_target_mean'] ,train_data['target_count'] ) + global_mean * Factor\n",
    "    train_data['item_target_enc_smg'] = train_data['item_target_enc_smg'] / (train_data['target_count'] + Factor)\n",
    "\n",
    "    encoded_feature = train_data['item_target_enc_smg'].values* (1 + noise_level * np.random.randn(len(train_data)))\n",
    "    \n",
    "    corr = np.corrcoef(train_data['y'].values, encoded_feature)[0][1]\n",
    "    print('Corr between {} and target is: {}'.format(f_ ,np.corrcoef(train_data['y'].values, encoded_feature)[0][1]))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "03_Answer.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
