{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how to generate document vector ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from gensim.models import Doc2Vec, doc2vec\n",
    "from gensim.models import word2vec\n",
    "import random\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "\n",
    "## turn back to main directory\n",
    "os.chdir(\"../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s')\n",
    "logging.root.setLevel(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load 'article_cutted'\n",
    "with open('article_cutted', 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## average word vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-26 02:13:48,627: INFO: loading Word2Vec object from word2vec_model/CBOW\n",
      "2019-02-26 02:13:49,123: INFO: loading wv recursively from word2vec_model/CBOW.wv.* with mmap=None\n",
      "2019-02-26 02:13:49,124: INFO: loading syn0 from word2vec_model/CBOW.wv.syn0.npy with mmap=None\n",
      "2019-02-26 02:13:49,173: INFO: setting ignored attribute syn0norm to None\n",
      "2019-02-26 02:13:49,174: INFO: loading syn1neg from word2vec_model/CBOW.syn1neg.npy with mmap=None\n",
      "2019-02-26 02:13:49,223: INFO: setting ignored attribute cum_table to None\n",
      "2019-02-26 02:13:49,224: INFO: loaded word2vec_model/CBOW\n"
     ]
    }
   ],
   "source": [
    "## load word2vec model\n",
    "model = word2vec.Word2Vec.load('word2vec_model/CBOW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter words that not in word2vec's vocab\n",
    "data_filtered = [[w for w in l if w in model.wv] for l in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute average word vector\n",
    "avg_vector = []\n",
    "\n",
    "for l in data_filtered:\n",
    "    if len(l)==0:\n",
    "        avg_vector.append(np.array([0]*256))\n",
    "    else:\n",
    "        avg_vector.append(np.mean([model.wv[w] for w in l], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.51370144e-01, -2.78773546e-01,  1.24224238e-01, -7.16151416e-01,\n",
       "        1.15960687e-01, -1.52856693e-01,  1.22566722e-01, -7.10553944e-01,\n",
       "        4.90807533e-01,  3.79381895e-01,  2.00905949e-01,  2.79838353e-01,\n",
       "        1.34332359e-01,  3.83681148e-01, -7.02719465e-02, -2.50310719e-01,\n",
       "       -7.68486261e-02, -5.19854367e-01, -1.79893196e-01,  6.64657712e-01,\n",
       "       -4.40292865e-01, -2.77584791e-01, -5.59482463e-02, -5.74376099e-02,\n",
       "       -5.86083889e-01, -2.82081276e-01,  1.44022346e-01, -5.44365406e-01,\n",
       "       -5.62022567e-01, -2.72326022e-01, -1.77528694e-01, -1.55522391e-01,\n",
       "       -3.33025575e-01, -1.29549161e-01, -2.69888163e-01, -7.67731220e-02,\n",
       "       -2.18084052e-01, -1.85102567e-01, -3.73278022e-01,  1.95911378e-01,\n",
       "        8.22586417e-02, -9.60026234e-02,  1.38279945e-01, -4.29557145e-01,\n",
       "       -1.01881586e-01, -3.72718930e-01,  8.86401534e-02,  7.95484722e-01,\n",
       "        1.83235094e-01,  1.84247699e-02,  4.70789552e-01, -1.03564426e-01,\n",
       "        3.68086010e-01, -2.88486421e-01, -2.96178818e-01, -2.98064828e-01,\n",
       "       -6.25927508e-01, -2.76328325e-01,  5.67940548e-02, -1.64256603e-01,\n",
       "       -1.05116069e-01,  2.24227786e-01,  1.07218541e-01,  1.13503315e-01,\n",
       "        4.46511984e-01, -1.94499364e-07, -1.71116684e-02, -4.32818860e-01,\n",
       "        2.15374142e-01,  1.64562359e-01, -8.56854796e-01, -4.06801462e-01,\n",
       "        2.39897333e-02, -8.91800523e-02,  6.28555894e-01, -3.96421254e-01,\n",
       "       -1.88240901e-01, -2.90598959e-01, -4.61903885e-02, -2.58002341e-01,\n",
       "       -3.02503586e-01, -1.66686982e-01, -3.82725954e-01,  4.53982562e-01,\n",
       "        2.39310592e-01,  1.13956690e-01, -6.31436259e-02, -1.66227266e-01,\n",
       "       -1.23505063e-01,  2.81824052e-01, -4.72184390e-01, -5.70128083e-01,\n",
       "        3.29089500e-02,  7.94751644e-01,  2.27249652e-01, -7.46584773e-01,\n",
       "        4.25469637e-01,  2.97492504e-01, -4.00918037e-01, -5.35251275e-02,\n",
       "        5.85594893e-01, -1.17351711e-01,  9.81554016e-02,  4.26307887e-01,\n",
       "       -8.89444724e-02,  4.91914935e-02,  1.17409088e-01, -3.08062524e-01,\n",
       "       -2.30307635e-02, -4.94229972e-01,  9.67176110e-02, -6.17356420e-01,\n",
       "        4.80719209e-01,  2.23763019e-01,  4.14762020e-01, -2.77321339e-01,\n",
       "       -3.23962092e-01,  1.20466046e-01,  1.77954003e-01, -2.42514655e-01,\n",
       "       -2.71784872e-01, -2.11363789e-02, -9.47851166e-02, -1.37828901e-01,\n",
       "        1.40753552e-01,  6.19049847e-01,  3.43604505e-01, -3.59310150e-01,\n",
       "       -1.64877862e-01,  3.96432698e-01, -2.83139348e-01,  2.63268799e-02,\n",
       "        3.09305549e-01, -2.00923998e-02, -2.09751859e-01,  7.58139882e-03,\n",
       "        6.14132404e-01, -8.75932947e-02, -2.47754201e-01, -2.32291594e-01,\n",
       "       -2.41346434e-01, -2.62252331e-01, -2.54366957e-02,  4.92826670e-01,\n",
       "        3.90028089e-01, -2.02338994e-01, -1.59201980e-01, -1.03105478e-01,\n",
       "        1.09007418e-01, -2.77020335e-01, -1.87169343e-01,  1.59042001e-01,\n",
       "       -2.48254269e-01, -1.28011882e-01, -3.67229521e-01, -2.16836303e-01,\n",
       "       -3.16673517e-01, -2.07522497e-01, -2.91541964e-01,  4.88242358e-01,\n",
       "       -2.71051466e-01, -4.30959985e-02, -1.45411983e-01, -4.10767168e-01,\n",
       "       -4.18368667e-01,  3.72313738e-01, -9.00288224e-01,  3.91035944e-01,\n",
       "       -7.72827715e-02, -3.82401445e-03,  8.79718781e-01,  1.32912591e-01,\n",
       "       -1.04594886e-01,  2.03375638e-01, -1.94437318e-02, -3.82409811e-01,\n",
       "       -7.54152238e-02, -1.03280596e-01, -8.67031217e-02,  2.13207200e-01,\n",
       "       -1.39376283e-01,  4.58390415e-02, -3.56432319e-01, -2.98206210e-01,\n",
       "       -1.86709270e-01,  2.75287330e-01,  3.37959379e-01,  3.54775816e-01,\n",
       "        2.27328703e-01, -6.87856257e-01, -2.14039721e-02, -5.29015362e-01,\n",
       "       -5.06805368e-02, -1.95456177e-01,  3.74129832e-01,  3.62920702e-01,\n",
       "        1.93297446e-01,  3.15375775e-02,  5.14697731e-01,  8.28191265e-02,\n",
       "        1.70472354e-01,  7.10235164e-03, -1.96534574e-01,  9.21022594e-02,\n",
       "        2.43693903e-01,  1.18656337e-01, -5.13913203e-03,  3.43831539e-01,\n",
       "       -3.18806887e-01, -6.29571974e-02,  3.89276445e-02,  6.68872818e-02,\n",
       "       -2.47189820e-01, -2.53802240e-01, -3.47542495e-01, -1.90193057e-01,\n",
       "        1.02016609e-02,  4.25259233e-01, -8.90604556e-02,  4.44132745e-01,\n",
       "       -6.43299341e-01, -1.00506544e-01, -3.31528991e-01,  4.81055826e-02,\n",
       "       -1.93429347e-02, -2.05695257e-01,  1.77573338e-01, -6.94274127e-01,\n",
       "       -6.33968830e-01, -2.17164546e-01, -2.93236732e-01, -1.49983838e-01,\n",
       "       -2.24614441e-01, -6.25059366e-01,  3.01842332e-01, -2.16148302e-01,\n",
       "        1.38803437e-01,  1.73823997e-01, -5.06923974e-01, -7.17043430e-02,\n",
       "        5.01473188e-01,  1.59874320e-01,  2.73269355e-01,  2.82919109e-01,\n",
       "       -6.23638332e-01, -7.07845315e-02, -5.12315214e-01, -4.66705896e-02,\n",
       "       -1.42892241e-01, -9.87935439e-02,  3.90892953e-01,  1.03268005e-01,\n",
       "       -4.32723388e-02, -3.10867637e-01,  1.21412918e-01, -7.95980021e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print result\n",
    "avg_vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save result\n",
    "with open('avg_article_vector', 'wb') as file:\n",
    "    pickle.dump(avg_vector, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a document id map\n",
    "sentence_list = []\n",
    "\n",
    "for i, l in enumerate(data):\n",
    "    sentence_list.append(doc2vec.LabeledSentence(words=l, tags=[str(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabeledSentence(words=['韓瑜', '協志', '前妻', '正', '女演員', '周子', '瑜', 'TWICE', '團裡裡面', '台灣', '人', '正', '兩個', '要當', '鄉民', '老婆', '選', '五樓', '真', '勇氣'], tags=['0'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print result\n",
    "sentence_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define 轉換器\n",
    "model = Doc2Vec(size=256, min_count=5, window=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-26 02:14:33,123: INFO: collecting all words and their counts\n",
      "2019-02-26 02:14:33,124: INFO: PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2019-02-26 02:14:33,236: INFO: PROGRESS: at example #10000, processed 450472 words (4041219/s), 62530 word types, 10000 tags\n",
      "2019-02-26 02:14:33,357: INFO: PROGRESS: at example #20000, processed 917994 words (3872718/s), 94798 word types, 20000 tags\n",
      "2019-02-26 02:14:33,474: INFO: PROGRESS: at example #30000, processed 1376864 words (3948272/s), 119647 word types, 30000 tags\n",
      "2019-02-26 02:14:33,595: INFO: PROGRESS: at example #40000, processed 1830843 words (3775518/s), 139918 word types, 40000 tags\n",
      "2019-02-26 02:14:33,720: INFO: PROGRESS: at example #50000, processed 2296622 words (3743697/s), 158826 word types, 50000 tags\n",
      "2019-02-26 02:14:33,849: INFO: PROGRESS: at example #60000, processed 2758111 words (3607322/s), 175445 word types, 60000 tags\n",
      "2019-02-26 02:14:33,969: INFO: PROGRESS: at example #70000, processed 3207991 words (3758926/s), 190133 word types, 70000 tags\n",
      "2019-02-26 02:14:34,096: INFO: PROGRESS: at example #80000, processed 3673394 words (3677536/s), 204929 word types, 80000 tags\n",
      "2019-02-26 02:14:34,224: INFO: PROGRESS: at example #90000, processed 4150285 words (3765208/s), 220178 word types, 90000 tags\n",
      "2019-02-26 02:14:34,342: INFO: PROGRESS: at example #100000, processed 4586170 words (3705821/s), 232949 word types, 100000 tags\n",
      "2019-02-26 02:14:34,464: INFO: PROGRESS: at example #110000, processed 5046757 words (3791183/s), 245237 word types, 110000 tags\n",
      "2019-02-26 02:14:34,584: INFO: PROGRESS: at example #120000, processed 5492090 words (3721060/s), 256501 word types, 120000 tags\n",
      "2019-02-26 02:14:34,706: INFO: PROGRESS: at example #130000, processed 5940297 words (3690174/s), 267710 word types, 130000 tags\n",
      "2019-02-26 02:14:35,378: INFO: PROGRESS: at example #140000, processed 6397077 words (680902/s), 278552 word types, 140000 tags\n",
      "2019-02-26 02:14:35,500: INFO: PROGRESS: at example #150000, processed 6852157 words (3757181/s), 289207 word types, 150000 tags\n",
      "2019-02-26 02:14:35,635: INFO: PROGRESS: at example #160000, processed 7314121 words (3431442/s), 300645 word types, 160000 tags\n",
      "2019-02-26 02:14:35,763: INFO: PROGRESS: at example #170000, processed 7778365 words (3633153/s), 311065 word types, 170000 tags\n",
      "2019-02-26 02:14:35,900: INFO: PROGRESS: at example #180000, processed 8243928 words (3417245/s), 321562 word types, 180000 tags\n",
      "2019-02-26 02:14:36,035: INFO: PROGRESS: at example #190000, processed 8694493 words (3349216/s), 331279 word types, 190000 tags\n",
      "2019-02-26 02:14:36,160: INFO: PROGRESS: at example #200000, processed 9139086 words (3582233/s), 340145 word types, 200000 tags\n",
      "2019-02-26 02:14:36,286: INFO: PROGRESS: at example #210000, processed 9593110 words (3630673/s), 349116 word types, 210000 tags\n",
      "2019-02-26 02:14:36,436: INFO: PROGRESS: at example #220000, processed 10070866 words (3195455/s), 358685 word types, 220000 tags\n",
      "2019-02-26 02:14:36,571: INFO: PROGRESS: at example #230000, processed 10553199 words (3606052/s), 368027 word types, 230000 tags\n",
      "2019-02-26 02:14:36,703: INFO: PROGRESS: at example #240000, processed 11016363 words (3508167/s), 376775 word types, 240000 tags\n",
      "2019-02-26 02:14:36,832: INFO: PROGRESS: at example #250000, processed 11477995 words (3599627/s), 385906 word types, 250000 tags\n",
      "2019-02-26 02:14:36,862: INFO: collected 388118 word types and 252229 unique tags from a corpus of 252229 examples and 11587581 words\n",
      "2019-02-26 02:14:36,863: INFO: Loading a fresh vocabulary\n",
      "2019-02-26 02:14:37,156: INFO: min_count=5 retains 100034 unique words (25% of original 388118, drops 288084)\n",
      "2019-02-26 02:14:37,156: INFO: min_count=5 leaves 11155104 word corpus (96% of original 11587581, drops 432477)\n",
      "2019-02-26 02:14:37,408: INFO: deleting the raw counts dictionary of 388118 items\n",
      "2019-02-26 02:14:37,417: INFO: sample=0.001 downsamples 18 most-common words\n",
      "2019-02-26 02:14:37,418: INFO: downsampling leaves estimated 10810274 word corpus (96.9% of prior 11155104)\n",
      "2019-02-26 02:14:37,419: INFO: estimated required memory for 100034 words and 256 dimensions: 563614928 bytes\n",
      "2019-02-26 02:14:37,720: INFO: resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "## build vocabulary\n",
    "model.build_vocab(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-26 02:14:42,121: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:14:43,137: INFO: PROGRESS: at 4.34% examples, 484407 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:14:44,138: INFO: PROGRESS: at 8.53% examples, 474107 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:14:45,144: INFO: PROGRESS: at 13.09% examples, 483130 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:14:46,154: INFO: PROGRESS: at 17.70% examples, 488678 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:14:47,165: INFO: PROGRESS: at 22.42% examples, 494228 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:14:48,178: INFO: PROGRESS: at 27.16% examples, 499416 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:14:49,182: INFO: PROGRESS: at 31.96% examples, 503682 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:14:50,200: INFO: PROGRESS: at 36.72% examples, 505822 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:14:51,227: INFO: PROGRESS: at 41.64% examples, 508378 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:14:52,232: INFO: PROGRESS: at 46.57% examples, 510577 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:14:53,248: INFO: PROGRESS: at 51.41% examples, 512615 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:14:54,261: INFO: PROGRESS: at 56.33% examples, 513830 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:14:55,277: INFO: PROGRESS: at 61.24% examples, 515210 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:14:56,286: INFO: PROGRESS: at 66.25% examples, 517506 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:14:57,289: INFO: PROGRESS: at 71.08% examples, 518822 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:14:58,291: INFO: PROGRESS: at 75.98% examples, 520641 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:14:59,295: INFO: PROGRESS: at 80.95% examples, 521758 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:00,315: INFO: PROGRESS: at 85.95% examples, 522803 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:01,331: INFO: PROGRESS: at 90.95% examples, 523845 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:02,337: INFO: PROGRESS: at 95.85% examples, 524919 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:03,157: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:15:03,172: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:15:03,177: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:15:03,177: INFO: training on 11587581 raw words (11062977 effective words) took 21.0s, 525571 effective words/s\n",
      "2019-02-26 02:15:03,391: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:15:04,405: INFO: PROGRESS: at 4.66% examples, 508561 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:05,409: INFO: PROGRESS: at 9.41% examples, 518321 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:06,414: INFO: PROGRESS: at 13.91% examples, 512108 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:07,427: INFO: PROGRESS: at 18.55% examples, 512905 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:08,440: INFO: PROGRESS: at 23.24% examples, 513082 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:09,442: INFO: PROGRESS: at 28.06% examples, 514428 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:10,452: INFO: PROGRESS: at 32.86% examples, 515925 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:11,460: INFO: PROGRESS: at 37.60% examples, 516314 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:12,476: INFO: PROGRESS: at 42.40% examples, 517067 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:13,483: INFO: PROGRESS: at 47.21% examples, 518136 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:14,492: INFO: PROGRESS: at 52.12% examples, 519719 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:15,494: INFO: PROGRESS: at 56.93% examples, 520584 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:16,520: INFO: PROGRESS: at 61.84% examples, 521101 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:17,522: INFO: PROGRESS: at 66.69% examples, 521836 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:18,525: INFO: PROGRESS: at 71.65% examples, 523575 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:19,562: INFO: PROGRESS: at 76.58% examples, 524036 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:20,576: INFO: PROGRESS: at 81.59% examples, 525156 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:21,577: INFO: PROGRESS: at 86.65% examples, 527007 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:22,585: INFO: PROGRESS: at 91.45% examples, 527036 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:23,587: INFO: PROGRESS: at 96.31% examples, 527706 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:24,323: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:15:24,332: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:15:24,345: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:15:24,346: INFO: training on 11587581 raw words (11063331 effective words) took 20.9s, 528087 effective words/s\n",
      "2019-02-26 02:15:24,560: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:15:25,578: INFO: PROGRESS: at 4.85% examples, 534146 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:26,581: INFO: PROGRESS: at 9.63% examples, 527175 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:27,590: INFO: PROGRESS: at 14.35% examples, 526699 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:28,595: INFO: PROGRESS: at 19.08% examples, 522354 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:29,614: INFO: PROGRESS: at 23.89% examples, 522365 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:30,641: INFO: PROGRESS: at 28.68% examples, 520327 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:31,649: INFO: PROGRESS: at 33.43% examples, 522043 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:32,653: INFO: PROGRESS: at 38.20% examples, 521909 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:33,659: INFO: PROGRESS: at 42.98% examples, 522607 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:34,678: INFO: PROGRESS: at 47.82% examples, 523244 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:35,702: INFO: PROGRESS: at 52.66% examples, 522831 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:36,718: INFO: PROGRESS: at 57.62% examples, 523760 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:37,728: INFO: PROGRESS: at 62.48% examples, 524577 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:38,747: INFO: PROGRESS: at 67.39% examples, 525058 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:39,749: INFO: PROGRESS: at 72.24% examples, 525506 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:40,755: INFO: PROGRESS: at 77.11% examples, 525682 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:41,775: INFO: PROGRESS: at 82.07% examples, 526561 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:42,784: INFO: PROGRESS: at 86.99% examples, 527372 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:43,799: INFO: PROGRESS: at 91.82% examples, 527613 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:44,808: INFO: PROGRESS: at 96.65% examples, 527625 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:45,482: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:15:45,500: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:15:45,501: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:15:45,501: INFO: training on 11587581 raw words (11062574 effective words) took 20.9s, 528381 effective words/s\n",
      "2019-02-26 02:15:45,722: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:15:46,759: INFO: PROGRESS: at 4.88% examples, 513809 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:47,791: INFO: PROGRESS: at 9.66% examples, 513575 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:48,811: INFO: PROGRESS: at 14.46% examples, 515881 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:49,821: INFO: PROGRESS: at 19.30% examples, 518675 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:50,827: INFO: PROGRESS: at 24.06% examples, 520728 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:51,852: INFO: PROGRESS: at 28.96% examples, 521800 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:52,855: INFO: PROGRESS: at 33.74% examples, 522787 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:53,862: INFO: PROGRESS: at 38.49% examples, 523329 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:54,870: INFO: PROGRESS: at 43.42% examples, 524844 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:55,893: INFO: PROGRESS: at 48.33% examples, 524344 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:15:56,898: INFO: PROGRESS: at 53.09% examples, 524720 words/s, in_qsize 6, out_qsize 1\n",
      "2019-02-26 02:15:57,900: INFO: PROGRESS: at 57.93% examples, 525895 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:58,904: INFO: PROGRESS: at 62.74% examples, 525828 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:15:59,906: INFO: PROGRESS: at 67.49% examples, 526209 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:00,907: INFO: PROGRESS: at 72.34% examples, 527192 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:01,918: INFO: PROGRESS: at 77.08% examples, 527031 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:02,922: INFO: PROGRESS: at 82.09% examples, 528634 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:03,945: INFO: PROGRESS: at 86.88% examples, 528522 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:04,959: INFO: PROGRESS: at 91.79% examples, 528730 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:05,971: INFO: PROGRESS: at 96.71% examples, 528735 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:06,609: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:16:06,614: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:16:06,622: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:16:06,623: INFO: training on 11587581 raw words (11062552 effective words) took 20.9s, 529406 effective words/s\n",
      "2019-02-26 02:16:06,831: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:16:07,836: INFO: PROGRESS: at 4.69% examples, 520424 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:08,855: INFO: PROGRESS: at 9.59% examples, 524121 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:09,864: INFO: PROGRESS: at 14.22% examples, 519436 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:10,889: INFO: PROGRESS: at 18.91% examples, 514731 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:11,896: INFO: PROGRESS: at 23.64% examples, 516206 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:12,907: INFO: PROGRESS: at 28.38% examples, 517137 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:13,932: INFO: PROGRESS: at 33.10% examples, 515929 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:14,954: INFO: PROGRESS: at 37.96% examples, 516642 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:15,976: INFO: PROGRESS: at 42.77% examples, 517088 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:16,981: INFO: PROGRESS: at 47.57% examples, 519047 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:17,991: INFO: PROGRESS: at 52.33% examples, 518901 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:19,009: INFO: PROGRESS: at 57.08% examples, 518448 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:20,020: INFO: PROGRESS: at 61.88% examples, 518920 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:21,036: INFO: PROGRESS: at 66.72% examples, 519889 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:22,039: INFO: PROGRESS: at 71.46% examples, 520543 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:23,046: INFO: PROGRESS: at 76.24% examples, 520976 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:24,060: INFO: PROGRESS: at 81.00% examples, 521729 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:25,094: INFO: PROGRESS: at 86.01% examples, 522399 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:26,105: INFO: PROGRESS: at 90.94% examples, 522604 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:27,113: INFO: PROGRESS: at 95.88% examples, 523296 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:27,944: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:16:27,959: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:16:27,960: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:16:27,961: INFO: training on 11587581 raw words (11062615 effective words) took 21.1s, 523661 effective words/s\n",
      "2019-02-26 02:16:28,174: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:16:29,182: INFO: PROGRESS: at 4.60% examples, 510667 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:30,187: INFO: PROGRESS: at 9.27% examples, 514823 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:31,204: INFO: PROGRESS: at 13.88% examples, 511173 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:32,216: INFO: PROGRESS: at 18.63% examples, 512887 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:33,226: INFO: PROGRESS: at 23.50% examples, 515868 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:34,238: INFO: PROGRESS: at 28.27% examples, 517452 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:35,247: INFO: PROGRESS: at 33.08% examples, 518741 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:36,258: INFO: PROGRESS: at 37.98% examples, 520675 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:37,294: INFO: PROGRESS: at 42.82% examples, 521727 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:38,294: INFO: PROGRESS: at 47.64% examples, 522571 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:39,298: INFO: PROGRESS: at 52.51% examples, 523213 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:40,304: INFO: PROGRESS: at 57.33% examples, 523719 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:41,308: INFO: PROGRESS: at 62.22% examples, 524228 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:42,322: INFO: PROGRESS: at 67.08% examples, 524837 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:43,326: INFO: PROGRESS: at 71.93% examples, 525692 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:44,356: INFO: PROGRESS: at 76.90% examples, 525811 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:45,393: INFO: PROGRESS: at 81.93% examples, 526071 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:46,411: INFO: PROGRESS: at 86.75% examples, 526704 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:47,430: INFO: PROGRESS: at 91.64% examples, 526971 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:48,437: INFO: PROGRESS: at 96.71% examples, 527970 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:49,075: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:16:49,088: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:16:49,098: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:16:49,099: INFO: training on 11587581 raw words (11062659 effective words) took 20.9s, 528802 effective words/s\n",
      "2019-02-26 02:16:49,333: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:16:50,361: INFO: PROGRESS: at 4.68% examples, 516890 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:51,366: INFO: PROGRESS: at 9.23% examples, 504745 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:52,401: INFO: PROGRESS: at 13.91% examples, 498978 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:53,413: INFO: PROGRESS: at 18.60% examples, 498315 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:54,449: INFO: PROGRESS: at 23.11% examples, 497300 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:55,452: INFO: PROGRESS: at 27.88% examples, 501236 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:56,466: INFO: PROGRESS: at 32.58% examples, 502303 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:16:57,471: INFO: PROGRESS: at 37.33% examples, 504543 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:58,499: INFO: PROGRESS: at 42.18% examples, 506755 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:16:59,530: INFO: PROGRESS: at 46.98% examples, 508653 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:00,546: INFO: PROGRESS: at 51.85% examples, 510749 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:01,549: INFO: PROGRESS: at 56.66% examples, 512206 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:02,570: INFO: PROGRESS: at 61.53% examples, 512958 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:03,610: INFO: PROGRESS: at 66.42% examples, 513469 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:04,614: INFO: PROGRESS: at 71.22% examples, 514854 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:05,647: INFO: PROGRESS: at 75.96% examples, 515196 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:06,656: INFO: PROGRESS: at 80.86% examples, 516447 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:07,662: INFO: PROGRESS: at 85.75% examples, 517579 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:08,669: INFO: PROGRESS: at 90.52% examples, 518125 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:09,687: INFO: PROGRESS: at 95.43% examples, 518763 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:10,610: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:17:10,612: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:17:10,622: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:17:10,622: INFO: training on 11587581 raw words (11062418 effective words) took 21.3s, 519723 effective words/s\n",
      "2019-02-26 02:17:10,840: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:17:11,865: INFO: PROGRESS: at 4.68% examples, 512442 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:12,868: INFO: PROGRESS: at 9.30% examples, 521091 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:13,873: INFO: PROGRESS: at 13.87% examples, 517036 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:14,892: INFO: PROGRESS: at 18.60% examples, 513814 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:15,917: INFO: PROGRESS: at 23.23% examples, 510974 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:16,920: INFO: PROGRESS: at 28.02% examples, 512746 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:17,935: INFO: PROGRESS: at 32.69% examples, 512267 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:18,945: INFO: PROGRESS: at 37.42% examples, 512856 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:19,957: INFO: PROGRESS: at 42.22% examples, 513365 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:20,963: INFO: PROGRESS: at 47.04% examples, 514629 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:21,980: INFO: PROGRESS: at 51.81% examples, 515418 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:22,981: INFO: PROGRESS: at 56.52% examples, 515992 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:24,012: INFO: PROGRESS: at 61.28% examples, 516428 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:25,028: INFO: PROGRESS: at 66.02% examples, 516894 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:26,073: INFO: PROGRESS: at 71.02% examples, 516950 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:27,094: INFO: PROGRESS: at 75.94% examples, 517755 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:28,138: INFO: PROGRESS: at 80.88% examples, 517798 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:29,145: INFO: PROGRESS: at 85.64% examples, 518418 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:30,167: INFO: PROGRESS: at 90.57% examples, 519064 words/s, in_qsize 6, out_qsize 1\n",
      "2019-02-26 02:17:31,185: INFO: PROGRESS: at 95.53% examples, 519737 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:32,083: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:17:32,091: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:17:32,105: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:17:32,105: INFO: training on 11587581 raw words (11061737 effective words) took 21.3s, 520311 effective words/s\n",
      "2019-02-26 02:17:32,316: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:17:33,334: INFO: PROGRESS: at 4.92% examples, 532927 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:34,345: INFO: PROGRESS: at 9.75% examples, 529280 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:35,372: INFO: PROGRESS: at 14.46% examples, 522890 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:36,384: INFO: PROGRESS: at 19.10% examples, 520482 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:37,399: INFO: PROGRESS: at 23.73% examples, 517414 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:38,411: INFO: PROGRESS: at 28.73% examples, 522400 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:39,421: INFO: PROGRESS: at 33.68% examples, 525721 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:40,423: INFO: PROGRESS: at 38.63% examples, 527602 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:41,429: INFO: PROGRESS: at 43.65% examples, 529854 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:42,444: INFO: PROGRESS: at 48.66% examples, 531895 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:43,447: INFO: PROGRESS: at 53.65% examples, 532666 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:44,479: INFO: PROGRESS: at 58.51% examples, 532010 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:45,508: INFO: PROGRESS: at 63.32% examples, 530797 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:46,509: INFO: PROGRESS: at 68.27% examples, 531471 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:47,514: INFO: PROGRESS: at 73.18% examples, 531800 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:48,555: INFO: PROGRESS: at 78.23% examples, 532560 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:49,571: INFO: PROGRESS: at 83.23% examples, 533517 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:50,576: INFO: PROGRESS: at 88.23% examples, 534258 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:51,586: INFO: PROGRESS: at 93.22% examples, 534855 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:52,588: INFO: PROGRESS: at 98.14% examples, 535590 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:52,942: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:17:52,961: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:17:52,966: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:17:52,966: INFO: training on 11587581 raw words (11062448 effective words) took 20.6s, 535822 effective words/s\n",
      "2019-02-26 02:17:53,180: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:17:54,193: INFO: PROGRESS: at 4.78% examples, 526444 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:55,226: INFO: PROGRESS: at 9.74% examples, 525149 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:56,229: INFO: PROGRESS: at 14.41% examples, 520622 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:17:57,242: INFO: PROGRESS: at 19.19% examples, 519523 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:58,244: INFO: PROGRESS: at 23.83% examples, 519284 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:17:59,272: INFO: PROGRESS: at 28.65% examples, 518991 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:00,294: INFO: PROGRESS: at 33.51% examples, 519200 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:01,312: INFO: PROGRESS: at 38.41% examples, 520661 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:02,312: INFO: PROGRESS: at 43.11% examples, 521452 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:03,316: INFO: PROGRESS: at 47.81% examples, 522118 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:04,334: INFO: PROGRESS: at 52.68% examples, 521446 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:05,361: INFO: PROGRESS: at 57.56% examples, 522008 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:06,379: INFO: PROGRESS: at 62.48% examples, 522050 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:07,386: INFO: PROGRESS: at 67.13% examples, 522192 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:08,387: INFO: PROGRESS: at 71.95% examples, 522766 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:09,400: INFO: PROGRESS: at 76.74% examples, 523927 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:10,410: INFO: PROGRESS: at 81.64% examples, 524059 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:11,433: INFO: PROGRESS: at 86.60% examples, 524424 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:12,441: INFO: PROGRESS: at 91.35% examples, 524482 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:13,448: INFO: PROGRESS: at 96.21% examples, 525101 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:14,195: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:18:14,215: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:18:14,228: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:18:14,229: INFO: training on 11587581 raw words (11063049 effective words) took 21.0s, 525717 effective words/s\n",
      "2019-02-26 02:18:14,435: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:18:15,449: INFO: PROGRESS: at 4.80% examples, 533357 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:16,453: INFO: PROGRESS: at 9.47% examples, 525880 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:17,491: INFO: PROGRESS: at 14.29% examples, 520362 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:18,500: INFO: PROGRESS: at 19.06% examples, 519967 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:19,501: INFO: PROGRESS: at 23.71% examples, 521548 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:20,520: INFO: PROGRESS: at 28.51% examples, 520096 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:21,524: INFO: PROGRESS: at 33.25% examples, 520135 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:22,539: INFO: PROGRESS: at 37.99% examples, 519299 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:23,551: INFO: PROGRESS: at 42.75% examples, 519964 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:24,558: INFO: PROGRESS: at 47.55% examples, 519937 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:25,566: INFO: PROGRESS: at 52.32% examples, 520584 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:26,580: INFO: PROGRESS: at 57.18% examples, 520722 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:27,595: INFO: PROGRESS: at 62.09% examples, 521726 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:28,598: INFO: PROGRESS: at 66.81% examples, 521629 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:29,609: INFO: PROGRESS: at 71.66% examples, 522442 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:30,616: INFO: PROGRESS: at 76.49% examples, 523318 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:31,632: INFO: PROGRESS: at 81.28% examples, 523261 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:32,633: INFO: PROGRESS: at 85.99% examples, 523160 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:33,635: INFO: PROGRESS: at 90.93% examples, 524011 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:34,640: INFO: PROGRESS: at 95.77% examples, 524281 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:35,496: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:18:35,506: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:18:35,520: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:18:35,520: INFO: training on 11587581 raw words (11062231 effective words) took 21.1s, 524715 effective words/s\n",
      "2019-02-26 02:18:35,732: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:18:36,740: INFO: PROGRESS: at 4.77% examples, 527144 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:37,756: INFO: PROGRESS: at 9.56% examples, 524757 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:38,774: INFO: PROGRESS: at 14.24% examples, 522649 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:39,783: INFO: PROGRESS: at 19.00% examples, 521410 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:40,809: INFO: PROGRESS: at 23.71% examples, 520194 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:41,820: INFO: PROGRESS: at 28.51% examples, 520160 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:42,845: INFO: PROGRESS: at 33.18% examples, 519576 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:43,880: INFO: PROGRESS: at 38.02% examples, 520114 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:44,898: INFO: PROGRESS: at 42.99% examples, 522240 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:45,902: INFO: PROGRESS: at 47.78% examples, 522916 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:46,903: INFO: PROGRESS: at 52.61% examples, 523685 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:47,905: INFO: PROGRESS: at 57.31% examples, 523362 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:48,909: INFO: PROGRESS: at 61.82% examples, 521069 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:49,924: INFO: PROGRESS: at 66.61% examples, 520716 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:50,946: INFO: PROGRESS: at 71.49% examples, 521355 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:51,949: INFO: PROGRESS: at 76.38% examples, 521893 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:52,983: INFO: PROGRESS: at 81.39% examples, 522069 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:53,997: INFO: PROGRESS: at 86.22% examples, 522534 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:54,999: INFO: PROGRESS: at 91.11% examples, 523505 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:18:56,009: INFO: PROGRESS: at 95.89% examples, 523197 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:56,833: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:18:56,843: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:18:56,843: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:18:56,844: INFO: training on 11587581 raw words (11062103 effective words) took 21.1s, 524072 effective words/s\n",
      "2019-02-26 02:18:57,056: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:18:58,076: INFO: PROGRESS: at 4.88% examples, 537264 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:18:59,088: INFO: PROGRESS: at 9.57% examples, 527322 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:00,110: INFO: PROGRESS: at 14.20% examples, 521884 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:01,120: INFO: PROGRESS: at 19.04% examples, 523219 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:02,124: INFO: PROGRESS: at 23.74% examples, 522429 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:03,146: INFO: PROGRESS: at 27.76% examples, 507710 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:04,158: INFO: PROGRESS: at 32.55% examples, 509893 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:05,164: INFO: PROGRESS: at 37.16% examples, 510655 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:06,175: INFO: PROGRESS: at 42.02% examples, 512452 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:07,177: INFO: PROGRESS: at 46.73% examples, 512336 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:08,193: INFO: PROGRESS: at 51.68% examples, 514198 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:09,217: INFO: PROGRESS: at 56.60% examples, 516016 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:10,220: INFO: PROGRESS: at 61.44% examples, 516985 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:11,229: INFO: PROGRESS: at 66.16% examples, 517715 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:12,237: INFO: PROGRESS: at 70.99% examples, 518407 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:13,266: INFO: PROGRESS: at 75.83% examples, 518926 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:14,267: INFO: PROGRESS: at 80.63% examples, 519208 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:15,282: INFO: PROGRESS: at 85.57% examples, 520268 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:16,298: INFO: PROGRESS: at 90.44% examples, 520446 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:17,306: INFO: PROGRESS: at 95.37% examples, 521334 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:18,250: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:19:18,268: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:19:18,282: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:19:18,283: INFO: training on 11587581 raw words (11062085 effective words) took 21.2s, 521253 effective words/s\n",
      "2019-02-26 02:19:18,496: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:19:19,536: INFO: PROGRESS: at 4.91% examples, 529872 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:20,540: INFO: PROGRESS: at 9.81% examples, 530577 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:21,544: INFO: PROGRESS: at 14.34% examples, 523720 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:22,566: INFO: PROGRESS: at 19.11% examples, 518487 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:23,594: INFO: PROGRESS: at 23.88% examples, 518216 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:24,615: INFO: PROGRESS: at 28.68% examples, 518654 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:25,621: INFO: PROGRESS: at 33.53% examples, 519718 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:26,642: INFO: PROGRESS: at 38.21% examples, 520026 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:27,661: INFO: PROGRESS: at 42.99% examples, 519775 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:28,668: INFO: PROGRESS: at 47.72% examples, 519751 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:29,675: INFO: PROGRESS: at 52.51% examples, 520545 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:30,676: INFO: PROGRESS: at 57.35% examples, 522687 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:31,678: INFO: PROGRESS: at 62.15% examples, 523087 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:32,696: INFO: PROGRESS: at 67.03% examples, 523085 words/s, in_qsize 5, out_qsize 1\n",
      "2019-02-26 02:19:33,697: INFO: PROGRESS: at 71.92% examples, 524243 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:34,722: INFO: PROGRESS: at 76.76% examples, 523895 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:35,763: INFO: PROGRESS: at 81.85% examples, 524720 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:36,767: INFO: PROGRESS: at 86.76% examples, 525490 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:37,771: INFO: PROGRESS: at 91.64% examples, 526059 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:38,792: INFO: PROGRESS: at 96.40% examples, 525803 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:39,501: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:19:39,504: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:19:39,520: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:19:39,521: INFO: training on 11587581 raw words (11061891 effective words) took 21.0s, 526216 effective words/s\n",
      "2019-02-26 02:19:39,733: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:19:40,744: INFO: PROGRESS: at 4.84% examples, 529146 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:41,750: INFO: PROGRESS: at 9.63% examples, 527938 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:42,760: INFO: PROGRESS: at 14.27% examples, 523185 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:43,775: INFO: PROGRESS: at 18.89% examples, 518445 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:44,778: INFO: PROGRESS: at 23.56% examples, 516806 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:45,786: INFO: PROGRESS: at 28.43% examples, 517191 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:46,809: INFO: PROGRESS: at 33.13% examples, 516391 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:47,835: INFO: PROGRESS: at 38.02% examples, 516687 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:48,844: INFO: PROGRESS: at 42.84% examples, 517910 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:49,856: INFO: PROGRESS: at 47.65% examples, 517835 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:50,875: INFO: PROGRESS: at 52.38% examples, 518190 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:51,892: INFO: PROGRESS: at 57.25% examples, 519274 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:52,892: INFO: PROGRESS: at 62.07% examples, 520217 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:53,894: INFO: PROGRESS: at 66.81% examples, 520343 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:54,916: INFO: PROGRESS: at 71.73% examples, 521060 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:55,922: INFO: PROGRESS: at 76.53% examples, 521616 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:19:56,930: INFO: PROGRESS: at 81.32% examples, 521956 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:57,962: INFO: PROGRESS: at 86.28% examples, 522604 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:19:58,988: INFO: PROGRESS: at 91.12% examples, 523213 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:00,012: INFO: PROGRESS: at 96.15% examples, 523884 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:00,807: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:20:00,816: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:20:00,824: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:20:00,825: INFO: training on 11587581 raw words (11063320 effective words) took 21.1s, 524644 effective words/s\n",
      "2019-02-26 02:20:01,043: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:20:02,051: INFO: PROGRESS: at 4.67% examples, 527327 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:03,053: INFO: PROGRESS: at 9.41% examples, 528825 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:04,062: INFO: PROGRESS: at 14.20% examples, 524946 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:05,074: INFO: PROGRESS: at 18.95% examples, 525062 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:06,091: INFO: PROGRESS: at 23.85% examples, 524621 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:07,104: INFO: PROGRESS: at 28.70% examples, 524788 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:08,115: INFO: PROGRESS: at 33.62% examples, 526304 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:09,124: INFO: PROGRESS: at 38.52% examples, 526562 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:10,154: INFO: PROGRESS: at 43.47% examples, 526382 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:11,159: INFO: PROGRESS: at 48.38% examples, 528217 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:12,184: INFO: PROGRESS: at 53.09% examples, 526996 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:13,198: INFO: PROGRESS: at 58.08% examples, 527574 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:14,220: INFO: PROGRESS: at 62.93% examples, 528318 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:15,251: INFO: PROGRESS: at 67.88% examples, 528072 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:16,259: INFO: PROGRESS: at 72.77% examples, 528014 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:17,264: INFO: PROGRESS: at 77.61% examples, 528662 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:18,269: INFO: PROGRESS: at 82.51% examples, 528761 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:19,288: INFO: PROGRESS: at 87.34% examples, 528830 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:20,291: INFO: PROGRESS: at 92.14% examples, 529387 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:21,302: INFO: PROGRESS: at 96.92% examples, 529550 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:21,905: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:20:21,907: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:20:21,908: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:20:21,909: INFO: training on 11587581 raw words (11063011 effective words) took 20.9s, 530295 effective words/s\n",
      "2019-02-26 02:20:22,131: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:20:23,150: INFO: PROGRESS: at 4.88% examples, 524936 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:24,174: INFO: PROGRESS: at 9.36% examples, 504270 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:25,183: INFO: PROGRESS: at 14.14% examples, 508833 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:26,184: INFO: PROGRESS: at 18.80% examples, 512161 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:27,191: INFO: PROGRESS: at 23.42% examples, 509526 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:28,196: INFO: PROGRESS: at 28.14% examples, 511056 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:29,199: INFO: PROGRESS: at 32.89% examples, 514413 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:30,213: INFO: PROGRESS: at 37.62% examples, 515495 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:31,237: INFO: PROGRESS: at 42.44% examples, 515926 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:32,280: INFO: PROGRESS: at 47.27% examples, 515768 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:33,282: INFO: PROGRESS: at 52.06% examples, 516336 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:34,294: INFO: PROGRESS: at 56.84% examples, 517815 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:35,305: INFO: PROGRESS: at 61.75% examples, 519085 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:36,331: INFO: PROGRESS: at 66.64% examples, 519066 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:37,347: INFO: PROGRESS: at 71.41% examples, 519857 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:38,375: INFO: PROGRESS: at 76.27% examples, 520339 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:39,394: INFO: PROGRESS: at 81.24% examples, 521076 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:40,403: INFO: PROGRESS: at 86.01% examples, 521397 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:41,411: INFO: PROGRESS: at 90.94% examples, 521750 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:42,428: INFO: PROGRESS: at 95.75% examples, 522274 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:43,251: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:20:43,275: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:20:43,278: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:20:43,278: INFO: training on 11587581 raw words (11062636 effective words) took 21.1s, 523245 effective words/s\n",
      "2019-02-26 02:20:43,494: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:20:44,515: INFO: PROGRESS: at 4.67% examples, 513202 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:45,526: INFO: PROGRESS: at 9.37% examples, 515164 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:46,528: INFO: PROGRESS: at 14.08% examples, 517317 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:47,555: INFO: PROGRESS: at 18.86% examples, 518595 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:48,595: INFO: PROGRESS: at 23.68% examples, 519151 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:49,596: INFO: PROGRESS: at 28.52% examples, 521130 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:50,602: INFO: PROGRESS: at 33.14% examples, 521239 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:51,641: INFO: PROGRESS: at 38.19% examples, 521416 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:52,647: INFO: PROGRESS: at 43.16% examples, 523925 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:53,655: INFO: PROGRESS: at 48.05% examples, 524291 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:54,666: INFO: PROGRESS: at 52.96% examples, 525291 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:55,684: INFO: PROGRESS: at 57.81% examples, 525761 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:56,703: INFO: PROGRESS: at 62.58% examples, 525383 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:20:57,729: INFO: PROGRESS: at 67.65% examples, 526225 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:58,738: INFO: PROGRESS: at 72.62% examples, 527534 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:20:59,747: INFO: PROGRESS: at 77.57% examples, 528611 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:00,783: INFO: PROGRESS: at 82.68% examples, 529383 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:01,813: INFO: PROGRESS: at 87.75% examples, 529750 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:21:02,820: INFO: PROGRESS: at 92.70% examples, 530565 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:21:03,835: INFO: PROGRESS: at 97.67% examples, 531191 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:04,278: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:21:04,281: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:21:04,302: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:21:04,303: INFO: training on 11587581 raw words (11062113 effective words) took 20.8s, 531705 effective words/s\n",
      "2019-02-26 02:21:04,517: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:21:05,537: INFO: PROGRESS: at 4.61% examples, 495655 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:06,539: INFO: PROGRESS: at 9.19% examples, 503147 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:07,552: INFO: PROGRESS: at 13.95% examples, 507271 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:21:08,580: INFO: PROGRESS: at 18.89% examples, 510142 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:09,601: INFO: PROGRESS: at 23.73% examples, 512420 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:21:10,609: INFO: PROGRESS: at 28.49% examples, 514894 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:11,625: INFO: PROGRESS: at 33.36% examples, 516072 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:12,653: INFO: PROGRESS: at 38.20% examples, 519173 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:13,654: INFO: PROGRESS: at 42.99% examples, 521255 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:14,662: INFO: PROGRESS: at 47.77% examples, 522389 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:15,666: INFO: PROGRESS: at 52.75% examples, 524819 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:16,681: INFO: PROGRESS: at 57.56% examples, 523906 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:21:17,696: INFO: PROGRESS: at 62.52% examples, 524631 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:18,702: INFO: PROGRESS: at 67.33% examples, 524943 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:19,707: INFO: PROGRESS: at 72.21% examples, 525730 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:20,724: INFO: PROGRESS: at 77.03% examples, 525567 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:21:21,737: INFO: PROGRESS: at 81.86% examples, 526383 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:22,750: INFO: PROGRESS: at 86.75% examples, 526365 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:23,751: INFO: PROGRESS: at 91.65% examples, 527106 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:24,789: INFO: PROGRESS: at 96.45% examples, 526316 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:25,489: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:21:25,500: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:21:25,512: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:21:25,512: INFO: training on 11587581 raw words (11063289 effective words) took 21.0s, 527056 effective words/s\n",
      "2019-02-26 02:21:25,723: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-02-26 02:21:26,746: INFO: PROGRESS: at 4.84% examples, 530690 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:27,761: INFO: PROGRESS: at 9.62% examples, 527268 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:21:28,767: INFO: PROGRESS: at 14.22% examples, 518504 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:29,772: INFO: PROGRESS: at 18.81% examples, 514141 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:21:30,781: INFO: PROGRESS: at 23.45% examples, 513231 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:31,793: INFO: PROGRESS: at 28.21% examples, 513720 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:32,809: INFO: PROGRESS: at 33.16% examples, 516407 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:33,823: INFO: PROGRESS: at 37.98% examples, 516326 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:21:34,825: INFO: PROGRESS: at 42.76% examples, 516916 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:35,831: INFO: PROGRESS: at 47.62% examples, 519305 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:21:36,837: INFO: PROGRESS: at 52.43% examples, 520816 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:21:37,841: INFO: PROGRESS: at 57.25% examples, 522124 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:21:38,854: INFO: PROGRESS: at 62.10% examples, 522325 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:21:39,873: INFO: PROGRESS: at 66.95% examples, 522622 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:40,906: INFO: PROGRESS: at 71.90% examples, 523968 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:41,919: INFO: PROGRESS: at 76.78% examples, 524577 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:21:42,928: INFO: PROGRESS: at 81.59% examples, 525045 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:43,957: INFO: PROGRESS: at 86.48% examples, 525053 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:21:44,971: INFO: PROGRESS: at 91.47% examples, 525584 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:21:45,986: INFO: PROGRESS: at 96.36% examples, 526349 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:21:46,689: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:21:46,711: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:21:46,720: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:21:46,721: INFO: training on 11587581 raw words (11062575 effective words) took 21.0s, 526941 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# train word2vec model ; shuffle data every epoch\n",
    "for i in range(20):\n",
    "    random.shuffle(sentence_list)\n",
    "    model.train(sentence_list, total_examples=len(data), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22980718,  0.00789416,  0.02035779,  0.04185508, -0.00514967,\n",
       "        0.1128194 , -0.07855923, -0.08681118,  0.01257118,  0.06460056,\n",
       "       -0.0582304 ,  0.09075426, -0.2722956 , -0.06693779, -0.09495676,\n",
       "       -0.01310479, -0.08950269,  0.09734064, -0.11864288,  0.15712133,\n",
       "        0.04746243, -0.04436997, -0.2408271 ,  0.06401458, -0.12367046,\n",
       "        0.06111585, -0.06969734, -0.03151445, -0.10286377, -0.20577462,\n",
       "        0.18633549, -0.00356869,  0.12576573, -0.07345627, -0.02170525,\n",
       "       -0.00152637, -0.15971154, -0.2268031 , -0.05581135,  0.00815263,\n",
       "       -0.14308691,  0.09365018,  0.04854256, -0.02740743,  0.02945334,\n",
       "       -0.05015876, -0.02297004, -0.06033265, -0.11060242,  0.13931838,\n",
       "        0.02869797, -0.14428619, -0.1998235 , -0.13052125, -0.08681565,\n",
       "        0.0124726 , -0.21207602, -0.00438632, -0.02285017, -0.02299456,\n",
       "       -0.17588468,  0.00263094,  0.08744419, -0.15261105, -0.12483302,\n",
       "       -0.14497292, -0.00298459,  0.01670099,  0.15397269, -0.12638877,\n",
       "       -0.07969187, -0.02922138, -0.16720666,  0.04824683,  0.18204504,\n",
       "       -0.26123416, -0.02381941, -0.25993454,  0.09655629, -0.0127505 ,\n",
       "       -0.20415805,  0.2791788 , -0.04583962,  0.07372984,  0.10512358,\n",
       "       -0.00401705, -0.00702624, -0.14177564,  0.11006753,  0.25750822,\n",
       "       -0.1653069 ,  0.06437157, -0.14825457,  0.06076309,  0.10260291,\n",
       "       -0.06752147, -0.03573662, -0.1892326 , -0.02374335,  0.1079576 ,\n",
       "        0.02548962,  0.09414952, -0.08941533,  0.08453115, -0.02624412,\n",
       "       -0.01170076,  0.07306243, -0.01346621, -0.10465797,  0.0111353 ,\n",
       "        0.14915773, -0.14176685, -0.2052461 , -0.14654893,  0.09766117,\n",
       "        0.01588231, -0.10843117,  0.17120387,  0.14729105, -0.08844467,\n",
       "        0.13146426, -0.0507281 , -0.01317732,  0.12786996,  0.20163009,\n",
       "       -0.04691447, -0.0479036 ,  0.0071131 , -0.00861132, -0.18058245,\n",
       "       -0.04400313, -0.13751292, -0.02849169,  0.09634657,  0.25129983,\n",
       "        0.01990751,  0.01817839,  0.17379573, -0.1647948 , -0.06588559,\n",
       "        0.02590577, -0.10128159,  0.37901232,  0.06280582, -0.21035315,\n",
       "       -0.13720752,  0.03978658,  0.01742146,  0.3309862 , -0.06343974,\n",
       "        0.07753032, -0.09462813,  0.05812556, -0.19858305, -0.14819923,\n",
       "       -0.01404713,  0.13043259, -0.10503726,  0.12142576,  0.12937555,\n",
       "       -0.10617769, -0.07727143, -0.06194742,  0.14295527, -0.163433  ,\n",
       "       -0.05971851,  0.2718069 , -0.1508394 ,  0.10223734, -0.03331573,\n",
       "        0.12034407,  0.18696736, -0.15580726,  0.02722496, -0.10169385,\n",
       "        0.1504761 , -0.10706437, -0.19483076,  0.13923071,  0.04554392,\n",
       "       -0.18469936,  0.15501098,  0.11551261, -0.06757662,  0.13691604,\n",
       "       -0.06181284, -0.27034888,  0.02193495,  0.01439491,  0.09902561,\n",
       "       -0.10614481,  0.03873734,  0.207373  , -0.04299558, -0.12119189,\n",
       "        0.23510933,  0.02250353, -0.17690332,  0.07043081,  0.01874883,\n",
       "        0.03503365,  0.04287729,  0.11508944,  0.0057666 ,  0.07686889,\n",
       "       -0.01226614,  0.20922379, -0.01923192,  0.04193201, -0.05523841,\n",
       "        0.05924537,  0.06269543, -0.03869852, -0.03571985, -0.1843579 ,\n",
       "        0.08290906,  0.03902989, -0.00067049,  0.02758019, -0.0479361 ,\n",
       "        0.10310272, -0.01593784,  0.14537008,  0.03521302,  0.1033081 ,\n",
       "       -0.2523843 , -0.07855792, -0.1797359 ,  0.0730035 ,  0.01533223,\n",
       "        0.02856536, -0.12705162,  0.18046664, -0.01505395, -0.02085061,\n",
       "       -0.10715544, -0.07139336,  0.11355202, -0.09909645, -0.0617405 ,\n",
       "       -0.02301183, -0.04920239, -0.17266364, -0.06997056, -0.0457123 ,\n",
       "       -0.16901228, -0.12120172, -0.03209778,  0.1171373 , -0.09934818,\n",
       "        0.12460698,  0.1159093 ,  0.05269676, -0.05192936,  0.22280312,\n",
       "        0.03399455], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print result\n",
    "model.docvecs['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-26 02:21:46,743: INFO: saving Doc2Vec object under word2vec_model/doc2vec, separately None\n",
      "2019-02-26 02:21:46,744: INFO: storing np array 'syn0' to word2vec_model/doc2vec.wv.syn0.npy\n",
      "2019-02-26 02:21:48,793: INFO: not storing attribute syn0norm\n",
      "2019-02-26 02:21:48,793: INFO: storing np array 'doctag_syn0' to word2vec_model/doc2vec.docvecs.doctag_syn0.npy\n",
      "2019-02-26 02:21:53,849: INFO: storing np array 'syn1neg' to word2vec_model/doc2vec.syn1neg.npy\n",
      "2019-02-26 02:21:55,923: INFO: not storing attribute cum_table\n",
      "2019-02-26 02:21:57,389: INFO: saved word2vec_model/doc2vec\n"
     ]
    }
   ],
   "source": [
    "## save result\n",
    "model.save('word2vec_model/doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
