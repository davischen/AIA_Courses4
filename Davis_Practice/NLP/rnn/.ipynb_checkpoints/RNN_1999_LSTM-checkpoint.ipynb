{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6HbiNb7tuPNW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding,GRU,Conv1D, MaxPooling1D,GlobalMaxPooling1D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "from keras.layers.wrappers import Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IlAf6k8euPNa"
   },
   "source": [
    "# Step 0. Loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lvEhxA7_uPNb"
   },
   "source": [
    "#### Step 0.1 load article cutted and article df and define y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EZwp-WsZuPNb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bFQvhCnouPNd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1800000321</td>\n",
       "      <td>無法透過 CAMP 上SIT 系統 icon 的連接登入. 可否協助看一下這問題</td>\n",
       "      <td>1</td>\n",
       "      <td>20180213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800000321</td>\n",
       "      <td>無法透過 CAMP 上SIT 系統 icon 的連接登入. 可否協助看一下這問題</td>\n",
       "      <td>1</td>\n",
       "      <td>20180213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1600001420</td>\n",
       "      <td>收到CAMP 簽核表單，開頭CAF_QRDC，不清楚這是什麼簽核表單</td>\n",
       "      <td>1</td>\n",
       "      <td>20160604</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600001420</td>\n",
       "      <td>收到CAMP 簽核表單，開頭CAF_QRDC，不清楚這是什麼簽核表單</td>\n",
       "      <td>1</td>\n",
       "      <td>20160604</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1500003557</td>\n",
       "      <td>無法會員登入,顯示訊息:無效的帳號或使用者不存在。帳號:96122401</td>\n",
       "      <td>1</td>\n",
       "      <td>20151228</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                   content  type      date  idx\n",
       "0  1800000321  無法透過 CAMP 上SIT 系統 icon 的連接登入. 可否協助看一下這問題     1  20180213    0\n",
       "1  1800000321  無法透過 CAMP 上SIT 系統 icon 的連接登入. 可否協助看一下這問題     1  20180213    1\n",
       "2  1600001420        收到CAMP 簽核表單，開頭CAF_QRDC，不清楚這是什麼簽核表單     1  20160604    2\n",
       "3  1600001420        收到CAMP 簽核表單，開頭CAF_QRDC，不清楚這是什麼簽核表單     1  20160604    3\n",
       "4  1500003557      無法會員登入,顯示訊息:無效的帳號或使用者不存在。帳號:96122401     1  20151228    4"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/1999_preprocessed.csv')\n",
    "df['type'] = pd.factorize(df['type'])[0] + 1\n",
    "#diff_threshold = 20\n",
    "#df = df[abs(df['push']-df['boo']) > diff_threshold].copy()\n",
    "#df['type'] = np.clip(df['push']-df['boo'], 0, 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bFQvhCnouPNd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APP0038374</td>\n",
       "      <td>user無法login.</td>\n",
       "      <td>7</td>\n",
       "      <td>20110426</td>\n",
       "      <td>4277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APP0019359</td>\n",
       "      <td>1、因现有报废程式内有公司自制半成品99*阶及2*、3*阶料号的Docking及小板可以直接...</td>\n",
       "      <td>3</td>\n",
       "      <td>20080307</td>\n",
       "      <td>1418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APP0020747</td>\n",
       "      <td>登入SAP VD02 KEY IN 問題</td>\n",
       "      <td>7</td>\n",
       "      <td>20080617</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>APP0000935</td>\n",
       "      <td>user欲從QRDCFS02上下載SAP檔案,但系統顯示此資料夾其權限不足,煩請Sworm協...</td>\n",
       "      <td>7</td>\n",
       "      <td>20050815</td>\n",
       "      <td>5863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APP0001552</td>\n",
       "      <td>User 反應 218端BOM 用量不對,料號3123MMB00B5,請速連繫# 3158</td>\n",
       "      <td>4</td>\n",
       "      <td>20050920</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                            content  type  \\\n",
       "0  APP0038374                                       user無法login.     7   \n",
       "1  APP0019359  1、因现有报废程式内有公司自制半成品99*阶及2*、3*阶料号的Docking及小板可以直接...     3   \n",
       "2  APP0020747                               登入SAP VD02 KEY IN 問題     7   \n",
       "3  APP0000935  user欲從QRDCFS02上下載SAP檔案,但系統顯示此資料夾其權限不足,煩請Sworm協...     7   \n",
       "4  APP0001552      User 反應 218端BOM 用量不對,料號3123MMB00B5,請速連繫# 3158     4   \n",
       "\n",
       "       date   idx  \n",
       "0  20110426  4277  \n",
       "1  20080307  1418  \n",
       "2  20080617   356  \n",
       "3  20050815  5863  \n",
       "4  20050920   200  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 資料打散\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B8XHk6SguPNg"
   },
   "source": [
    "#### Step 0.2 create word id mapping and word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Eib4FB-CuPN7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "num_classes = 7\n"
     ]
    }
   ],
   "source": [
    "X = df.content\n",
    "Y = df.type\n",
    "le = LabelEncoder()  \n",
    "Y = le.fit_transform(Y) # 這邊Y.shape = (84020, )\n",
    "Y = Y.reshape(-1,1) # 將Y的shape轉換成： Y.shape= (84020, 1)\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)\n",
    "\n",
    "# label 做 onehot\n",
    "y_one_hot = np_utils.to_categorical(Y)\n",
    "print (y_one_hot[0])\n",
    "# 總共類別數\n",
    "num_classes = len((y_one_hot[0]))\n",
    "print ('num_classes = {}'.format(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Eib4FB-CuPN7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Eib4FB-CuPN7"
   },
   "outputs": [],
   "source": [
    "# 標點符號過濾\n",
    "WORD_FILTERS = '!\"#$&()*+,-./:;<=>?@[\\\\]^_{|}~\\t\\n'\n",
    "# 字典數量\n",
    "NUM_WORDS = 100\n",
    "# 向量長度\n",
    "MAX_LEN = 100\n",
    "\n",
    "# 將訓練資料的單字轉成向量\n",
    "#total\n",
    "tokenizer_obj= Tokenizer()\n",
    "total_reviews= X_train + X_test\n",
    "#tokenizer_obj.fit_on_texts(total_reviews)\n",
    "#max_len=max([len(s.split()) for s in total_reviews])\n",
    "#vocab_size=len(tokenizer_obj.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Eib4FB-CuPN7"
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "jieba: file does not exist: /home/jovyan/Davis_Practice/NLP/part4/NLP/jieba/dict.txt.big",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-213-224bcf65b90e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## set dictionary (can define yourself)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjieba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NLP/jieba/dict.txt.big'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NLP/jieba/stop_words.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/jieba/__init__.py\u001b[0m in \u001b[0;36mset_dictionary\u001b[0;34m(self, dictionary_path)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mabs_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_abs_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"jieba: file does not exist: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mabs_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: jieba: file does not exist: /home/jovyan/Davis_Practice/NLP/part4/NLP/jieba/dict.txt.big"
     ]
    }
   ],
   "source": [
    "## set dictionary (can define yourself)\n",
    "jieba.set_dictionary('../NLP/jieba/dict.txt.big')\n",
    "stop_words = open('../NLP/jieba/stop_words.txt', encoding=\"utf-8\").read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Eib4FB-CuPN7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8981 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# 將訓練資料的單字轉成向量\n",
    "#X_train\n",
    "tokenizer = Tokenizer(filters=WORD_FILTERS,\n",
    "                        num_words=NUM_WORDS,\n",
    "                        split=\",\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Eib4FB-CuPN7"
   },
   "outputs": [],
   "source": [
    "# 將訓練字句截長補短\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len) # 確保所有序列具有相同的形狀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Eib4FB-CuPN7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5139,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Eib4FB-CuPN7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5139, 1)\n"
     ]
    }
   ],
   "source": [
    "print (Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Eib4FB-CuPN7"
   },
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(279,name='out_layer')(layer) # 最後一層參數值為類別數\n",
    "    layer = Activation('softmax')(layer) #二元分類是'sigmoid'，多元分類上修改為'softmax'\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Eib4FB-CuPN7"
   },
   "outputs": [],
   "source": [
    "def RNN_GRU():\n",
    "    sequence_input = Input(shape=(max_len,), dtype='int32')\n",
    "    embedded_sequences = Embedding(max_words,50,input_length=max_len)(sequence_input)\n",
    "    x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    x = Conv1D(128, 5, activation='relu')(x)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    x = Conv1D(128, 5, activation='relu')(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    preds = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Eib4FB-CuPN7"
   },
   "outputs": [],
   "source": [
    "def build_model(num_classes, vocab_size, sentence_max_len):\n",
    "    print(num_classes)\n",
    "    print(vocab_size)\n",
    "    print(sentence_max_len)\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, \n",
    "                        output_dim=256, \n",
    "                        input_length=sentence_max_len))\n",
    "    model.add(Bidirectional(LSTM(128,implementation=2)))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Eib4FB-CuPN7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "100\n",
      "100\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 100, 256)          25600     \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 421,639\n",
      "Trainable params: 421,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 100, 256)          25600     \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 421,639\n",
      "Trainable params: 421,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected embedding_13_input to have shape (100,) but got array with shape (1000,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-8e527189d82c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m model.fit(sequences_matrix,Y_train,batch_size=128,epochs=100,\n\u001b[0;32m---> 14\u001b[0;31m           validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    135\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected embedding_13_input to have shape (100,) but got array with shape (1000,)"
     ]
    }
   ],
   "source": [
    "#model = RNN()\n",
    "#model.summary()\n",
    "#model.compile(loss = 'sparse_categorical_crossentropy', optimizer=RMSprop(),metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "model = build_model(num_classes, NUM_WORDS, MAX_LEN)\n",
    "model.summary()\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='Adam',metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# train model\n",
    "model.fit(sequences_matrix,Y_train,batch_size=128,epochs=100,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k-vsxfy3uPOF"
   },
   "source": [
    "### Time to train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "908/908 [==============================] - 2s 2ms/step\n",
      "Test set\n",
      "  Loss: 1.275\n",
      "  Accuracy: 0.551\n"
     ]
    }
   ],
   "source": [
    "# 處理測試集資料\n",
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
    "# 使用測試集來進行模型評估\n",
    "accr = model.evaluate(test_sequences_matrix,Y_test)\n",
    "\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "07_rnn_ptt_text_classification.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
