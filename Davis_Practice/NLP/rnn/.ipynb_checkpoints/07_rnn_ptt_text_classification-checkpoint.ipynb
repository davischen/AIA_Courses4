{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6HbiNb7tuPNW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "from gensim.models import word2vec\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IlAf6k8euPNa"
   },
   "source": [
    "### Step 0. Loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lvEhxA7_uPNb"
   },
   "source": [
    "#### Step 0.1 load article cutted and article df and define y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EZwp-WsZuPNb"
   },
   "outputs": [],
   "source": [
    "with open(\"../article_cutted\", \"rb\") as file:\n",
    "    docs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bFQvhCnouPNd"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/article_preprocessed.csv')\n",
    "diff_threshold = 20\n",
    "df = df[abs(df['push']-df['boo']) > diff_threshold].copy()\n",
    "df['type'] = np.clip(df['push']-df['boo'], 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B8XHk6SguPNg"
   },
   "source": [
    "#### Step 0.2 create word id mapping and word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "N0evuFZJuPNg"
   },
   "outputs": [],
   "source": [
    "w2v = word2vec.Word2Vec.load('../word2vec_model/CBOW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TTqL7HAPuPNi"
   },
   "outputs": [],
   "source": [
    "word2id = {k:i for i, k in enumerate(w2v.wv.vocab.keys())}\n",
    "id2word = {i:k for k, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "crdG_vUmuPNk"
   },
   "outputs": [],
   "source": [
    "words_len = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NBJ8KKsiuPNn"
   },
   "outputs": [],
   "source": [
    "embedding = np.zeros((words_len+1, 256))\n",
    "for k, v in word2id.items():\n",
    "    embedding[v] = w2v.wv[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ww_Yjk2auPNp"
   },
   "source": [
    "#### Step 0.3 sentence to seq transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bKE_MSpIuPNq"
   },
   "outputs": [],
   "source": [
    "input_length = 80\n",
    "docs_id = []\n",
    "for doc in docs:\n",
    "    text = doc[:input_length]\n",
    "    ids = [words_len+1]*input_length\n",
    "    ids[:len(text)] = [word2id[w] if w in word2id else words_len+1 for w in text]\n",
    "\n",
    "    docs_id.append(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Z9vZqbvGuPNr",
    "outputId": "9995fffd-ce85-4c8e-822f-771fbf8b40fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['韓瑜', '協志', '前妻', '正', '女演員', '周子', '瑜', 'TWICE', '團裡裡面', '台灣', '人', '正', '兩個', '要當', '鄉民', '老婆', '選', '五樓', '真', '勇氣']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 100035, 8, 9, 3, 10, 11, 12, 13, 14, 15, 16, 17, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035]\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])\n",
    "print(docs_id[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QIgXcRXDuPNv"
   },
   "source": [
    "### Step 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nz_CRjP1uPNw"
   },
   "source": [
    "#### Step 1.1 Creating Training and Testing sets and creating generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eVjfzGNDuPNx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7n4Lfma2uPN0"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, shuffle=True, stratify=df['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3QCQnnIhuPN2"
   },
   "outputs": [],
   "source": [
    "def train_data_generator(df, bz, docs_id):\n",
    "    # bz: batch size \n",
    "    \n",
    "    dfs = [sub_df for key,sub_df in df.groupby('type')]\n",
    "    df_n = len(dfs)\n",
    "    \n",
    "    docs_id = np.array(docs_id)\n",
    "    while True:\n",
    "        selected = pd.concat([sub_df.sample(int(bz/2)) for sub_df in dfs], axis=0)\n",
    "        selected = selected.sample(frac=1)\n",
    "        x = docs_id[selected['idx']]\n",
    "        y = selected.as_matrix(columns=['type'])\n",
    "                    \n",
    "        yield x, y\n",
    "        \n",
    "def test_data_generator(df, docs_id):\n",
    "    docs_id = np.array(docs_id)\n",
    "    x = docs_id[df['idx']]\n",
    "    y = df.as_matrix(columns=['type'])\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iOwTLmDkuPN4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = test_data_generator(test, docs_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1j599yZuPN6"
   },
   "source": [
    "### Let's create the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Eib4FB-CuPN7"
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "update_per_epochs = 100\n",
    "\n",
    "learning_rate=0.001\n",
    "hidden_layer_size=64\n",
    "number_of_layers=1\n",
    "dropout=True\n",
    "dropout_rate=0.8\n",
    "number_of_classes=1\n",
    "gradient_clip_margin=4\n",
    "wv=embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GHIAFkXduPN9"
   },
   "outputs": [],
   "source": [
    "def LSTM_cell(hidden_layer_size, batch_size, number_of_layers, dropout=True, dropout_rate=0.8):\n",
    "    def get_LSTM(hidden_layer_size, dropout, dropout_rate):\n",
    "        layer = tf.contrib.rnn.BasicLSTMCell(hidden_layer_size)\n",
    "\n",
    "        if dropout:\n",
    "            layer = tf.contrib.rnn.DropoutWrapper(layer, output_keep_prob=dropout_rate)\n",
    "            \n",
    "        return layer\n",
    "    \n",
    "    cell = tf.contrib.rnn.MultiRNNCell([get_LSTM(hidden_layer_size, dropout, dropout_rate) for _ in range(number_of_layers)])\n",
    "\n",
    "    init_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    return cell, init_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wfl64n1GuPOA"
   },
   "outputs": [],
   "source": [
    "def output_layer(lstm_output, out_size):\n",
    "    x = lstm_output[:, -1, :]\n",
    "    output = tf.layers.dense(inputs= x, units= out_size)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "c497NKMBuPOC"
   },
   "outputs": [],
   "source": [
    "def opt_loss(logits, targets, learning_rate, grad_clip_margin):\n",
    "    \n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=targets, logits=logits))\n",
    "    \n",
    "    #Cliping the gradient loss\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    gradients = optimizer.compute_gradients(loss)\n",
    "\n",
    "    capped_gradients = [(tf.clip_by_value(grad, (-1)*grad_clip_margin, grad_clip_margin), var) for grad, var in gradients if grad is not None]\n",
    "    \n",
    "    train_optimizer = optimizer.apply_gradients(capped_gradients)\n",
    "\n",
    "    \n",
    "    return loss, train_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VRWsII5cuPOD"
   },
   "outputs": [],
   "source": [
    "main_graph = tf.Graph()\n",
    "sess = tf.Session(graph=main_graph)\n",
    "\n",
    "with main_graph.as_default():\n",
    "    \n",
    "    ##defining placeholders##\n",
    "    with tf.name_scope('input'):\n",
    "        inputs = tf.placeholder(tf.int32, [None, input_length], name='input_data')\n",
    "        targets = tf.placeholder(tf.float32, [None, 1], name='targets')\n",
    "        bz = tf.placeholder(tf.int32, [], name='batch_size')\n",
    "        \n",
    "    ## embedding lookup table\n",
    "    with tf.variable_scope('embedding'):    \n",
    "        em_W = tf.Variable(wv.astype(np.float32), trainable=True)  #wv.shape = (100035, 256)\n",
    "        x = tf.nn.embedding_lookup(em_W, inputs)    #x.shape = (?, 80, 256)\n",
    "        \n",
    "    ##LSTM layer##\n",
    "    with tf.variable_scope(\"LSTM_layer\"):\n",
    "        cell, init_state = LSTM_cell(hidden_layer_size, tf.shape(inputs)[0], number_of_layers, dropout, dropout_rate) \n",
    "        outputs, states = tf.nn.dynamic_rnn(cell, x, initial_state=init_state)\n",
    "    \n",
    "    ##Output layer##   \n",
    "    with tf.variable_scope('output_layer'):\n",
    "        logits = output_layer(outputs, number_of_classes)\n",
    "    \n",
    "    ##loss and optimization##\n",
    "    with tf.name_scope('loss_and_opt'):\n",
    "        loss, opt = opt_loss(logits, targets, learning_rate, gradient_clip_margin)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k-vsxfy3uPOF"
   },
   "source": [
    "### Time to train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DoQJCDVYuPOF"
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fPnPG66kuPOH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100  Train loss: 0.647307813167572  Train auc: 0.661328125  Test loss: 0.6530517935752869  Test auc: 0.7279239706585545\n",
      "Epoch 5/100  Train loss: 0.2078537940979004  Train auc: 0.965703125  Test loss: 0.3756914436817169  Test auc: 0.7781205807245831\n",
      "Epoch 10/100  Train loss: 0.09402593970298767  Train auc: 0.9883984375  Test loss: 0.27901434898376465  Test auc: 0.7465790357204627\n",
      "Epoch 15/100  Train loss: 0.06293924152851105  Train auc: 0.992578125  Test loss: 0.37999531626701355  Test auc: 0.7601102847666623\n",
      "Epoch 20/100  Train loss: 0.0335342139005661  Train auc: 0.9976953125  Test loss: 0.2589842677116394  Test auc: 0.763744900346929\n",
      "Epoch 25/100  Train loss: 0.034729670733213425  Train auc: 0.9961328125  Test loss: 0.34007948637008667  Test auc: 0.7363377623587104\n",
      "Epoch 30/100  Train loss: 0.048718225210905075  Train auc: 0.996796875  Test loss: 0.3171576261520386  Test auc: 0.7212206610981677\n",
      "Epoch 35/100  Train loss: 0.029366498813033104  Train auc: 0.9963671875  Test loss: 0.3187635838985443  Test auc: 0.715172294513231\n",
      "Epoch 40/100  Train loss: 0.0406685434281826  Train auc: 0.9959765625  Test loss: 0.29384681582450867  Test auc: 0.6686331912382619\n",
      "Epoch 45/100  Train loss: 0.020440245047211647  Train auc: 0.9984375  Test loss: 0.3381154239177704  Test auc: 0.7356128740169496\n",
      "Epoch 50/100  Train loss: 0.01438553910702467  Train auc: 0.9990625  Test loss: 0.30471763014793396  Test auc: 0.7502530750526497\n",
      "Epoch 55/100  Train loss: 0.011918901465833187  Train auc: 0.9990234375  Test loss: 0.4103366732597351  Test auc: 0.7046067289985858\n",
      "Epoch 60/100  Train loss: 0.06921079009771347  Train auc: 0.991328125  Test loss: 0.40688976645469666  Test auc: 0.7464378732539093\n",
      "Epoch 65/100  Train loss: 0.04557923972606659  Train auc: 0.993359375  Test loss: 0.3901658356189728  Test auc: 0.7677578567722375\n",
      "Epoch 70/100  Train loss: 0.04123260825872421  Train auc: 0.9977734375  Test loss: 0.3432231545448303  Test auc: 0.7985954970444904\n",
      "Epoch 75/100  Train loss: 0.03898376226425171  Train auc: 0.994609375  Test loss: 0.4178629219532013  Test auc: 0.767692998341659\n",
      "Epoch 80/100  Train loss: 0.03333735093474388  Train auc: 0.99515625  Test loss: 0.38508427143096924  Test auc: 0.7483251264103528\n",
      "Epoch 85/100  Train loss: 0.026793094351887703  Train auc: 0.9966796875  Test loss: 0.517964780330658  Test auc: 0.7806716789940077\n",
      "Epoch 90/100  Train loss: 0.03923983499407768  Train auc: 0.9944140625  Test loss: 0.4197530746459961  Test auc: 0.7358366991891425\n",
      "Epoch 95/100  Train loss: 0.015489468351006508  Train auc: 0.9980078125  Test loss: 0.4143025279045105  Test auc: 0.703178571791924\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "train_generate = train_data_generator(train, batch_size, docs_id)\n",
    "\n",
    "train_loss = []\n",
    "train_auc = []\n",
    "test_loss = []\n",
    "test_auc = []\n",
    "for i in range(epochs):\n",
    "    traind_scores = []\n",
    "    epoch_loss = []\n",
    "    for j in range(update_per_epochs):\n",
    "        X_batch, y_batch = next(train_generate) \n",
    "        \n",
    "        o, c, _ = sess.run([logits, loss, opt], feed_dict={\n",
    "            inputs:X_batch, \n",
    "            targets:y_batch,\n",
    "            bz:np.array(batch_size)\n",
    "        })\n",
    "        \n",
    "        epoch_loss.append(c)\n",
    "        traind_scores.append(roc_auc_score(y_batch, o))\n",
    "    \n",
    "    to, tc = sess.run([logits, loss], feed_dict={\n",
    "        inputs:X_test, \n",
    "        targets:Y_test,\n",
    "        bz:np.array(len(X_test))\n",
    "    })\n",
    "    \n",
    "    train_loss.append(np.mean(epoch_loss))\n",
    "    train_auc.append(np.mean(traind_scores))\n",
    "    test_loss.append(tc)\n",
    "    test_auc.append(roc_auc_score(Y_test, to))\n",
    "    \n",
    "    if (i % 5) == 0:\n",
    "        print('Epoch {}/{}'.format(i, epochs), ' Train loss: {}'.format(np.mean(epoch_loss)), \n",
    "              ' Train auc: {}'.format(np.mean(traind_scores)), \n",
    "             ' Test loss: {}'.format(tc), ' Test auc: {}'.format(roc_auc_score(Y_test, to)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "07_rnn_ptt_text_classification.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
