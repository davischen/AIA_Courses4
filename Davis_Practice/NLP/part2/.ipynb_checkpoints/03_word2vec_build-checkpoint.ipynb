{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how to build words relationship ? word2vec !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from gensim.models import word2vec\n",
    "import random\n",
    "import logging\n",
    "import os\n",
    "\n",
    "## turn back to main directory\n",
    "os.chdir(\"../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s')\n",
    "logging.root.setLevel(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load 'article_cutted'\n",
    "with open('article_cutted', 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build word2vec\n",
    "# sg=0 CBOW ; sg=1 skip-gram\n",
    "model = word2vec.Word2Vec(size=256, min_count=5, window=5, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-26 02:07:37,757: INFO: collecting all words and their counts\n",
      "2019-02-26 02:07:37,758: INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-02-26 02:07:37,869: INFO: PROGRESS: at sentence #10000, processed 450472 words, keeping 62530 word types\n",
      "2019-02-26 02:07:37,993: INFO: PROGRESS: at sentence #20000, processed 917994 words, keeping 94798 word types\n",
      "2019-02-26 02:07:38,114: INFO: PROGRESS: at sentence #30000, processed 1376864 words, keeping 119647 word types\n",
      "2019-02-26 02:07:38,236: INFO: PROGRESS: at sentence #40000, processed 1830843 words, keeping 139918 word types\n",
      "2019-02-26 02:07:38,362: INFO: PROGRESS: at sentence #50000, processed 2296622 words, keeping 158826 word types\n",
      "2019-02-26 02:07:38,497: INFO: PROGRESS: at sentence #60000, processed 2758111 words, keeping 175445 word types\n",
      "2019-02-26 02:07:38,617: INFO: PROGRESS: at sentence #70000, processed 3207991 words, keeping 190133 word types\n",
      "2019-02-26 02:07:38,740: INFO: PROGRESS: at sentence #80000, processed 3673394 words, keeping 204929 word types\n",
      "2019-02-26 02:07:38,866: INFO: PROGRESS: at sentence #90000, processed 4150285 words, keeping 220178 word types\n",
      "2019-02-26 02:07:38,990: INFO: PROGRESS: at sentence #100000, processed 4586170 words, keeping 232949 word types\n",
      "2019-02-26 02:07:39,112: INFO: PROGRESS: at sentence #110000, processed 5046757 words, keeping 245237 word types\n",
      "2019-02-26 02:07:39,229: INFO: PROGRESS: at sentence #120000, processed 5492090 words, keeping 256501 word types\n",
      "2019-02-26 02:07:39,351: INFO: PROGRESS: at sentence #130000, processed 5940297 words, keeping 267710 word types\n",
      "2019-02-26 02:07:39,472: INFO: PROGRESS: at sentence #140000, processed 6397077 words, keeping 278552 word types\n",
      "2019-02-26 02:07:39,592: INFO: PROGRESS: at sentence #150000, processed 6852157 words, keeping 289207 word types\n",
      "2019-02-26 02:07:39,713: INFO: PROGRESS: at sentence #160000, processed 7314121 words, keeping 300645 word types\n",
      "2019-02-26 02:07:39,850: INFO: PROGRESS: at sentence #170000, processed 7778365 words, keeping 311065 word types\n",
      "2019-02-26 02:07:39,982: INFO: PROGRESS: at sentence #180000, processed 8243928 words, keeping 321562 word types\n",
      "2019-02-26 02:07:40,106: INFO: PROGRESS: at sentence #190000, processed 8694493 words, keeping 331279 word types\n",
      "2019-02-26 02:07:40,228: INFO: PROGRESS: at sentence #200000, processed 9139086 words, keeping 340145 word types\n",
      "2019-02-26 02:07:40,355: INFO: PROGRESS: at sentence #210000, processed 9593110 words, keeping 349116 word types\n",
      "2019-02-26 02:07:40,503: INFO: PROGRESS: at sentence #220000, processed 10070866 words, keeping 358685 word types\n",
      "2019-02-26 02:07:40,633: INFO: PROGRESS: at sentence #230000, processed 10553199 words, keeping 368027 word types\n",
      "2019-02-26 02:07:40,757: INFO: PROGRESS: at sentence #240000, processed 11016363 words, keeping 376775 word types\n",
      "2019-02-26 02:07:40,881: INFO: PROGRESS: at sentence #250000, processed 11477995 words, keeping 385906 word types\n",
      "2019-02-26 02:07:40,910: INFO: collected 388118 word types from a corpus of 11587581 raw words and 252229 sentences\n",
      "2019-02-26 02:07:40,911: INFO: Loading a fresh vocabulary\n",
      "2019-02-26 02:07:41,487: INFO: min_count=5 retains 100034 unique words (25% of original 388118, drops 288084)\n",
      "2019-02-26 02:07:41,487: INFO: min_count=5 leaves 11155104 word corpus (96% of original 11587581, drops 432477)\n",
      "2019-02-26 02:07:41,726: INFO: deleting the raw counts dictionary of 388118 items\n",
      "2019-02-26 02:07:41,734: INFO: sample=0.001 downsamples 18 most-common words\n",
      "2019-02-26 02:07:41,735: INFO: downsampling leaves estimated 10810274 word corpus (96.9% of prior 11155104)\n",
      "2019-02-26 02:07:41,735: INFO: estimated required memory for 100034 words and 256 dimensions: 254886632 bytes\n",
      "2019-02-26 02:07:42,043: INFO: resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary\n",
    "model.build_vocab(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-26 02:07:43,332: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:07:44,345: INFO: PROGRESS: at 8.08% examples, 859058 words/s, in_qsize 4, out_qsize 1\n",
      "2019-02-26 02:07:45,358: INFO: PROGRESS: at 16.21% examples, 859816 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:07:46,365: INFO: PROGRESS: at 24.64% examples, 876745 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:07:47,367: INFO: PROGRESS: at 33.17% examples, 886656 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:07:48,369: INFO: PROGRESS: at 41.71% examples, 894519 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:07:49,373: INFO: PROGRESS: at 50.22% examples, 900260 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:07:50,384: INFO: PROGRESS: at 59.02% examples, 906821 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:07:51,389: INFO: PROGRESS: at 67.96% examples, 912353 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:07:52,392: INFO: PROGRESS: at 76.67% examples, 915717 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:07:53,392: INFO: PROGRESS: at 85.55% examples, 919684 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:07:54,394: INFO: PROGRESS: at 94.41% examples, 922627 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:07:55,003: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:07:55,004: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:07:55,018: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:07:55,018: INFO: training on 11587581 raw words (10809388 effective words) took 11.7s, 925649 effective words/s\n",
      "2019-02-26 02:07:55,249: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:07:56,262: INFO: PROGRESS: at 8.76% examples, 947116 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:07:57,273: INFO: PROGRESS: at 17.32% examples, 939971 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:07:58,276: INFO: PROGRESS: at 25.75% examples, 926229 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:07:59,276: INFO: PROGRESS: at 34.42% examples, 929086 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:00,281: INFO: PROGRESS: at 43.08% examples, 932114 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:01,299: INFO: PROGRESS: at 52.07% examples, 934949 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:02,300: INFO: PROGRESS: at 60.78% examples, 936009 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:03,303: INFO: PROGRESS: at 69.66% examples, 938914 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:08:04,309: INFO: PROGRESS: at 78.59% examples, 942058 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:08:05,311: INFO: PROGRESS: at 87.30% examples, 940461 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:06,317: INFO: PROGRESS: at 96.55% examples, 943969 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:06,666: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:08:06,679: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:08:06,684: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:08:06,684: INFO: training on 11587581 raw words (10810711 effective words) took 11.4s, 946072 effective words/s\n",
      "2019-02-26 02:08:06,898: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:08:07,907: INFO: PROGRESS: at 8.80% examples, 953143 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:08:08,912: INFO: PROGRESS: at 17.39% examples, 941560 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:09,923: INFO: PROGRESS: at 25.82% examples, 924584 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:10,924: INFO: PROGRESS: at 34.43% examples, 926862 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:11,924: INFO: PROGRESS: at 43.28% examples, 934607 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:12,946: INFO: PROGRESS: at 51.19% examples, 919139 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:13,953: INFO: PROGRESS: at 58.20% examples, 896560 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:14,957: INFO: PROGRESS: at 65.83% examples, 886110 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:15,974: INFO: PROGRESS: at 72.96% examples, 870530 words/s, in_qsize 4, out_qsize 1\n",
      "2019-02-26 02:08:16,988: INFO: PROGRESS: at 81.03% examples, 869483 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:18,000: INFO: PROGRESS: at 88.64% examples, 863883 words/s, in_qsize 4, out_qsize 1\n",
      "2019-02-26 02:08:19,025: INFO: PROGRESS: at 95.51% examples, 852055 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:19,637: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:08:19,649: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:08:19,650: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:08:19,651: INFO: training on 11587581 raw words (10809873 effective words) took 12.7s, 848032 effective words/s\n",
      "2019-02-26 02:08:19,892: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:08:20,918: INFO: PROGRESS: at 6.13% examples, 660696 words/s, in_qsize 4, out_qsize 1\n",
      "2019-02-26 02:08:21,942: INFO: PROGRESS: at 13.45% examples, 715121 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:22,943: INFO: PROGRESS: at 21.21% examples, 757473 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:23,948: INFO: PROGRESS: at 30.17% examples, 808719 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:24,949: INFO: PROGRESS: at 39.14% examples, 839433 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:25,950: INFO: PROGRESS: at 47.97% examples, 857944 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:26,952: INFO: PROGRESS: at 56.79% examples, 872462 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:27,958: INFO: PROGRESS: at 65.74% examples, 883506 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:28,976: INFO: PROGRESS: at 72.87% examples, 869411 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:29,993: INFO: PROGRESS: at 80.10% examples, 859957 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:30,995: INFO: PROGRESS: at 87.93% examples, 857522 words/s, in_qsize 6, out_qsize 1\n",
      "2019-02-26 02:08:32,005: INFO: PROGRESS: at 96.79% examples, 864296 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:08:32,344: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:08:32,354: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:08:32,359: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:08:32,360: INFO: training on 11587581 raw words (10809681 effective words) took 12.5s, 867233 effective words/s\n",
      "2019-02-26 02:08:32,576: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:08:33,591: INFO: PROGRESS: at 8.37% examples, 901298 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:08:34,600: INFO: PROGRESS: at 17.10% examples, 918337 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:35,603: INFO: PROGRESS: at 25.98% examples, 930128 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:36,630: INFO: PROGRESS: at 34.80% examples, 929826 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:37,634: INFO: PROGRESS: at 43.41% examples, 930744 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:38,641: INFO: PROGRESS: at 52.11% examples, 931941 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:39,649: INFO: PROGRESS: at 61.05% examples, 936820 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:40,656: INFO: PROGRESS: at 69.94% examples, 937448 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:08:41,660: INFO: PROGRESS: at 78.70% examples, 937983 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:42,677: INFO: PROGRESS: at 87.94% examples, 942852 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:08:43,694: INFO: PROGRESS: at 97.03% examples, 944143 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:08:44,007: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:08:44,009: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:08:44,013: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:08:44,013: INFO: training on 11587581 raw words (10810093 effective words) took 11.4s, 945945 effective words/s\n",
      "2019-02-26 02:08:44,234: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:08:45,251: INFO: PROGRESS: at 7.16% examples, 777578 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:46,253: INFO: PROGRESS: at 15.83% examples, 856213 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:08:47,265: INFO: PROGRESS: at 24.99% examples, 894273 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:48,265: INFO: PROGRESS: at 33.98% examples, 915388 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:49,266: INFO: PROGRESS: at 43.23% examples, 930758 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:08:50,268: INFO: PROGRESS: at 52.04% examples, 936245 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:51,271: INFO: PROGRESS: at 60.90% examples, 939786 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:52,278: INFO: PROGRESS: at 69.97% examples, 943249 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:08:53,289: INFO: PROGRESS: at 79.22% examples, 946520 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:54,295: INFO: PROGRESS: at 88.47% examples, 951180 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:55,296: INFO: PROGRESS: at 97.73% examples, 955679 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:55,521: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:08:55,523: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:08:55,529: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:08:55,530: INFO: training on 11587581 raw words (10810018 effective words) took 11.3s, 957411 effective words/s\n",
      "2019-02-26 02:08:55,747: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:08:56,754: INFO: PROGRESS: at 8.88% examples, 950017 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:57,765: INFO: PROGRESS: at 17.22% examples, 918976 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:08:58,778: INFO: PROGRESS: at 25.88% examples, 914444 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:08:59,783: INFO: PROGRESS: at 34.77% examples, 925760 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:09:00,788: INFO: PROGRESS: at 44.03% examples, 938222 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:01,797: INFO: PROGRESS: at 53.29% examples, 947405 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:02,807: INFO: PROGRESS: at 62.16% examples, 950968 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:09:03,811: INFO: PROGRESS: at 71.25% examples, 954485 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:04,813: INFO: PROGRESS: at 80.47% examples, 959532 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:09:05,818: INFO: PROGRESS: at 89.88% examples, 964212 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:06,822: INFO: PROGRESS: at 99.22% examples, 968241 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:06,899: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:09:06,905: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:09:06,917: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:09:06,918: INFO: training on 11587581 raw words (10810800 effective words) took 11.2s, 968111 effective words/s\n",
      "2019-02-26 02:09:07,133: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:09:08,159: INFO: PROGRESS: at 9.07% examples, 966430 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:09,167: INFO: PROGRESS: at 17.72% examples, 954718 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:10,171: INFO: PROGRESS: at 26.82% examples, 959420 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:11,172: INFO: PROGRESS: at 35.98% examples, 965057 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:09:12,174: INFO: PROGRESS: at 45.17% examples, 966906 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:13,178: INFO: PROGRESS: at 53.84% examples, 964466 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:14,200: INFO: PROGRESS: at 63.06% examples, 964343 words/s, in_qsize 6, out_qsize 1\n",
      "2019-02-26 02:09:15,206: INFO: PROGRESS: at 72.12% examples, 965851 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:16,213: INFO: PROGRESS: at 81.30% examples, 968062 words/s, in_qsize 4, out_qsize 1\n",
      "2019-02-26 02:09:17,218: INFO: PROGRESS: at 90.30% examples, 968052 words/s, in_qsize 4, out_qsize 1\n",
      "2019-02-26 02:09:18,220: INFO: PROGRESS: at 99.20% examples, 967521 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:18,290: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:09:18,301: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:09:18,306: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:09:18,307: INFO: training on 11587581 raw words (10810368 effective words) took 11.2s, 968177 effective words/s\n",
      "2019-02-26 02:09:18,553: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:09:19,565: INFO: PROGRESS: at 9.13% examples, 976576 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:20,568: INFO: PROGRESS: at 17.84% examples, 959496 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:21,574: INFO: PROGRESS: at 26.95% examples, 963197 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:09:22,580: INFO: PROGRESS: at 35.95% examples, 963478 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:23,583: INFO: PROGRESS: at 44.97% examples, 966202 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:09:24,601: INFO: PROGRESS: at 54.15% examples, 967151 words/s, in_qsize 6, out_qsize 1\n",
      "2019-02-26 02:09:25,617: INFO: PROGRESS: at 63.14% examples, 966001 words/s, in_qsize 6, out_qsize 1\n",
      "2019-02-26 02:09:26,619: INFO: PROGRESS: at 71.76% examples, 960989 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:09:27,631: INFO: PROGRESS: at 79.88% examples, 950940 words/s, in_qsize 4, out_qsize 1\n",
      "2019-02-26 02:09:28,656: INFO: PROGRESS: at 88.81% examples, 950672 words/s, in_qsize 6, out_qsize 2\n",
      "2019-02-26 02:09:29,658: INFO: PROGRESS: at 97.94% examples, 954245 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:29,876: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:09:29,880: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:09:29,882: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:09:29,882: INFO: training on 11587581 raw words (10811091 effective words) took 11.3s, 954945 effective words/s\n",
      "2019-02-26 02:09:30,108: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:09:31,121: INFO: PROGRESS: at 8.99% examples, 977079 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:32,142: INFO: PROGRESS: at 17.46% examples, 942225 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:09:33,159: INFO: PROGRESS: at 26.49% examples, 947140 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:34,162: INFO: PROGRESS: at 35.70% examples, 953192 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:35,162: INFO: PROGRESS: at 44.86% examples, 960450 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:36,195: INFO: PROGRESS: at 53.92% examples, 958747 words/s, in_qsize 6, out_qsize 2\n",
      "2019-02-26 02:09:37,200: INFO: PROGRESS: at 63.09% examples, 963980 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:38,210: INFO: PROGRESS: at 72.42% examples, 967720 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:39,223: INFO: PROGRESS: at 81.74% examples, 970032 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:40,232: INFO: PROGRESS: at 91.09% examples, 972452 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:09:41,215: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:09:41,225: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:09:41,227: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:09:41,228: INFO: training on 11587581 raw words (10810203 effective words) took 11.1s, 972937 effective words/s\n",
      "2019-02-26 02:09:41,473: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:09:42,489: INFO: PROGRESS: at 6.69% examples, 699228 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:43,504: INFO: PROGRESS: at 14.00% examples, 736434 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:09:44,504: INFO: PROGRESS: at 22.96% examples, 811799 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:45,519: INFO: PROGRESS: at 32.09% examples, 853530 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:46,522: INFO: PROGRESS: at 41.28% examples, 880642 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:47,532: INFO: PROGRESS: at 50.24% examples, 896336 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:48,532: INFO: PROGRESS: at 59.45% examples, 909956 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:49,535: INFO: PROGRESS: at 68.63% examples, 918966 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:09:50,557: INFO: PROGRESS: at 77.77% examples, 924995 words/s, in_qsize 6, out_qsize 1\n",
      "2019-02-26 02:09:51,574: INFO: PROGRESS: at 86.68% examples, 927580 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:09:52,588: INFO: PROGRESS: at 95.90% examples, 932835 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:09:53,010: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:09:53,012: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:09:53,029: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:09:53,029: INFO: training on 11587581 raw words (10810075 effective words) took 11.6s, 935830 effective words/s\n",
      "2019-02-26 02:09:53,248: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:09:54,254: INFO: PROGRESS: at 8.91% examples, 972251 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:55,261: INFO: PROGRESS: at 17.70% examples, 956226 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:09:56,265: INFO: PROGRESS: at 25.77% examples, 924790 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:57,273: INFO: PROGRESS: at 34.24% examples, 921102 words/s, in_qsize 4, out_qsize 1\n",
      "2019-02-26 02:09:58,292: INFO: PROGRESS: at 43.33% examples, 932745 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:09:59,295: INFO: PROGRESS: at 52.34% examples, 938710 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:00,309: INFO: PROGRESS: at 61.55% examples, 945841 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:01,310: INFO: PROGRESS: at 70.54% examples, 948243 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:10:02,311: INFO: PROGRESS: at 79.64% examples, 950124 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:03,312: INFO: PROGRESS: at 88.53% examples, 950458 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:10:04,330: INFO: PROGRESS: at 97.78% examples, 954095 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:04,548: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:10:04,553: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:10:04,553: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:10:04,554: INFO: training on 11587581 raw words (10810013 effective words) took 11.3s, 956384 effective words/s\n",
      "2019-02-26 02:10:04,773: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:10:05,786: INFO: PROGRESS: at 9.08% examples, 974530 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:06,789: INFO: PROGRESS: at 17.48% examples, 944539 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:07,790: INFO: PROGRESS: at 26.13% examples, 942140 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:08,793: INFO: PROGRESS: at 34.92% examples, 941394 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:09,804: INFO: PROGRESS: at 43.61% examples, 939685 words/s, in_qsize 6, out_qsize 1\n",
      "2019-02-26 02:10:10,806: INFO: PROGRESS: at 51.94% examples, 935674 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:11,813: INFO: PROGRESS: at 60.88% examples, 938683 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:12,818: INFO: PROGRESS: at 69.85% examples, 941127 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:13,826: INFO: PROGRESS: at 78.95% examples, 942966 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:10:14,831: INFO: PROGRESS: at 87.90% examples, 945552 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:10:15,833: INFO: PROGRESS: at 96.84% examples, 947134 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:16,171: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:10:16,172: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:10:16,176: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:10:16,177: INFO: training on 11587581 raw words (10811441 effective words) took 11.4s, 948809 effective words/s\n",
      "2019-02-26 02:10:16,398: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:10:17,407: INFO: PROGRESS: at 9.22% examples, 976774 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:10:18,407: INFO: PROGRESS: at 17.92% examples, 961562 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:19,414: INFO: PROGRESS: at 27.06% examples, 966897 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:20,424: INFO: PROGRESS: at 36.28% examples, 973046 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:21,430: INFO: PROGRESS: at 45.30% examples, 973145 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:22,443: INFO: PROGRESS: at 54.27% examples, 972338 words/s, in_qsize 5, out_qsize 2\n",
      "2019-02-26 02:10:23,454: INFO: PROGRESS: at 63.27% examples, 971121 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:24,461: INFO: PROGRESS: at 72.18% examples, 968763 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:10:25,483: INFO: PROGRESS: at 81.01% examples, 963739 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:26,493: INFO: PROGRESS: at 89.98% examples, 963417 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:10:27,497: INFO: PROGRESS: at 99.15% examples, 965515 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:27,576: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:10:27,579: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:10:27,591: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:10:27,592: INFO: training on 11587581 raw words (10809480 effective words) took 11.2s, 965923 effective words/s\n",
      "2019-02-26 02:10:27,806: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:10:28,813: INFO: PROGRESS: at 8.87% examples, 943615 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:29,816: INFO: PROGRESS: at 18.02% examples, 961852 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:10:30,822: INFO: PROGRESS: at 27.43% examples, 973987 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:31,822: INFO: PROGRESS: at 36.38% examples, 974884 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:32,826: INFO: PROGRESS: at 45.55% examples, 977725 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:10:33,835: INFO: PROGRESS: at 54.82% examples, 981694 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:34,849: INFO: PROGRESS: at 64.14% examples, 984871 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:35,853: INFO: PROGRESS: at 72.94% examples, 979612 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:36,868: INFO: PROGRESS: at 81.95% examples, 978238 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:37,869: INFO: PROGRESS: at 91.05% examples, 978727 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:38,844: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:10:38,845: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:10:38,850: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:10:38,851: INFO: training on 11587581 raw words (10809790 effective words) took 11.0s, 978954 effective words/s\n",
      "2019-02-26 02:10:39,136: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:10:40,156: INFO: PROGRESS: at 5.70% examples, 602383 words/s, in_qsize 5, out_qsize 1\n",
      "2019-02-26 02:10:41,160: INFO: PROGRESS: at 14.30% examples, 762583 words/s, in_qsize 6, out_qsize 1\n",
      "2019-02-26 02:10:42,166: INFO: PROGRESS: at 23.42% examples, 833572 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:43,177: INFO: PROGRESS: at 32.48% examples, 866193 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:44,183: INFO: PROGRESS: at 41.85% examples, 891915 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:45,183: INFO: PROGRESS: at 50.87% examples, 907303 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:46,194: INFO: PROGRESS: at 59.90% examples, 913502 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:47,198: INFO: PROGRESS: at 68.59% examples, 917812 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:48,205: INFO: PROGRESS: at 77.53% examples, 923321 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:10:49,213: INFO: PROGRESS: at 86.44% examples, 927808 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:10:50,215: INFO: PROGRESS: at 95.57% examples, 933146 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:10:50,692: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:10:50,701: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:10:50,707: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:10:50,707: INFO: training on 11587581 raw words (10810340 effective words) took 11.6s, 934618 effective words/s\n",
      "2019-02-26 02:10:50,924: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:10:51,930: INFO: PROGRESS: at 7.91% examples, 853099 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:52,936: INFO: PROGRESS: at 16.93% examples, 913091 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:53,944: INFO: PROGRESS: at 26.02% examples, 933384 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:54,949: INFO: PROGRESS: at 35.19% examples, 947773 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:10:55,954: INFO: PROGRESS: at 44.53% examples, 957561 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:10:56,955: INFO: PROGRESS: at 53.53% examples, 961397 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:10:57,965: INFO: PROGRESS: at 62.31% examples, 958935 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:10:58,980: INFO: PROGRESS: at 71.22% examples, 956945 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:10:59,992: INFO: PROGRESS: at 80.23% examples, 957366 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:00,999: INFO: PROGRESS: at 89.47% examples, 960024 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:02,004: INFO: PROGRESS: at 98.33% examples, 959894 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:02,168: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:11:02,176: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:11:02,185: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:11:02,185: INFO: training on 11587581 raw words (10810751 effective words) took 11.3s, 960429 effective words/s\n",
      "2019-02-26 02:11:02,423: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:11:03,429: INFO: PROGRESS: at 8.82% examples, 970285 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:04,431: INFO: PROGRESS: at 17.82% examples, 970880 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:11:05,436: INFO: PROGRESS: at 27.09% examples, 979877 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:11:06,440: INFO: PROGRESS: at 36.39% examples, 984413 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:07,441: INFO: PROGRESS: at 45.38% examples, 980175 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:08,444: INFO: PROGRESS: at 53.97% examples, 969618 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:09,444: INFO: PROGRESS: at 62.84% examples, 967722 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:11:10,447: INFO: PROGRESS: at 71.71% examples, 968797 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:11,459: INFO: PROGRESS: at 80.71% examples, 966718 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:11:12,471: INFO: PROGRESS: at 89.81% examples, 966030 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:11:13,484: INFO: PROGRESS: at 99.03% examples, 968151 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:11:13,569: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:11:13,575: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:11:13,575: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:11:13,576: INFO: training on 11587581 raw words (10810667 effective words) took 11.1s, 969620 effective words/s\n",
      "2019-02-26 02:11:13,793: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:11:14,808: INFO: PROGRESS: at 9.11% examples, 977802 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:11:15,823: INFO: PROGRESS: at 18.37% examples, 978222 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:11:16,826: INFO: PROGRESS: at 27.53% examples, 983434 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:17,840: INFO: PROGRESS: at 36.81% examples, 986502 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:18,850: INFO: PROGRESS: at 45.78% examples, 981563 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:19,861: INFO: PROGRESS: at 54.76% examples, 976878 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:20,879: INFO: PROGRESS: at 63.77% examples, 974920 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:21,884: INFO: PROGRESS: at 72.78% examples, 973952 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:22,891: INFO: PROGRESS: at 81.19% examples, 966199 words/s, in_qsize 4, out_qsize 1\n",
      "2019-02-26 02:11:23,900: INFO: PROGRESS: at 90.19% examples, 965763 words/s, in_qsize 4, out_qsize 1\n",
      "2019-02-26 02:11:24,909: INFO: PROGRESS: at 99.27% examples, 965935 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:11:24,966: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:11:24,971: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:11:24,980: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:11:24,981: INFO: training on 11587581 raw words (10810737 effective words) took 11.2s, 967000 effective words/s\n",
      "2019-02-26 02:11:25,196: INFO: training model with 3 workers on 100034 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-26 02:11:26,208: INFO: PROGRESS: at 9.10% examples, 971168 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:27,218: INFO: PROGRESS: at 18.42% examples, 981168 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:11:28,223: INFO: PROGRESS: at 27.55% examples, 983567 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:29,224: INFO: PROGRESS: at 36.47% examples, 980928 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:30,238: INFO: PROGRESS: at 45.10% examples, 969285 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:31,239: INFO: PROGRESS: at 53.91% examples, 965346 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:32,243: INFO: PROGRESS: at 62.69% examples, 960518 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:33,246: INFO: PROGRESS: at 71.68% examples, 960781 words/s, in_qsize 5, out_qsize 1\n",
      "2019-02-26 02:11:34,257: INFO: PROGRESS: at 80.89% examples, 963038 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-26 02:11:35,272: INFO: PROGRESS: at 90.04% examples, 965506 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:36,281: INFO: PROGRESS: at 98.53% examples, 961238 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-26 02:11:36,454: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-26 02:11:36,462: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-26 02:11:36,464: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-26 02:11:36,464: INFO: training on 11587581 raw words (10810252 effective words) took 11.3s, 960039 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# train word2vec model ; shuffle data every epoch\n",
    "for i in range(20):\n",
    "    random.shuffle(data)\n",
    "    model.train(data, total_examples=len(data), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.24762085, -0.8977107 , -0.6067121 ,  0.31750113,  0.16057867,\n",
       "        0.34901646,  0.81001127,  0.23419233,  0.7779766 ,  0.30983135,\n",
       "        0.22631015, -1.8175101 ,  1.1944888 ,  1.6416944 , -0.30495656,\n",
       "       -1.433823  ,  0.28768963, -1.0790287 ,  1.0192944 , -0.07710487,\n",
       "       -0.01903037,  0.79018307,  0.25264913, -0.06716511,  0.6858139 ,\n",
       "       -0.12604445, -0.5698138 ,  2.327396  , -0.99093246,  0.67131174,\n",
       "       -0.16539991, -0.3128735 , -0.43180308, -1.9976908 ,  0.7554993 ,\n",
       "       -1.883988  ,  0.5619505 ,  0.14653046,  0.03516036, -0.44651273,\n",
       "        0.28207737,  0.5111326 ,  1.3762465 , -0.9683797 , -0.5359118 ,\n",
       "        0.6463878 ,  0.47309807,  0.41490504, -0.16516861, -1.6284944 ,\n",
       "       -0.31047145,  0.267966  , -1.3487182 , -0.6682791 , -0.14002845,\n",
       "       -0.22394612,  0.08432519, -1.3455534 , -0.6790668 , -0.82799226,\n",
       "       -0.60738003,  0.6808849 , -1.1272975 , -0.5058519 ,  1.0986543 ,\n",
       "        0.80967057, -0.4469238 , -0.4563255 , -0.43787932,  0.49932188,\n",
       "       -0.24078685, -0.6111761 , -1.4299085 ,  0.778296  , -0.74147344,\n",
       "       -0.5443173 ,  0.4324095 ,  0.2907998 , -0.5910882 ,  1.2181752 ,\n",
       "        0.7006152 ,  0.62062603, -0.8616231 , -0.41727808, -0.6036538 ,\n",
       "       -0.06901809,  0.9396616 ,  0.05253107,  1.0171081 ,  1.3431456 ,\n",
       "        0.20350017,  0.24719043,  1.0205808 ,  2.1372411 ,  0.61668897,\n",
       "       -0.34309068,  0.2649916 , -0.09806829, -1.2813303 , -0.20664336,\n",
       "        0.26355398,  2.0109882 , -0.05381325,  0.24069715, -0.8291129 ,\n",
       "        0.26001287, -0.5862279 ,  0.6994503 , -0.45102295, -1.5829759 ,\n",
       "       -0.3954535 , -1.2726697 , -1.3957062 , -0.6775116 ,  0.55436295,\n",
       "        1.4147853 , -2.3533292 , -0.02252374, -0.73614997,  0.48689055,\n",
       "       -0.11901435,  0.32652047, -2.0586803 , -0.13890655, -0.49148133,\n",
       "       -0.33147478,  1.6427232 , -0.40892276,  1.383526  , -2.2088215 ,\n",
       "       -1.0879527 , -0.41726628,  0.14706917, -0.6346257 ,  0.7369185 ,\n",
       "       -0.81021017,  0.7131136 ,  1.2311556 , -2.2922204 ,  1.5006516 ,\n",
       "        1.6231577 ,  1.5763476 ,  0.66011864,  0.49270546, -0.90176654,\n",
       "       -0.5544745 ,  0.78960425, -1.0202414 , -0.5813919 , -0.10054162,\n",
       "       -0.23009098,  2.535661  ,  1.7606003 ,  0.6158943 ,  0.43715325,\n",
       "        0.27109122, -0.40210703, -1.5309534 , -2.5729501 ,  0.45724753,\n",
       "       -1.8499889 , -0.02613885,  0.37663683,  0.4477792 , -0.6508351 ,\n",
       "       -0.90073025,  1.5931392 ,  1.9007838 , -0.63400894, -0.68481165,\n",
       "       -1.0276233 , -0.54507804,  1.8687066 ,  0.27828172,  0.44622278,\n",
       "       -0.3579807 , -1.0099242 ,  0.5116262 ,  1.830201  , -0.40864274,\n",
       "        1.7287166 ,  1.6764137 , -0.39636043,  0.49130452, -0.73451126,\n",
       "        0.7357387 ,  0.07941727, -0.04954223, -0.12931907,  0.11531456,\n",
       "       -1.0252047 , -0.707498  ,  0.05272232, -0.5460945 , -1.0794517 ,\n",
       "        0.37997335,  0.18009232, -0.23581928,  0.6591987 ,  0.6337809 ,\n",
       "       -0.1529202 ,  1.4000231 ,  0.20851383, -1.5409608 , -0.40397173,\n",
       "        0.13690443, -0.35035202, -0.77418214, -0.24593915, -0.98954827,\n",
       "        0.8824187 , -0.9790348 , -1.6153773 ,  0.1373269 , -0.7869627 ,\n",
       "       -0.19047284, -1.5671626 ,  0.70979464,  0.15844326,  1.4743915 ,\n",
       "        0.09859458,  0.63320404, -0.08795628,  0.04946853,  1.0328639 ,\n",
       "       -0.11376671,  0.24303883,  1.0575943 ,  0.8241544 ,  0.3962834 ,\n",
       "       -1.4247417 , -0.11479066,  0.29859212, -0.81219536, -1.4013319 ,\n",
       "        1.5322927 , -1.1851368 , -0.27289313, -0.25303018, -1.3394191 ,\n",
       "       -0.46607727, -1.7274991 ,  0.82130057,  1.7002834 , -1.3031439 ,\n",
       "       -0.7434414 ,  0.04336534,  0.71342987, -0.08161399,  2.1518507 ,\n",
       "       -0.03345567, -0.29798022, -0.5025256 , -0.2890242 , -0.6591678 ,\n",
       "       -0.27994406], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print an example\n",
    "model.wv['人工智慧']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-26 02:11:36,517: INFO: saving Word2Vec object under word2vec_model/CBOW, separately None\n",
      "2019-02-26 02:11:36,518: INFO: storing np array 'syn0' to word2vec_model/CBOW.wv.syn0.npy\n",
      "2019-02-26 02:11:38,568: INFO: not storing attribute syn0norm\n",
      "2019-02-26 02:11:38,569: INFO: storing np array 'syn1neg' to word2vec_model/CBOW.syn1neg.npy\n",
      "2019-02-26 02:11:40,656: INFO: not storing attribute cum_table\n",
      "2019-02-26 02:11:41,101: INFO: saved word2vec_model/CBOW\n"
     ]
    }
   ],
   "source": [
    "## save model\n",
    "model.save('word2vec_model/CBOW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 嘗試調整 word2vec 的參數 , etc. sg = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
