{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import load_data, load_test_data\n",
    "from utils import num_classes, epochs, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = load_data(test_size=0.2, img_size=360,Gray2RGB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a classic CNN model\n",
    "model_name = 'classic_CNN_GlobalAveragePooling2D'\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=X_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator with augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='constant',\n",
    "    cval=0)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=10e-4)\n",
    "\n",
    "model_path = './saved_models/CNN_051101.h5'.format(model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_acc', save_best_only=True, verbose=1)\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=16, verbose=1)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, metrics=['accuracy'])\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "batch_size = 64\n",
    "aug_ratio = 2\n",
    "epochs = 400\n",
    "steps_per_epoch = int(aug_ratio * X_train.shape[0] / batch_size)\n",
    "validation_steps = int(aug_ratio * X_valid.shape[0] / batch_size)\n",
    "model_history = model.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size),\n",
    "                                    epochs = epochs,\n",
    "                                    validation_data = (X_valid, y_valid),\n",
    "                                    callbacks = [checkpoint,earlystop],\n",
    "                                    steps_per_epoch=steps_per_epoch,\n",
    "                                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.plot(training_loss, 'b', label=\"training_loss\")\n",
    "plt.plot(val_loss, 'r', label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc = model_history.history['acc']\n",
    "val_acc = model_history.history['val_acc']\n",
    "\n",
    "plt.plot(training_acc, 'b', label=\"training_acc\")\n",
    "plt.plot(val_acc, 'r', label=\"validation_acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_id = load_test_data(Gray2RGB=True, img_size=360)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './saved_models/CNN_051101.h5'.format(model_name)\n",
    "model = load_model(model_path)\n",
    "\n",
    "#scores = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "#print('Validation loss:', scores[0])\n",
    "#print('Validation accuracy:', scores[1])\n",
    "\n",
    "y_test_pred = model.predict_classes(X_test)\n",
    "y_test_pred_df = pd.DataFrame({'id': np.array(X_id), 'class':y_test_pred}).sort_values(by='id')\n",
    "y_test_pred_df.to_csv('CNN_051101.csv'.format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a classic CNN model\n",
    "model_name = 'classic_CNN_GlobalAveragePooling2D'\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=X_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator with augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='constant',\n",
    "    cval=0)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=10e-6)\n",
    "\n",
    "model_path = './saved_models/{}.h5'.format(model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, metrics=['accuracy'])\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "batch_size = 16\n",
    "aug_ratio = 1\n",
    "epochs = 200\n",
    "steps_per_epoch = int(aug_ratio * X_train.shape[0] / batch_size)\n",
    "validation_steps = int(aug_ratio * X_valid.shape[0] / batch_size)\n",
    "model_history = model.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size),\n",
    "                                    epochs = epochs,\n",
    "                                    validation_data = (X_valid, y_valid),\n",
    "                                    callbacks = [checkpoint, earlystop],\n",
    "                                    steps_per_epoch=steps_per_epoch,\n",
    "                                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc = model_history.history['acc']\n",
    "val_acc = model_history.history['val_acc']\n",
    "\n",
    "plt.plot(training_acc, label=\"training_acc\")\n",
    "plt.plot(val_acc, label=\"validation_acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_id = load_test_data()\n",
    "\n",
    "model_path = './saved_models/{}.h5'.format(model_name)\n",
    "model = load_model(model_path)\n",
    "\n",
    "scores = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('Validation loss:', scores[0])\n",
    "print('Validation accuracy:', scores[1])\n",
    "\n",
    "y_test_pred = model.predict_classes(X_test)\n",
    "y_test_pred_df = pd.DataFrame({'id': np.array(X_id), 'class':y_test_pred}).sort_values(by='id')\n",
    "y_test_pred_df.to_csv('./submissions/{}.csv'.format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
