{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以 VGG16 為例，來示範 Transfer Learning 的作法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import load_data, load_test_data\n",
    "from utils import num_classes, epochs, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = load_data(Gray2RGB=True, mean_proc='VGG16_ImageNet', img_size=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取 pretrain model 可選擇要不要使用它末端的 dense layers\n",
    "\n",
    "* include_top = True，會沿用 pre-trained model 後端的全連接層\n",
    "* include_top = False，只會留 pre-trained model 的 CNN 層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning & Layer Transfer\n",
    "\n",
    "* Fine tuning：不鎖 layers，pre-trained model 的每一層都可以再訓練\n",
    "* Layer transfer：鎖住 pre-trained model 的 layers，只訓練自己額外加的 dense layers\n",
    "\n",
    "實務上 fine tuning 跟 layer transfer 不會分這麼清楚，不一定會全鎖或全不鎖，你可能會留 CNN 的後面幾層是可以訓練的，但鎖住前面幾層做特徵萃取器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning 實例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 5s 0us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 15)                376335    \n",
      "=================================================================\n",
      "Total params: 15,091,023\n",
      "Trainable params: 15,091,023\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 此例完全不鎖層，充分的 fine tuning\n",
    "model_name = 'VGG16-Fine-Tune'\n",
    "\n",
    "img_rows, img_cols, img_channel = 224, 224, 3\n",
    "\n",
    "base_model = keras.applications.vgg16.VGG16(weights='imagenet', include_top=False,\n",
    "                                            input_shape=(img_rows, img_cols, img_channel))\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3,3,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/Variable_48/Assign = AssignVariableOp[_grappler_relax_allocator_constraints=true, dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/Adam/Variable_48, training/Adam/zeros_16)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training/Adam/Variable_48/Assign', defined at:\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-2a635a5dc77a>\", line 23, in <module>\n    callbacks = [checkpoint, earlystop])\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1779, in fit_generator\n    initial_epoch=initial_epoch)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\", line 204, in fit_generator\n    x, y, sample_weight=sample_weight, class_weight=class_weight)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1551, in train_on_batch\n    self._make_train_function()\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 598, in _make_train_function\n    params=self._collected_trainable_weights, loss=self.total_loss)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/optimizers.py\", line 472, in get_updates\n    vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/optimizers.py\", line 472, in <listcomp>\n    vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 972, in zeros\n    return variable(v, dtype=dtype, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 648, in variable\n    constraint=constraint)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 312, in __init__\n    constraint=constraint)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 478, in _init_from_args\n    name=n))\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 157, in assign_variable_op\n    \"AssignVariableOp\", resource=resource, value=value, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,3,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/Variable_48/Assign = AssignVariableOp[_grappler_relax_allocator_constraints=true, dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/Adam/Variable_48, training/Adam/zeros_16)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/Variable_48/Assign = AssignVariableOp[_grappler_relax_allocator_constraints=true, dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/Adam/Variable_48, training/Adam/zeros_16)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2a635a5dc77a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                                     callbacks = [checkpoint, earlystop])\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         outs = model.train_on_batch(\n\u001b[0;32m--> 204\u001b[0;31m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2874\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`inputs` should be a list or tuple.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2876\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2877\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2878\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m       \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/Variable_48/Assign = AssignVariableOp[_grappler_relax_allocator_constraints=true, dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/Adam/Variable_48, training/Adam/zeros_16)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training/Adam/Variable_48/Assign', defined at:\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-2a635a5dc77a>\", line 23, in <module>\n    callbacks = [checkpoint, earlystop])\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1779, in fit_generator\n    initial_epoch=initial_epoch)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\", line 204, in fit_generator\n    x, y, sample_weight=sample_weight, class_weight=class_weight)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1551, in train_on_batch\n    self._make_train_function()\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 598, in _make_train_function\n    params=self._collected_trainable_weights, loss=self.total_loss)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/optimizers.py\", line 472, in get_updates\n    vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/optimizers.py\", line 472, in <listcomp>\n    vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 972, in zeros\n    return variable(v, dtype=dtype, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 648, in variable\n    constraint=constraint)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 312, in __init__\n    constraint=constraint)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 478, in _init_from_args\n    name=n))\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 157, in assign_variable_op\n    \"AssignVariableOp\", resource=resource, value=value, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,3,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/Variable_48/Assign = AssignVariableOp[_grappler_relax_allocator_constraints=true, dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/Adam/Variable_48, training/Adam/zeros_16)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=10e-6)\n",
    "\n",
    "model_path = './saved_models/TCNN0501.h5'.format(model_name)\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model_history = model.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size),\n",
    "                                    epochs = epochs,\n",
    "                                    validation_data = (X_valid, y_valid),\n",
    "                                    callbacks = [checkpoint, earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc = model_history.history['acc']\n",
    "val_acc = model_history.history['val_acc']\n",
    "\n",
    "plt.plot(training_acc, label=\"training_acc\")\n",
    "plt.plot(val_acc, label=\"validation_acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_path)\n",
    "\n",
    "scores = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('Validation loss:', scores[0])\n",
    "print('Validation accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_id = load_test_data(Gray2RGB=True, mean_proc='VGG16_ImageNet')\n",
    "\n",
    "y_test_pred_prob = model.predict(X_test)\n",
    "y_test_pred = y_test_pred_prob.argmax(axis=-1)\n",
    "y_test_pred_df = pd.DataFrame({'id': np.array(X_id), 'class':y_test_pred}).sort_values(by='id')\n",
    "y_test_pred_df.to_csv('./submissions/TCNN0501.csv'.format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Transfer 實例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                376335    \n",
      "=================================================================\n",
      "Total params: 15,091,023\n",
      "Trainable params: 376,335\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 此例的 VGG pre-trained layers 完全鎖住，充分的 layer transfer\n",
    "model_name = 'VGG16-Layer-Transfer'\n",
    "\n",
    "img_rows, img_cols, img_channel = 224, 224, 3\n",
    "\n",
    "base_model = keras.applications.vgg16.VGG16(weights='imagenet',\n",
    "                                            include_top=False, input_shape=(img_rows, img_cols, img_channel))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 2.3714 - acc: 0.2367\n",
      "Epoch 00001: val_loss improved from inf to 1.44165, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 21s 301ms/step - loss: 2.3599 - acc: 0.2404 - val_loss: 1.4417 - val_acc: 0.6345\n",
      "Epoch 2/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 1.5685 - acc: 0.4746\n",
      "Epoch 00002: val_loss improved from 1.44165 to 0.99773, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 254ms/step - loss: 1.5659 - acc: 0.4746 - val_loss: 0.9977 - val_acc: 0.7590\n",
      "Epoch 3/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 1.2332 - acc: 0.5979\n",
      "Epoch 00003: val_loss improved from 0.99773 to 0.78836, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 262ms/step - loss: 1.2305 - acc: 0.5979 - val_loss: 0.7884 - val_acc: 0.8046\n",
      "Epoch 4/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 1.0798 - acc: 0.6450\n",
      "Epoch 00004: val_loss improved from 0.78836 to 0.68523, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 263ms/step - loss: 1.0808 - acc: 0.6438 - val_loss: 0.6852 - val_acc: 0.8059\n",
      "Epoch 5/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.9166 - acc: 0.6976\n",
      "Epoch 00005: val_loss improved from 0.68523 to 0.60823, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 264ms/step - loss: 0.9210 - acc: 0.6956 - val_loss: 0.6082 - val_acc: 0.8327\n",
      "Epoch 6/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.8582 - acc: 0.7176\n",
      "Epoch 00006: val_loss improved from 0.60823 to 0.56057, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 260ms/step - loss: 0.8564 - acc: 0.7180 - val_loss: 0.5606 - val_acc: 0.8353\n",
      "Epoch 7/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.8007 - acc: 0.7331\n",
      "Epoch 00007: val_loss improved from 0.56057 to 0.53351, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 259ms/step - loss: 0.8003 - acc: 0.7329 - val_loss: 0.5335 - val_acc: 0.8353\n",
      "Epoch 8/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.7411 - acc: 0.7638\n",
      "Epoch 00008: val_loss improved from 0.53351 to 0.49166, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 257ms/step - loss: 0.7419 - acc: 0.7645 - val_loss: 0.4917 - val_acc: 0.8635\n",
      "Epoch 9/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.7085 - acc: 0.7751\n",
      "Epoch 00009: val_loss improved from 0.49166 to 0.46696, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 257ms/step - loss: 0.7071 - acc: 0.7743 - val_loss: 0.4670 - val_acc: 0.8568\n",
      "Epoch 10/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.6586 - acc: 0.7901\n",
      "Epoch 00010: val_loss improved from 0.46696 to 0.44552, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 262ms/step - loss: 0.6549 - acc: 0.7913 - val_loss: 0.4455 - val_acc: 0.8675\n",
      "Epoch 11/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.6201 - acc: 0.7938\n",
      "Epoch 00011: val_loss improved from 0.44552 to 0.42319, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 19s 265ms/step - loss: 0.6205 - acc: 0.7940 - val_loss: 0.4232 - val_acc: 0.8809\n",
      "Epoch 12/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5920 - acc: 0.8106\n",
      "Epoch 00012: val_loss improved from 0.42319 to 0.41591, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 261ms/step - loss: 0.5898 - acc: 0.8111 - val_loss: 0.4159 - val_acc: 0.8782\n",
      "Epoch 13/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5795 - acc: 0.8115\n",
      "Epoch 00013: val_loss improved from 0.41591 to 0.39952, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 258ms/step - loss: 0.5788 - acc: 0.8115 - val_loss: 0.3995 - val_acc: 0.8782\n",
      "Epoch 14/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5656 - acc: 0.8160\n",
      "Epoch 00014: val_loss improved from 0.39952 to 0.39001, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 19s 265ms/step - loss: 0.5629 - acc: 0.8168 - val_loss: 0.3900 - val_acc: 0.8782\n",
      "Epoch 15/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5401 - acc: 0.8256\n",
      "Epoch 00015: val_loss improved from 0.39001 to 0.37977, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 261ms/step - loss: 0.5390 - acc: 0.8254 - val_loss: 0.3798 - val_acc: 0.8782\n",
      "Epoch 16/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5226 - acc: 0.8315\n",
      "Epoch 00016: val_loss improved from 0.37977 to 0.37113, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 263ms/step - loss: 0.5215 - acc: 0.8312 - val_loss: 0.3711 - val_acc: 0.8835\n",
      "Epoch 17/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4953 - acc: 0.8418\n",
      "Epoch 00017: val_loss improved from 0.37113 to 0.36759, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 261ms/step - loss: 0.4957 - acc: 0.8414 - val_loss: 0.3676 - val_acc: 0.8849\n",
      "Epoch 18/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4822 - acc: 0.8490\n",
      "Epoch 00018: val_loss improved from 0.36759 to 0.36182, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 261ms/step - loss: 0.4826 - acc: 0.8480 - val_loss: 0.3618 - val_acc: 0.8795\n",
      "Epoch 19/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4744 - acc: 0.8527\n",
      "Epoch 00019: val_loss improved from 0.36182 to 0.35846, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 259ms/step - loss: 0.4723 - acc: 0.8548 - val_loss: 0.3585 - val_acc: 0.8862\n",
      "Epoch 20/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4692 - acc: 0.8459\n",
      "Epoch 00020: val_loss improved from 0.35846 to 0.35784, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 258ms/step - loss: 0.4675 - acc: 0.8468 - val_loss: 0.3578 - val_acc: 0.8809\n",
      "Epoch 21/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4579 - acc: 0.8527\n",
      "Epoch 00021: val_loss improved from 0.35784 to 0.34793, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 257ms/step - loss: 0.4562 - acc: 0.8530 - val_loss: 0.3479 - val_acc: 0.8795\n",
      "Epoch 22/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4501 - acc: 0.8549\n",
      "Epoch 00022: val_loss improved from 0.34793 to 0.34395, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 260ms/step - loss: 0.4482 - acc: 0.8556 - val_loss: 0.3439 - val_acc: 0.8862\n",
      "Epoch 23/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4262 - acc: 0.8591\n",
      "Epoch 00023: val_loss improved from 0.34395 to 0.33603, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 258ms/step - loss: 0.4283 - acc: 0.8579 - val_loss: 0.3360 - val_acc: 0.8916\n",
      "Epoch 24/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4254 - acc: 0.8731\n",
      "Epoch 00024: val_loss improved from 0.33603 to 0.32125, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 260ms/step - loss: 0.4269 - acc: 0.8718 - val_loss: 0.3212 - val_acc: 0.8862\n",
      "Epoch 25/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4077 - acc: 0.8690\n",
      "Epoch 00025: val_loss improved from 0.32125 to 0.31294, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 259ms/step - loss: 0.4080 - acc: 0.8690 - val_loss: 0.3129 - val_acc: 0.8956\n",
      "Epoch 26/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4057 - acc: 0.8700\n",
      "Epoch 00026: val_loss did not improve from 0.31294\n",
      "70/70 [==============================] - 18s 258ms/step - loss: 0.4053 - acc: 0.8705 - val_loss: 0.3157 - val_acc: 0.8916\n",
      "Epoch 27/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4071 - acc: 0.8713\n",
      "Epoch 00027: val_loss did not improve from 0.31294\n",
      "70/70 [==============================] - 18s 260ms/step - loss: 0.4047 - acc: 0.8722 - val_loss: 0.3230 - val_acc: 0.8876\n",
      "Epoch 28/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3881 - acc: 0.8708\n",
      "Epoch 00028: val_loss did not improve from 0.31294\n",
      "70/70 [==============================] - 18s 260ms/step - loss: 0.3860 - acc: 0.8718 - val_loss: 0.3310 - val_acc: 0.8782\n",
      "Epoch 29/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4061 - acc: 0.8685\n",
      "Epoch 00029: val_loss did not improve from 0.31294\n",
      "70/70 [==============================] - 18s 260ms/step - loss: 0.4055 - acc: 0.8682 - val_loss: 0.3172 - val_acc: 0.8929\n",
      "Epoch 30/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3640 - acc: 0.8794\n",
      "Epoch 00030: val_loss improved from 0.31294 to 0.30796, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 259ms/step - loss: 0.3636 - acc: 0.8794 - val_loss: 0.3080 - val_acc: 0.8942\n",
      "Epoch 31/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3674 - acc: 0.8822\n",
      "Epoch 00031: val_loss improved from 0.30796 to 0.30726, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 258ms/step - loss: 0.3654 - acc: 0.8821 - val_loss: 0.3073 - val_acc: 0.8929\n",
      "Epoch 32/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3525 - acc: 0.8903\n",
      "Epoch 00032: val_loss improved from 0.30726 to 0.30550, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 262ms/step - loss: 0.3530 - acc: 0.8897 - val_loss: 0.3055 - val_acc: 0.8983\n",
      "Epoch 33/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3613 - acc: 0.8822\n",
      "Epoch 00033: val_loss improved from 0.30550 to 0.30127, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 264ms/step - loss: 0.3630 - acc: 0.8816 - val_loss: 0.3013 - val_acc: 0.8902\n",
      "Epoch 34/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3729 - acc: 0.8794\n",
      "Epoch 00034: val_loss did not improve from 0.30127\n",
      "70/70 [==============================] - 18s 255ms/step - loss: 0.3732 - acc: 0.8793 - val_loss: 0.3016 - val_acc: 0.8956\n",
      "Epoch 35/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3411 - acc: 0.8839\n",
      "Epoch 00035: val_loss improved from 0.30127 to 0.29526, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 260ms/step - loss: 0.3396 - acc: 0.8847 - val_loss: 0.2953 - val_acc: 0.8969\n",
      "Epoch 36/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3553 - acc: 0.8854\n",
      "Epoch 00036: val_loss did not improve from 0.29526\n",
      "70/70 [==============================] - 18s 256ms/step - loss: 0.3535 - acc: 0.8861 - val_loss: 0.2988 - val_acc: 0.8983\n",
      "Epoch 37/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3282 - acc: 0.9016\n",
      "Epoch 00037: val_loss did not improve from 0.29526\n",
      "70/70 [==============================] - 18s 256ms/step - loss: 0.3291 - acc: 0.9017 - val_loss: 0.3028 - val_acc: 0.8996\n",
      "Epoch 38/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3350 - acc: 0.8894\n",
      "Epoch 00038: val_loss improved from 0.29526 to 0.28693, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 262ms/step - loss: 0.3342 - acc: 0.8896 - val_loss: 0.2869 - val_acc: 0.8996\n",
      "Epoch 39/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3295 - acc: 0.9003\n",
      "Epoch 00039: val_loss did not improve from 0.28693\n",
      "70/70 [==============================] - 18s 259ms/step - loss: 0.3283 - acc: 0.9013 - val_loss: 0.2983 - val_acc: 0.8942\n",
      "Epoch 40/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3165 - acc: 0.9003\n",
      "Epoch 00040: val_loss did not improve from 0.28693\n",
      "70/70 [==============================] - 18s 257ms/step - loss: 0.3193 - acc: 0.8986 - val_loss: 0.2980 - val_acc: 0.9023\n",
      "Epoch 41/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3237 - acc: 0.8980\n",
      "Epoch 00041: val_loss did not improve from 0.28693\n",
      "70/70 [==============================] - 19s 266ms/step - loss: 0.3234 - acc: 0.8985 - val_loss: 0.3091 - val_acc: 0.8876\n",
      "Epoch 42/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3195 - acc: 0.8922\n",
      "Epoch 00042: val_loss did not improve from 0.28693\n",
      "70/70 [==============================] - 18s 260ms/step - loss: 0.3178 - acc: 0.8933 - val_loss: 0.2929 - val_acc: 0.9036\n",
      "Epoch 43/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3199 - acc: 0.8962\n",
      "Epoch 00043: val_loss improved from 0.28693 to 0.28404, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 256ms/step - loss: 0.3205 - acc: 0.8963 - val_loss: 0.2840 - val_acc: 0.9063\n",
      "Epoch 44/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3028 - acc: 0.9047\n",
      "Epoch 00044: val_loss improved from 0.28404 to 0.28336, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 262ms/step - loss: 0.3043 - acc: 0.9043 - val_loss: 0.2834 - val_acc: 0.9023\n",
      "Epoch 45/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.2983 - acc: 0.9117\n",
      "Epoch 00045: val_loss improved from 0.28336 to 0.28063, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 259ms/step - loss: 0.2985 - acc: 0.9116 - val_loss: 0.2806 - val_acc: 0.9063\n",
      "Epoch 46/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.2926 - acc: 0.9062\n",
      "Epoch 00046: val_loss did not improve from 0.28063\n",
      "70/70 [==============================] - 18s 256ms/step - loss: 0.2922 - acc: 0.9066 - val_loss: 0.2817 - val_acc: 0.8956\n",
      "Epoch 47/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.2891 - acc: 0.9067\n",
      "Epoch 00047: val_loss improved from 0.28063 to 0.27824, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 18s 257ms/step - loss: 0.2928 - acc: 0.9049 - val_loss: 0.2782 - val_acc: 0.9050\n",
      "Epoch 48/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.2905 - acc: 0.9111\n",
      "Epoch 00048: val_loss did not improve from 0.27824\n",
      "70/70 [==============================] - 18s 254ms/step - loss: 0.2921 - acc: 0.9106 - val_loss: 0.2816 - val_acc: 0.9036\n",
      "Epoch 49/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3014 - acc: 0.9035\n",
      "Epoch 00049: val_loss improved from 0.27824 to 0.26611, saving model to ./saved_models/VGG16-Layer-Transfer.h5\n",
      "70/70 [==============================] - 19s 264ms/step - loss: 0.3002 - acc: 0.9036 - val_loss: 0.2661 - val_acc: 0.9130\n",
      "Epoch 50/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.2994 - acc: 0.8966\n",
      "Epoch 00050: val_loss did not improve from 0.26611\n",
      "70/70 [==============================] - 18s 258ms/step - loss: 0.2969 - acc: 0.8981 - val_loss: 0.2855 - val_acc: 0.9023\n",
      "Epoch 51/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.2770 - acc: 0.9160\n",
      "Epoch 00051: val_loss did not improve from 0.26611\n",
      "70/70 [==============================] - 18s 257ms/step - loss: 0.2762 - acc: 0.9159 - val_loss: 0.2761 - val_acc: 0.9050\n",
      "Epoch 52/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.2945 - acc: 0.9025\n",
      "Epoch 00052: val_loss did not improve from 0.26611\n",
      "70/70 [==============================] - 18s 257ms/step - loss: 0.2946 - acc: 0.9030 - val_loss: 0.2766 - val_acc: 0.9050\n",
      "Epoch 53/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.2766 - acc: 0.9102\n",
      "Epoch 00053: val_loss did not improve from 0.26611\n",
      "70/70 [==============================] - 18s 255ms/step - loss: 0.2774 - acc: 0.9101 - val_loss: 0.2682 - val_acc: 0.9103\n",
      "Epoch 54/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.2602 - acc: 0.9157\n",
      "Epoch 00054: val_loss did not improve from 0.26611\n",
      "70/70 [==============================] - 18s 259ms/step - loss: 0.2605 - acc: 0.9160 - val_loss: 0.2799 - val_acc: 0.8983\n",
      "Epoch 00054: early stopping\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=10e-5)\n",
    "\n",
    "model_path = './saved_models/{}.h5'.format(model_name)\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model_history = model.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size),\n",
    "                                    epochs = epochs,\n",
    "                                    validation_data = (X_valid, y_valid),\n",
    "                                    callbacks = [checkpoint, earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xl8VPW5+PHPM5PJvi8kgSQkIJuIgCCLiHsRFdeCXFqtUJVbrq3a23pr++vvulR/3axtrV6p1t1qFbdaq1XkoogiCMi+L4EEQvaQPZnMfH9/nJMwQDYgk2Eyz/v1mtfMnDlz5jkhzJPv9hwxxqCUUkoBOAIdgFJKqdOHJgWllFJtNCkopZRqo0lBKaVUG00KSiml2mhSUEop1UaTglJdEJEPROSWQMehVG/QpKBOWyKSLyKXBToOY8wVxpgX/HFsEYkXkT+IyH4RqRWR3fbzVH98nlJd0aSgQpqIhAXws8OBJcBIYDoQD0wGyoEJJ3G8gJ2L6js0KaigJCIzRGSdiFSJyBcicrbPa/faf3HXiMgWEbne57W5IvK5iPxeRMqB++1ty0XkERGpFJG9InKFz3s+EZHbfN7f2b55IrLM/uyPReQJEXm5g9P4DpADXG+M2WKM8RpjSowxvzDGvG8fz4jIGT7Hf15EHrIfXyQihSLyExE5BDwnIltFZIbP/mEiUioi59jPJ9k/ryoRWS8iF53Kv4PqezQpqKAjImOBZ4F/B1KAPwPvikiEvctuYCqQADwAvCwimT6HmAjsAdKBh322bQdSgd8Az4iIdBBCZ/u+Aqyy47ofuLmTU7kM+Jcxprbrs+5QBpAMDATmA68Cc3xevxwoM8asFZEBwD+Bh+z3/Bh4U0TSTuHzVR+jSUEFo/nAn40xK40xHru/vwmYBGCMWWSMOWj/5f0asJOju2MOGmP+ZIxpMcY02Nv2GWOeNsZ4gBeATKyk0Z529xWRHOBc4L+NMc3GmOXAu52cRwpQdFI/gSO8wH3GmCb7XF4BrhGRaPv1b2ElCoCbgPeNMe/bP5vFwGrgylOMQfUhmhRUMBoI/MjuAqkSkSogG+gPICLf8elaqgLOwvqrvlVBO8c81PrAGFNvP4zt4PM72rc/UOGzraPPalWOlVBORakxptEnnl3AVuBqOzFcg5UowPq5zTrm53Z+D8Sg+hAdmFLBqAB42Bjz8LEviMhA4GngUmCFMcYjIusA364gf5UGLgKSRSTaJzFkd7L/x8BDIhJjjKnrYJ96INrneQZQ6PO8vXNp7UJyAFvsRAHWz+0lY8ztXZyHCmHaUlCnO5eIRPrcwrC+9L8nIhPFEiMiV4lIHBCD9UVZCiAi87BaCn5njNmH1R1zv4iEi8hk4OpO3vIS1hf1myIyXEQcIpIiIj8TkdYunXXAt0TEKSLTgQu7EcrfgGnAAo60EgBexmpBXG4fL9IerM46wVNVfZgmBXW6ex9o8Lndb4xZDdwOPA5UAruAuQDGmC3A74AVQDEwCvi8F+P9NkemlT4EvIY13nEcY0wT1mDzNmAxUI01SJ0KrLR3uwsrsVTZx36nqwCMMUVY53+e/fmt2wuAa4GfYSXNAuAe9HtA+RC9yI5S/iMirwHbjDH3BToWpbpD/0JQqgeJyLkiMtjuCpqO9Zd5l3/dK3W60IFmpXpWBvAW1nTTQmCBMebrwIakVPdp95FSSqk22n2klFKqTdB1H6Wmpprc3NxAh6GUUkFlzZo1ZcaYLkuaBF1SyM3NZfXq1YEOQymlgoqI7OvOftp9pJRSqo0mBaWUUm00KSillGoTdGMKSqne43a7KSwspLGxseud1WkhMjKSrKwsXC7XSb1fk4JSqkOFhYXExcWRm5tLx9ccUqcLYwzl5eUUFhaSl5d3UsfQ7iOlVIcaGxtJSUnRhBAkRISUlJRTatlpUlBKdUoTQnA51X+vkEkK2w/V8MiH26msaw50KEopddoKmaSwt6yOx5fu4kBVQ9c7K6VUiAqZpJAcEw5AVb07wJEopbqrqqqK//mf/znh91155ZVUVVV1us9///d/8/HHH59saO2Kje3ost7BI2SSQlK0NT2rol67j5QKFh0lhZaWlk7f9/7775OYmNjpPg8++CCXXXbZKcXXF4XMlNQku6WgYwpKnZwH/rGZLQere/SYZ/aP576rR3b4+r333svu3bsZM2YMLpeLyMhIkpKS2LZtGzt27OC6666joKCAxsZG7rrrLubPnw8cqZFWW1vLFVdcwfnnn88XX3zBgAED+Pvf/05UVBRz585lxowZzJw5k9zcXG655Rb+8Y9/4Ha7WbRoEcOHD6e0tJRvfetbHDx4kMmTJ7N48WLWrFlDampqp+dljOG//uu/+OCDDxARfv7znzN79myKioqYPXs21dXVtLS08OSTT3Leeedx6623snr1akSE7373u/zwhz/s0Z/ziQiZlkJilNVSqNSWglJB41e/+hWDBw9m3bp1/Pa3v2Xt2rX88Y9/ZMeOHQA8++yzrFmzhtWrV/PYY49RXl5+3DF27tzJHXfcwebNm0lMTOTNN99s97NSU1NZu3YtCxYs4JFHHgHggQce4JJLLmHz5s3MnDmT/fv3dyvut956i3Xr1rF+/Xo+/vhj7rnnHoqKinjllVe4/PLL214bM2YM69at48CBA2zatImNGzcyb968k/xp9YyQaSmEOR3ER4ZpS0Gpk9TZX/S9ZcKECUctynrsscd4++23ASgoKGDnzp2kpKQc9Z68vDzGjBkDwLhx48jPz2/32DfccEPbPm+99RYAy5cvbzv+9OnTSUpK6lacy5cvZ86cOTidTtLT07nwwgv56quvOPfcc/nud7+L2+3muuuuY8yYMQwaNIg9e/bwgx/8gKuuuopp06Z1/wfiByHTUgBrsLlCB5qVCloxMTFtjz/55BM+/vhjVqxYwfr16xk7dmy7i7YiIiLaHjudzg7HI1r362yfU3XBBRewbNkyBgwYwNy5c3nxxRdJSkpi/fr1XHTRRSxcuJDbbrvNL5/dXSGVFJJiwqnS7iOlgkZcXBw1NTXtvnb48GGSkpKIjo5m27ZtfPnllz3++VOmTOH1118H4KOPPqKysrJb75s6dSqvvfYaHo+H0tJSli1bxoQJE9i3bx/p6encfvvt3Hbbbaxdu5aysjK8Xi/f/OY3eeihh1i7dm2Pn8eJCJnuI4Ck6HCKq7Wwl1LBIiUlhSlTpnDWWWcRFRVFenp622vTp09n4cKFjBgxgmHDhjFp0qQe//z77ruPOXPm8NJLLzF58mQyMjKIi4vr8n3XX389K1asYPTo0YgIv/nNb8jIyOCFF17gt7/9LS6Xi9jYWF588UUOHDjAvHnz8Hq9APzyl7/s8fM4EWKMCWgAJ2r8+PHmZK+89qPX17Nidxlf/PTSHo5Kqb5p69atjBgxItBhBExTUxNOp5OwsDBWrFjBggULWLduXaDD6lJ7/24issYYM76r94ZUSyE5xkWljikopbpp//793HjjjXi9XsLDw3n66acDHZLfhVRSSIwOp8HtoaHZQ1S4M9DhKKVOc0OGDOHrr78+alt5eTmXXnp8b8OSJUuOm/kUjEIqKbSWuqisbyYqPCrA0SilglFKSkpQdCGdrNCafRR9JCkopZQ6XoglBXtVc52OKyilVHtCKim0dh9pUTyllGpfSCWFpLby2ZoUlFKqPSGVFFqL4lVo/SOl+qzWaxocPHiQmTNntrvPRRddRFfrnf7whz9QX1/f9rw712g4EXPnzuWNN97oseP1lJBKCq1F8fRCO0r1ff379z+lL91jk0J3rtHQF4TUlFSwi+JpS0GpE/fBvXBoY88eM2MUXPGrTne59957yc7O5o477gDg/vvvJywsjKVLl1JZWYnb7eahhx7i2muvPep9+fn5zJgxg02bNtHQ0MC8efNYv349w4cPp6HhyGV5FyxYwFdffUVDQwMzZ87kgQce4LHHHuPgwYNcfPHFpKamsnTp0rZrNKSmpvLoo4/y7LPPAnDbbbdx9913k5+f3+G1G7qyZMkSfvzjH9PS0sK5557Lk08+SUREBPfeey/vvvsuYWFhTJs2jUceeYRFixbxwAMP4HQ6SUhIYNmyZSf6U+9UyCWFxOhwnZKqVBCZPXs2d999d1tSeP311/nwww+58847iY+Pp6ysjEmTJnHNNdcgIu0e48knnyQ6OpqtW7eyYcMGzjnnnLbXHn74YZKTk/F4PFx66aVs2LCBO++8k0cffZSlS5ced0GdNWvW8Nxzz7Fy5UqMMUycOJELL7yQpKQkdu7cyauvvsrTTz/NjTfeyJtvvslNN93U6fk1NjYyd+5clixZwtChQ/nOd77Dk08+yc0338zbb7/Ntm3bEJG2rqsHH3yQDz/8kAEDBvRod1arkEsKyTHhlNRoUTylTlgXf9H7y9ixYykpKeHgwYOUlpaSlJRERkYGP/zhD1m2bBkOh4MDBw5QXFxMRkZGu8dYtmwZd955JwBnn302Z599dttrr7/+Ok899RQtLS0UFRWxZcuWo14/1vLly7n++uvbynjfcMMNfPbZZ1xzzTXdvnaDr+3bt5OXl8fQoUMBuOWWW3jiiSf4/ve/T2RkJLfeeiszZsxgxowZgFW5de7cudx4441t14DoSSE1pgDWAjZdp6BUcJk1axZvvPEGr732GrNnz+avf/0rpaWlrFmzhnXr1pGent7utRS6snfvXh555BGWLFnChg0buOqqq07qOK26e+2G7ggLC2PVqlXMnDmT9957j+nTpwOwcOFCHnroIQoKChg3bly7V5s7FSGYFFw6pqBUkJk9ezZ/+9vfeOONN5g1axaHDx+mX79+uFwuli5dyr59+zp9/wUXXMArr7wCwKZNm9iwYQMA1dXVxMTEkJCQQHFxMR988EHbezq6lsPUqVN55513qK+vp66ujrfffpupU6ee9LkNGzaM/Px8du3aBcBLL73EhRdeSG1tLYcPH+bKK6/k97//PevXrwdg9+7dTJw4kQcffJC0tDQKCgpO+rPbE3LdR0kxVlG8RreHSJcWxVMqGIwcOZKamhoGDBhAZmYm3/72t7n66qsZNWoU48ePZ/jw4Z2+f8GCBcybN48RI0YwYsQIxo0bB8Do0aMZO3Ysw4cPJzs7mylTprS9Z/78+UyfPp3+/fuzdOnStu3nnHMOc+fOZcKECYA10Dx27NhudRW1JzIykueee45Zs2a1DTR/73vfo6KigmuvvZbGxkaMMTz66KMA3HPPPezcuRNjDJdeeimjR48+qc/tSEhdTwHg1VX7+elbG1nx00vITNCieEp1JtSvpxCsTuV6CiHZfQS6gE0ppdoTet1H0a2lLnSwWSnlf3fccQeff/75Udvuuusu5s2bF6CIOhdySaGtKJ62FJTqFmNMh/P/VdeeeOKJXv28Ux0SCLnuo0S9poJS3RYZGUl5efkpf9Go3mGMoby8nMjIyJM+Rsi1FBL1mgpKdVtWVhaFhYWUlpYGOhTVTZGRkWRlZZ30+/2WFEQkG3gRSAcM8JQx5o/H7CPAH4ErgXpgrjFmrb9iAnDZRfG0paBU11wuF3l5eYEOQ/Uif7YUWoAfGWPWikgcsEZEFhtjtvjscwUwxL5NBJ607/0qSYviKaVUu/w2pmCMKWr9q98YUwNsBQYcs9u1wIvG8iWQKCKZ/oqpVZIWxVNKqXb1ykCziOQCY4GVx7w0APBdo13I8YkDEZkvIqtFZHVP9G0mx2hSUEqp9vg9KYhILPAmcLcxpvpkjmGMecoYM94YMz4tLe2UY0qMdulAs1JKtcOvSUFEXFgJ4a/GmLfa2eUAkO3zPMve5lfJ2n2klFLt8ltSsGcWPQNsNcY82sFu7wLfEcsk4LAxpshfMbVKigmnvtkqiqeUUuoIf84+mgLcDGwUkXX2tp8BOQDGmIXA+1jTUXdhTUntlXXfST4L2LQonlJKHeG3pGCMWQ50ujbeWMsk7/BXDB1JjjmygE2TglJKHRFyZS7g6JaCUkqpI0IzKWhRPKWUaldoJoW28tmaFJRSyldIJoXEtgvt6FoFpZTyFZJJweV0EKdF8ZRS6jghmRRAS10opVR7QjYpJEVrpVSllDpWCCcFl7YUlFLqGKGbFGLCtSieUkodI2STghbFU0qp44VsUtCieEopdbzQTQptC9i0C0kppVqFbFJoLYqnM5CUUuqIkE0KiVoUTymljhOySSE5RpOCUkodK2STQlv5bO0+UkqpNiGbFLQonlJKHS9kk4IWxVNKqeOFbFIALYqnlFLHCumkkKhF8ZRS6ighnRSSo126eE0ppXyEdFJIitGWglJK+QrtpKBF8ZRS6ighnRSStSieUkodJaSTghbFU0qpo4V4UtCieEop5Su0k0JMa0tBk4JSSkGIJ4XWongVmhSUUgoI8aTQWv9Ii+IppZQlpJNCW6VUHWhWSikgxJNCa1E8HWhWSilLSCcF0AVsSinlS5NCTLh2HymllC3kk0JytEsHmpVSyhbySSFJy2crpVSbkE8K/ROjOFTdqPWPlFIKTQoMz4zD4zXsKqkNdChKKRVwIZ8URmTGA7C1qDrAkSilVOD5LSmIyLMiUiIimzp4/SIROSwi6+zbf/srls7kpsQQ6XKwtagmEB+vlFKnlTA/Hvt54HHgxU72+cwYM8OPMXTJ6RCGpcex7ZC2FJRSym8tBWPMMqDCX8fvSSMy49laVI0xJtChKKVUQAV6TGGyiKwXkQ9EZGRHO4nIfBFZLSKrS0tLezyI4RlxVNa7Kalp6vFjK6VUMAlkUlgLDDTGjAb+BLzT0Y7GmKeMMeONMePT0tJ6PJDWweYtOtislApxAUsKxphqY0yt/fh9wCUiqYGIZXiGzkBSSikIYFIQkQwREfvxBDuW8kDEkhDtYkBiFNt0BpJSKsT5bfaRiLwKXASkikghcB/gAjDGLARmAgtEpAVoAP7N+Hukt6kGXNHgcB730vCMOG0pKKVCnt+SgjFmThevP441ZbV3bHwD3rwVfrAWUgYf9/KIzHg+2VFKo9tDpOv4pKGUUqEg0LOPek/8AOu+Ym+7L2u5C6WUCqWkkJxn3Ve2nxS03IVSSoVSUohNt8YTOmgpaLkLpZQKpaQgAkl5ULGn3Ze13IVSSnUzKYjIYBGJsB9fJCJ3ikiif0Pzg+S8DruPwFqvoOUulFKhrLsthTcBj4icATwFZAOv+C0qf0nKhcp88HrbfXlEppa7UEqFtu4mBa8xpgW4HviTMeYeINN/YflJch60NELtoXZf1nIXSqlQ192k4BaROcAtwHv2Npd/QvKjJHsGUkfTUrXchVIqxHU3KcwDJgMPG2P2ikge8JL/wvKTLqalarkLpVSo69aKZmPMFuBOABFJAuKMMb/2Z2B+kZADjrAOZyCBlrtQSoW27s4++kRE4kUkGavk9dMi8qh/Q/MDZxgkZHfYfQTWuMKesjoa3Z5eDEwppU4P3e0+SjDGVAM3AC8aYyYCl/kvLD/qalqqlrtQSoWw7iaFMBHJBG7kyEBzcErK67KlADrYrJQKTd1NCg8CHwK7jTFficggYKf/wvKj5DxorIKGynZf1nIXSqlQ1t2B5kXAIp/ne4Bv+isov/Kdljog6biXtdyFUiqUdXegOUtE3haREvv2pohk+Ts4v0geZN13OgNJy10opUJTd7uPngPeBfrbt3/Y24JPUq5138lgs5a7UEqFqu4mhTRjzHPGmBb79jyQ5se4/Cc8GmIzoCK/w12Ga7kLpVSI6m5SKBeRm0TEad9uAsr9GZhfdTEtdYSWu1BKhajuJoXvYk1HPQQUATOBuX6Kyf+6mJbaWu5i7b6qXgxKKaUCr1tJwRizzxhzjTEmzRjTzxhzHcE6+wisweaag+Bu6HCXGWdnsnR7CcXVjb0YmFJKBdapXHntP3ssit7WVhgvv8Nd5kzIweM1vPZVQe/EpJRSp4FTSQrSY1H0ti5KaAPkpsYwdUgqr67aT4un/YvyKKVUX3MqSSF4J/F3UUK71bcnDqTocCOfbC/thaCUUirwOk0KIlIjItXt3Gqw1isEp6gkiEjotKUAcOmIfqTHR/Dyyn29FJhSSgVWp0nBGBNnjIlv5xZnjOlWiYzTkggk53bZUnA5Hcw+N4dPd5RSUFHfO7EppVQAnUr3UXBLHtRlSwFgzoRsBHh11X7/x6SUUgEWukkhKQ+q9oGnpdPdMhOiuHREOq+vLqC5RQeclVJ9W+gmheQ88LZAdWGXu357Yg5ltc18uPlQLwSmlFKBE7pJoRvTUltdMCSNrKQo/qoDzkqpPi50k0I3p6UCOBzCtybm8OWeCr1Mp1KqTwvdpBDXH5wR3WopANw4PhuXU3hlpQ44K6X6rtBNCg6HdW2FbrQUAFJjI5h+ViZvrCmgodnj39iUUipAQjcpgNWF1M2WAlgDztWNLfxzY5Efg1JKqcAJ7aTQWkK7m5fdnJiXTF5qDK+v1iJ5Sqm+KbSTQnIeuOugrnu1jUSEmeOyWLW3gvyyOj8Hp5RSvS+0k8IJTEtt9c1zsnAIvLGm6/UNSikVbEI7KZzAtNRWGQmRXDg0jTfWFOLxBm+hWKWUao/fkoKIPCsiJSKyqYPXRUQeE5FdIrJBRM7xVywdSswBcZxQSwFg1vhsDlU38tlOLamtlOpb/NlSeB6Y3snrVwBD7Nt84Ek/xtK+sAiIz4KKPSf0tktH9CMp2sUi7UJSSvUxfksKxphlQEUnu1wLvGgsXwKJIpLpr3g61I0S2seKCHNy3dgBLN5cTFV9s3/iUkqpAAjkmMIAwHduZ6G97TgiMl9EVovI6tLSHu6ySTkDSneA98QWpM0al02zx8vf1x3s2XiUUiqAgmKg2RjzlDFmvDFmfFpaWs8ePHcqNB2GwtUn9LYz+8dz1oB4XbOglOpTApkUDgDZPs+z7G29a/AlIE7Y+eEJv3XWuGw2H6xm88HDfghMKaV6XyCTwrvAd+xZSJOAw8aY3q8fEZUIOZNg50cn/NZrx/Qn3Olg0WodcFZK9Q3+nJL6KrACGCYihSJyq4h8T0S+Z+/yPrAH2AU8DfyHv2Lp0pBpcGgjVJ/Y+EBidDjTRqbzzroDNLVokTylVPDz5+yjOcaYTGOMyxiTZYx5xhiz0Biz0H7dGGPuMMYMNsaMMsacWKd+Txoyzbo/idbCrPHZVNW7+XhLSQ8HpZRSvS8oBpr9rt8ISMiGnYtP+K3nn5FKZkIki9bogLNSKvhpUgAQsVoLu5dCS9MJvdXpsIrkLdtRyur8zpZlKKXU6U+TQqsh06yKqfs+P+G3zpuSR25KDPOe/4pNB3QmklIqeGlSaJV3gXV5zpPoQkqOCeel2yYSH+niO8+u0us4K6WCliaFVuHRkDcVdpz4egWAAYlRvHzbRBwi3PSXlRRU1PdwgEop5X+aFHwNuRwqdkP57pN6e15qDC/dOoEGt4ebnllJSXVjDweolFL+pUnB15BvWPcnMTW11YjMeJ6fdy6lNU3c9MxKKuu0YJ5SKnhoUvCVnAepQ0+6C6nV2Jwk/nLLePLL67n52ZWU157YjCallAoUTQrHGjLNmoHUdGqDxecNTuXPN49jV0ktsxau0DEGpVRQ0KRwrCHTwNMMez895UNdPKwfL986kbLaJmYu/ILth2p6IECllPIfTQrHypkM4XGnNK7ga3xuMou+dx4AsxZ+oQvclFKnNU0KxwoLh8EXWesVjOmRQw7LiOPNBeeRGhvBTc+s5H+3FffIcZVSqqdpUmjPkMuh+gAUb+qxQ2YlRbPoe5MZmh7H7S+u4a21Wm5bKXX60aTQntapqac4C+lYKbERvHL7JCYNSuZHi9bzysr9PXp8pZQ6VZoU2hOXAdmT4Ku/nPIspGPFRoTxzC3ncvGwfvzs7Y08s3xvjx5fKaVOhSaFjkz7BdQUwbLf9vihI11OFt40jivOyuAX723hiaW7evwzlFLqZGhS6Ej2BBj9LVjxBJT1/Jd2eJiDP80Zy3Vj+vPbD7fzyIfbMT00sK2UUidLk0JnLrsfwiLhXz/psZlIvsKcDn534xj+7dxsHl+6i4f+uVUTg1IqoDQpdCYuHS7+Kez6GLZ/4JePcDqE/3f9KOael8szy/cy+89fsrFQr8mglAoMTQpdmTAf0obDv+4Ft3+qnjocwn1Xn8kvbxjF7tJarnliOT9etJ5irbKqlOplmhS64nTBFb+Gqn3wxWN++xgRYc6EHJbecxHzLxjEu+sOcvEjn/CnJTtpdHv89rlKKeVLk0J3DLoIzrwWPnsUqvy7tiA+0sVPrxjB4v+8gAuGpPG7xTu49Hef6mU+lVK9QpNCd0172Lr/6Oe98nEDU2JYePM4/jZ/EsYYbvzzCpZs1fIYSin/0qTQXYnZMPVHsOXvsKNniuV1x6RBKbxzxxQGp8Vy+4uref5zXeymlPIfTQon4rwfQL+R8PZ8qMzvtY/tFx/Ja/8+iUtHpHP/P7Zw/7ub8Xh16qpSqudpUjgRrkiY/RIYL7x2EzT33oVzosPDWHjTOG47P4/nv8hn/ourqWtq6bXPV0qFBk0KJyplMNzwFzi0Cd672y+L2jridAg/n3Emv7h2JEu3l3DN48v5dEdpr32+Uqrv06RwMoZOg4t/Bhteg5V/7vWPv3lyLi98dwItXsMtz67ilmdXsaNYr+qmlDp1mhRO1tQfw7Ar4cOfQf7nvf/xQ9JY/MML+flVI1i7v5Lpf1jG/3l7I2W1Tb0ei1Kq75Bgq7Uzfvx4s3r16kCHYWk8DE9fYt3P/xQSBgQkjIq6Zh5bspOXvtxHtMvJ/AsGMXdKLnGRroDEo5Q6/YjIGmPM+K7205bCqYhMgNl/BXcDvH6zlRwCIDkmnPuvGcmHd1/AxEHJ/G7xDqb+ZilPLN1FTaM7IDEppYKTthR6wtZ/wOu3QHIezH4Z+o0IaDgbCqv448c7WbKthMRoF7dPHcQt5+USGxEW0LiUUoHT3ZaCJoWekv85LJoLzbVwzZ9g1MxAR3RUckiIcnFubjJnZsYxPDOe4RlxDEyJwemQQIeplOoFmhQCobrISgwFX8Kk/4BvPGgV1AuwDYVVPP95PhsPHGZPWV3bwrdIl4PhGfFMHpzClMGpjM9NItLlDHC0Sil/0KQQKB4AQ2npAAAVTklEQVQ3fPR/YeWTkDMZZj1vXfP5NNHo9rCrpJatRdVsO1TD+oIq1hVU0eI1hIc5GJeTxJQzUrh4eD9G9k8IdLhKqR6iSSHQNr4B7/4AHGFwzndg4r9DYk6go2pXXVMLq/ZW8PmuMj7fXc7WomoAzhoQz+zx2VwzZgAJUYFv8SilTp4mhdNB6Xb49New+R3r+ZnXwOTvQ1aX/y4BVVbbxPsbi3h1VQFbi6qJCHNw1ahMZp+bzYS8ZER0HEKpYKNJ4XRSVQCrnoI1L0DTYciaAJf8H+s6DacxYwybDlTzt6/28+66g9Q0tZAeH8GFQ9O4eFg/pgxJJV7XQigVFE6LpCAi04E/Ak7gL8aYXx3z+lzgt8ABe9Pjxpi/dHbMoEwKrZpqYN0rsOJx62I9594O33gAwmMCHVmX6ptb+NemQyzZWsKynaXUNLYQ5hDOGZjExcP6ccM5A0iPjwx0mEqpDgQ8KYiIE9gBfAMoBL4C5hhjtvjsMxcYb4z5fnePG9RJoZW7AZb8Ar58ApIHwfV/huwJgY6q21o8Xtbur+KT7SUs3V7K1qJqwhzC5WdlMPe8XMYPTNIuJqVOM6dDUpgM3G+Mudx+/lMAY8wvffaZSygmhVZ7P4N3/gOqC+H8H8KF90JYeKCjOmH7yut4+ct9vPZVAdWNLYzIjOeWyQO5dswAosJ1iqtSp4PTISnMBKYbY26zn98MTPRNAHZS+CVQitWq+KExpqCdY80H5gPk5OSM27dvn19iDojGavjwp/D1y5A+Ci75OQz5BjiC78u0vrmFd74+yAtf5LO9uIbocCejsxIZm5PI2JwkxmQnkhYXEegwlQpJwZIUUoBaY0yTiPw7MNsYc0lnx+1TLQVf2z+A9/4Tag5CfBaMuwXG3gzxmYGO7IQZY1i5t4J/bihiXUEVW4uqabEXzGUlRTFqQAJD0uMYmh7L0PQ4clNiCA/TMlxK+dPpkBS67D46Zn8nUGGM6XTFVJ9NCmAtfNv+Pqx+DvYsBXHC8Cth3FwYdHFQth7AWjC36cBhvt5fxdcFlWw5WM2+ivq26xOFOYS81BgyE6NIiQknKTqclNhwkmPCSYkJ54x+seSmxODQkhxKnbTTISmEYXUJXYo1u+gr4FvGmM0++2QaY4rsx9cDPzHGTOrsuH06Kfgq3w1rnod1f4X6cohNh5E3wKhZMOAcCPKB3Ea3h92ltewsrmVHcQ07S2opqW6kor6Zitpm6po9R+0f5XIyLCOOEZnxjMiMY1h6HLmpMaTFRmiyUKobAp4U7CCuBP6ANSX1WWPMwyLyILDaGPOuiPwSuAZoASqABcaYbZ0dM2SSQquWJqtradMbsOND8DRDUp6VHEbNgrShgY7QLxrdHirqmimpaWLHoRq2Hqpma1E1W4tqONxwpBx4pMtBdlI0A1OiyUmOYVRWPJcMT9cV2Eod47RICv4QcknBV0MVbHsPNi6CvcvAeKH/OTB6Dpz1TYhJCXSEfmeM4VB1IzuKa9lfXsf+inr2lde33Te4PYQ5hMmDU5h+VgbfODOdfnG6fkIpTQp9Xc0hq77Shr/BoY1WjaUh02D0v8HA8yE6Oei7mE6U12vYcOAwH2wq4l+bDrGvvB4RGJeTxMCUGMLDBJfT0XaLCXcyeXAKY3OStIS46vM0KYSSQ5us5LBhEdQesra5oiEhCxKyrfvEHMiZZJXYCMK1ECfKGMP24pq2VdgVdc00e7y4PV7cLV7cXkNzixeA1NhwLhuRzrSR6Zw3OFXLh6s+SZNCKPJ6IP8zKN4Chwvh8H7rvqoA6susfVzRMHAKDL7YmtHUb0TItShaVTe6+WR7KR9tPsQn20upbWohOtzJuIFJxEe6iAp3EuVyEh3uJNLlJDzMgUMEpwMcIjhECHMKZw1IYExWYqcD3o1uD5/vKqO+2cOVozK1ZaJ6nSYFdbSGKtj3Oexeak13Ld9lbY9OtRJD6hBIGQKpQ63HCdngCJ21A00tHlbsLuejLcVsKKyiodlj3dzWrdHt7fT9aXERXDaiH5eNSGfKGVZro6bRzdLtpXy4+RCfbCtpm1E1IS+Z380aTXZydG+cmlKAJgXVlaoC2POJdZW4sp1Wme/GqiOvh0VZM5vSRkC/4dDvTEgbHnLJopXXa3B7vXi94DEGrzF4vYZGt5cv95SzeGsxn9qtjSiXkxGZcWw6UE2zx0tqbATTRqZz+cgMiqsbefAfWzDGcN/VI5k1PkvrRKleoUlBnRhjrPUQZTusW+kOKN0KJdusVdatnBGQnAfJg+37QdZ9VDJExkNEAkTEhcS4xbGaWjys3FPBYru1cW5uMpeflcE5xwxkF1bWc8+iDazYU85lI/rxyxvO7vHyH3VNLewsqWVXSS2D02IYm5PUo8dXwUeTguo5DVVWS6J0q9XtVLEXKvZYt5bG9t8TFgmRiRDbz1p4F5sOcfZ9dIqVOI66xVvXsxYniMNavS0O+9b3/pL2eg3PfZHPr/+1jdiIMK4d0x+3x0uT20tTi5dGtwe3x0tOcjRnZyVydlYCg9JijxuLqGl0s6ukti0B7CiuYWdxLQeqGo7a7/KR6fxk+nAGpcX25mmq04gmBeV/Xi/UFEFlvtX11FgNTdX2/WFoqITaUqgthtoSqCsBb8uJfYY4rZZI6jBI87klD7ISSZAnjJ3FNfzkzQ1sP1RDhMtJRJiDSPveIUJ+eR319lhETLiTkQMSGJwWQ2FlAzuLazlUfSQph4c5GJwW21ZTaki/WAalxfDBxkMs/HQ3TS1evjUxh7suHUJK7JGWiddr2FlSy5p9lRRW1jNtZAajsxK0W6uP0aSgTj9er9VF1VBpXXCoqdq+t2+eZmtBnvFY+xovtDRYJT/KdlitFN+kIk6ITICoRKtVEplgtUSSBkLiwCP38f2Dtm6Ux2vYU1rL+sLDbCysYsOBw+SX1ZGdHM0Z/WI5o18sQ/pZCSA7ObrDWU2lNU38cckOXl1VQJTLye1TB+EQWLO/krX7KqlutH6uIlZP4pmZ8cyZmMO1Y/rr1fX6CE0Kqu/xuK2uq9JtR1onDVXQePjI49piaxouPr/XDhdkng0Dz7Om4+ZMgqge7mM3BupKrbgq86GuDNJHwoBxEHH6dNnsKqnl1//axuItxYjA0H5xnDMwiXEDkxg/MInk2HDeXXeQV1buZ0tRNVEuJ1ePzuT8IWkcbnBTUdtMRV0TZXXNVNY1E+Z00C8ugrS4CJ/7SHKSo0mPj9DWxmlEk4IKXS3NcLgAqvZZX9AVe6FwNRxYbbVGEOsLO2eSNQU3Kc/qokrMgbAOBny9HutLv6rAOvbhgiNrQFo/x11//PvEAelnWZ+VPdEqZpg4MOAtl33ldSRGh3dYI8oYw4bCw7y6aj/vrj/Y1oUFEB8ZRkpsBMkx4bg9XkprmiitaWorj94qOtxJbkoMeanWLSMhkvrmFqobWjjc4OZwg5vqRjdeA6kxVmXc1NgIUmMjSIkNx+kQ6ps9NLo91NtThJs9Xkb2j+fc3GRdZHiCNCkodSx3IxxYA/u+sNZsFH4FzbU+O4i1+jsmzbpkanMduOus+/YG1CMSrP2TBkJS7tG3qCQ4tAH2r4SClVZSctdZ73OGW2MiKWccucWkWt1hDod977RKlzjDrUTljLBmdIVFWreI+F6bGlzb1EJBRT3Jdlnz9q594fUaqhrclNQ0UlzdxP7yOvaU1ZFfVsfesjoKKhvw2EnD6RDiI5wMjaxiVFgBTjwsax7GnroImlo6Xw/SKjzMwbm5SZx/RhpTh6RyZma8VsvtgiYFpbpijDUAXrnXak203teXQ3jMkZsrGsJjrXpSiTl2+ZAsawyjuzwtULIFitZZYyNlu+yZXHvA6+76/ccRezwlyRpTiUqyYjXGuuFzHx5rXawprj/EZVhjLLH9rJiafCcH2Pftdcu5Iq2aWoMutLrEnO20MFqarK69km3gabJitGePtXihvq6GyMrtuMq2IMVbrMkIPudjMs+mOecCKtPP40D8GExYJJH2ivLW1eUiwtp9lXy2s4zPd5WxvbgGgLiIMNITIkn1aW2k2d1Z6fGRpMdHkB4XSWK066S6tIwxlNY2sa+8nvyyOvaV11Pb1EJcZBhxkWHERris+8gwRg1IIDW2e1OMjTG91sWmSUGpYOBpsbqfGqvswXWP1VVlvNagusdtfcG2tN4arVZMoz27q7HKum+ohOZ6ezZW65cx1uOmaqgusr+ou8NOOL6D+A2VVuFFDLhirPGZQRda+x7aCMWbrITQ1eyy8Dir6y59JGScZXWtAez51F5MudJKks4Ia6V9ymBrTUzrfXIeuKLaWlMltW6W765gXUEVpTVNlNU2UVbbTGlNE7VNx8cSHmaNgUS6nHi91iJEjzHWj94YHA6raGKYQ3Daj90eL/sr6o/qQnM6hGiXk9rmFny/QvtRiREHwwYN4uox/Zk+MpOE6CMJ1OM1rCuo4uOtxSzZWkx+eT0T85K5cGgaFw5N44x+sX5LEpoUlFJHGGN9sdccshYj1pZYXVOta0Qi44887qhrqr4C8pfD3k+t0u1lO6ztcZmQMcr6gs8YZX3hu6Jpa60Yr/XYGW61Vjrr9mqug30rrFIsJVuhYjdU7beP0QlHmJWswmMgPBrCY/CGRdNswnC7m3C73bS0uPG2NOP1tNBMOI3OaJocMTQ6Y2hyxtDsiCbM20iEp45wTx0RnnoivXWAUJp4NvUDziN80BSyMzIYkBSFy+nA6/HSWLQZz+Z/4Nr5TyLLNgFQQwy7vJnsJROTPITUgSPYW9HMpgNV1Da6CRPDkH7R9EuI5dPSaJaXx1FLNP0TIrlgaBoXDE1jyhmpJEiDlXQPbYCiDXDGpTBq5sn8BmhSUEr5WU2xNfYRk+rfz2lpticM7LbuW5p8pi3bLSuv2x4HqrVaTM111sC/p9mafeYMsxKHw2XF3NJ09JToxmrrva5oa7aY78JKdyMcXGsdS5zQfwzkTrUS1bb3rC5ABLInwPCrwBmOKdtJ3cGtmNKdxLlLu3WajeFJFEkGW5pSwNPMSMc+cqW47XUT0w+Zciec94OT+jF2NymEndTRlVIqLr13Pics3K7DFcCrDDbXQ+Eq2PuZ1Vpa8bi1Pe8CmPx9KxnEZbTtLkDrRGRvQzUH920nPdaFK8x3pb7DSmSV+VC5l8iKveRV7iW3Yi/NHtgffiYvN05jyeEMNnlyaZZ+/MBzBrf5+VQ1KSilVFfCo2HQRdYNrJaI8VotiS44ouLJGn5uxzv0H3PUUwEigCH27aq6ZpbvKmPZjlLS4/1/FUFNCkopdaLCY3rto5Jiwrl6dH+uHt2/Vz4v9GogK6WU6pAmBaWUUm00KSillGqjSUEppVQbTQpKKaXaaFJQSinVRpOCUkqpNpoUlFJKtQm62kciUgrsO8m3pwJlPRjO6SoUzjMUzhFC4zxD4Rwh8Oc50BiT1tVOQZcUToWIrO5OQahgFwrnGQrnCKFxnqFwjhA856ndR0oppdpoUlBKKdUm1JLCU4EOoJeEwnmGwjlCaJxnKJwjBMl5htSYglJKqc6FWktBKaVUJzQpKKWUahMySUFEpovIdhHZJSL3BjqeniIiz4pIiYhs8tmWLCKLRWSnfZ8UyBhPlYhki8hSEdkiIptF5C57e585TxGJFJFVIrLePscH7O15IrLS/r19TUTCAx3rqRIRp4h8LSLv2c/74jnmi8hGEVknIqvtbUHx+xoSSUFEnMATwBXAmcAcETkzsFH1mOeB6cdsuxdYYowZAiyxnwezFuBHxpgzgUnAHfa/X186zybgEmPMaGAMMF1EJgG/Bn5vjDkDqARuDWCMPeUuYKvP8754jgAXG2PG+KxNCIrf15BICsAEYJcxZo8xphn4G3BtgGPqEcaYZUDFMZuvBV6wH78AXNerQfUwY0yRMWat/bgG6wtlAH3oPI2l1n7qsm8GuAR4w94e1OcIICJZwFXAX+znQh87x04Exe9rqCSFAUCBz/NCe1tflW6MKbIfHwLSAxlMTxKRXGAssJI+dp52t8o6oARYDOwGqowxLfYufeH39g/AfwFe+3kKfe8cwUroH4nIGhGZb28Lit/XsEAHoPzLGGNEpE/MOxaRWOBN4G5jTLX1R6alL5ynMcYDjBGRROBtYHiAQ+pRIjIDKDHGrBGRiwIdj5+db4w5ICL9gMUiss33xdP59zVUWgoHgGyf51n2tr6qWEQyAez7kgDHc8pExIWVEP5qjHnL3tznzhPAGFMFLAUmA4ki0vrHW7D/3k4BrhGRfKwu3EuAP9K3zhEAY8wB+74EK8FPIEh+X0MlKXwFDLFnOYQD/wa8G+CY/Old4Bb78S3A3wMYyymz+52fAbYaYx71eanPnKeIpNktBEQkCvgG1tjJUmCmvVtQn6Mx5qfGmCxjTC7W/8H/NcZ8mz50jgAiEiMica2PgWnAJoLk9zVkVjSLyJVY/ZlO4FljzMMBDqlHiMirwEVYZXmLgfuAd4DXgRysMuM3GmOOHYwOGiJyPvAZsJEjfdE/wxpX6BPnKSJnYw0+OrH+WHvdGPOgiAzC+qs6GfgauMkY0xS4SHuG3X30Y2PMjL52jvb5vG0/DQNeMcY8LCIpBMHva8gkBaWUUl0Lle4jpZRS3aBJQSmlVBtNCkoppdpoUlBKKdVGk4JSSqk2mhSUsomIx65q2XrrsYJlIpLrW8lWqdOVlrlQ6ogGY8yYQAehVCBpS0GpLti18X9j18dfJSJn2NtzReR/RWSDiCwRkRx7e7qIvG1fG2G9iJxnH8opIk/b10v4yF65jIjcaV8rYoOI/C1Ap6kUoElBKV9Rx3QfzfZ57bAxZhTwONbKeIA/AS8YY84G/go8Zm9/DPjUvjbCOcBme/sQ4AljzEigCvimvf1eYKx9nO/56+SU6g5d0ayUTURqjTGx7WzPx7oAzh67MN8hY0yKiJQBmcYYt729yBiTKiKlQJZvqQa75Pdi+wIriMhPAJcx5iER+RdQi1We5B2f6yoo1eu0paBU95gOHp8I33o+Ho6M6V2FdWXAc4CvfCqGKtXrNCko1T2zfe5X2I+/wKr2CfBtrKJ9YF1qcQG0XTgnoaODiogDyDbGLAV+AiQAx7VWlOot+heJUkdE2Vc+a/UvY0zrtNQkEdmA9df+HHvbD4DnROQeoBSYZ2+/C3hKRG7FahEsAIponxN42U4cAjxmX09BqYDQMQWlumCPKYw3xpQFOhal/E27j5RSSrXRloJSSqk22lJQSinVRpOCUkqpNpoUlFJKtdGkoJRSqo0mBaWUUm3+P5zCkfokl1PUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_acc = model_history.history['acc']\n",
    "val_acc = model_history.history['val_acc']\n",
    "\n",
    "plt.plot(training_acc, label=\"training_acc\")\n",
    "plt.plot(val_acc, label=\"validation_acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747/747 [==============================] - 2s 3ms/step\n",
      "Validation loss: 0.2661104056251097\n",
      "Validation accuracy: 0.9129852744310576\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_path)\n",
    "\n",
    "scores = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('Validation loss:', scores[0])\n",
    "print('Validation accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_id = load_test_data(Gray2RGB=True, mean_proc='VGG16_ImageNet')\n",
    "\n",
    "y_test_pred_prob = model.predict(X_test)\n",
    "y_test_pred = y_test_pred_prob.argmax(axis=-1)\n",
    "y_test_pred_df = pd.DataFrame({'id': np.array(X_id), 'class':y_test_pred}).sort_values(by='id')\n",
    "y_test_pred_df.to_csv('./submissions/{}.csv'.format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
