{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import load_data, load_test_data\n",
    "from utils import num_classes, epochs, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = load_data(test_size=0.2, img_size=224,Gray2RGB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1290, 224, 224, 3)\n",
      "(1290, 15)\n",
      "(323, 224, 224, 3)\n",
      "(323, 15)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 224, 224, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 112, 112, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 56, 56, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 15)                7695      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 15)                0         \n",
      "=================================================================\n",
      "Total params: 109,359\n",
      "Trainable params: 107,951\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# a classic CNN model\n",
    "model_name = 'classic_CNN_GlobalAveragePooling2D'\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=X_train.shape[1:]))\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3),activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),  padding='same', activation='relu'))\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),  padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation(activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 2.1656 - acc: 0.2224\n",
      "Epoch 00001: val_acc improved from -inf to 0.22291, saving model to ./saved_models/CNN_051401.h5\n",
      "40/40 [==============================] - 24s 606ms/step - loss: 2.1498 - acc: 0.2268 - val_loss: 2.0586 - val_acc: 0.2229\n",
      "Epoch 2/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.8675 - acc: 0.2414\n",
      "Epoch 00002: val_acc did not improve from 0.22291\n",
      "40/40 [==============================] - 19s 487ms/step - loss: 1.8644 - acc: 0.2432 - val_loss: 1.6802 - val_acc: 0.1981\n",
      "Epoch 3/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.7346 - acc: 0.2586\n",
      "Epoch 00003: val_acc did not improve from 0.22291\n",
      "40/40 [==============================] - 19s 487ms/step - loss: 1.7408 - acc: 0.2583 - val_loss: 1.6545 - val_acc: 0.1765\n",
      "Epoch 4/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.7586 - acc: 0.2627\n",
      "Epoch 00004: val_acc did not improve from 0.22291\n",
      "40/40 [==============================] - 21s 520ms/step - loss: 1.7638 - acc: 0.2589 - val_loss: 1.7140 - val_acc: 0.1796\n",
      "Epoch 5/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.6881 - acc: 0.2661\n",
      "Epoch 00005: val_acc did not improve from 0.22291\n",
      "40/40 [==============================] - 21s 519ms/step - loss: 1.6877 - acc: 0.2680 - val_loss: 1.7868 - val_acc: 0.1950\n",
      "Epoch 6/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.6950 - acc: 0.2708\n",
      "Epoch 00006: val_acc did not improve from 0.22291\n",
      "40/40 [==============================] - 20s 504ms/step - loss: 1.6943 - acc: 0.2708 - val_loss: 1.7447 - val_acc: 0.1889\n",
      "Epoch 7/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.6586 - acc: 0.2734\n",
      "Epoch 00007: val_acc did not improve from 0.22291\n",
      "40/40 [==============================] - 19s 485ms/step - loss: 1.6592 - acc: 0.2728 - val_loss: 1.8358 - val_acc: 0.1981\n",
      "Epoch 8/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.6495 - acc: 0.2663\n",
      "Epoch 00008: val_acc did not improve from 0.22291\n",
      "40/40 [==============================] - 20s 508ms/step - loss: 1.6499 - acc: 0.2648 - val_loss: 2.1083 - val_acc: 0.2105\n",
      "Epoch 9/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.6169 - acc: 0.2859\n",
      "Epoch 00009: val_acc improved from 0.22291 to 0.22601, saving model to ./saved_models/CNN_051401.h5\n",
      "40/40 [==============================] - 20s 498ms/step - loss: 1.6155 - acc: 0.2839 - val_loss: 1.7527 - val_acc: 0.2260\n",
      "Epoch 10/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.6169 - acc: 0.2877\n",
      "Epoch 00010: val_acc improved from 0.22601 to 0.27245, saving model to ./saved_models/CNN_051401.h5\n",
      "40/40 [==============================] - 21s 525ms/step - loss: 1.6200 - acc: 0.2876 - val_loss: 1.5732 - val_acc: 0.2724\n",
      "Epoch 11/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.5983 - acc: 0.2740\n",
      "Epoch 00011: val_acc did not improve from 0.27245\n",
      "40/40 [==============================] - 21s 520ms/step - loss: 1.5951 - acc: 0.2735 - val_loss: 1.9800 - val_acc: 0.2477\n",
      "Epoch 12/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.5662 - acc: 0.2740\n",
      "Epoch 00012: val_acc did not improve from 0.27245\n",
      "40/40 [==============================] - 20s 504ms/step - loss: 1.5642 - acc: 0.2722 - val_loss: 1.8579 - val_acc: 0.2693\n",
      "Epoch 13/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.5740 - acc: 0.2695\n",
      "Epoch 00013: val_acc improved from 0.27245 to 0.29102, saving model to ./saved_models/CNN_051401.h5\n",
      "40/40 [==============================] - 20s 507ms/step - loss: 1.5756 - acc: 0.2710 - val_loss: 1.7178 - val_acc: 0.2910\n",
      "Epoch 14/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.5461 - acc: 0.2841\n",
      "Epoch 00014: val_acc improved from 0.29102 to 0.29412, saving model to ./saved_models/CNN_051401.h5\n",
      "40/40 [==============================] - 20s 500ms/step - loss: 1.5467 - acc: 0.2855 - val_loss: 1.8423 - val_acc: 0.2941\n",
      "Epoch 15/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.5604 - acc: 0.2921\n",
      "Epoch 00015: val_acc improved from 0.29412 to 0.32198, saving model to ./saved_models/CNN_051401.h5\n",
      "40/40 [==============================] - 19s 487ms/step - loss: 1.5556 - acc: 0.2963 - val_loss: 1.5368 - val_acc: 0.3220\n",
      "Epoch 16/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.5288 - acc: 0.3018\n",
      "Epoch 00016: val_acc did not improve from 0.32198\n",
      "40/40 [==============================] - 20s 511ms/step - loss: 1.5310 - acc: 0.3000 - val_loss: 1.7129 - val_acc: 0.2786\n",
      "Epoch 17/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.5273 - acc: 0.2863\n",
      "Epoch 00017: val_acc did not improve from 0.32198\n",
      "40/40 [==============================] - 20s 505ms/step - loss: 1.5254 - acc: 0.2870 - val_loss: 1.7722 - val_acc: 0.2291\n",
      "Epoch 18/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.5106 - acc: 0.2969\n",
      "Epoch 00018: val_acc did not improve from 0.32198\n",
      "40/40 [==============================] - 21s 513ms/step - loss: 1.5105 - acc: 0.2961 - val_loss: 1.5081 - val_acc: 0.2632\n",
      "Epoch 19/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.5197 - acc: 0.3077\n",
      "Epoch 00019: val_acc did not improve from 0.32198\n",
      "40/40 [==============================] - 20s 501ms/step - loss: 1.5150 - acc: 0.3122 - val_loss: 1.5288 - val_acc: 0.2879\n",
      "Epoch 20/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.4941 - acc: 0.3032\n",
      "Epoch 00020: val_acc did not improve from 0.32198\n",
      "40/40 [==============================] - 21s 522ms/step - loss: 1.4940 - acc: 0.3039 - val_loss: 1.5279 - val_acc: 0.2570\n",
      "Epoch 21/400\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.5180 - acc: 0.2832\n",
      "Epoch 00021: val_acc did not improve from 0.32198\n",
      "40/40 [==============================] - 20s 511ms/step - loss: 1.5169 - acc: 0.2810 - val_loss: 1.5385 - val_acc: 0.3065\n",
      "Epoch 22/400\n",
      " 2/40 [>.............................] - ETA: 15s - loss: 1.4856 - acc: 0.3594"
     ]
    }
   ],
   "source": [
    "# Data generator with augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='constant',\n",
    "    cval=0)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=10e-4)#\n",
    "\n",
    "model_path = './saved_models/CNN_051401.h5'.format(model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_acc', save_best_only=True, verbose=1)\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=16, verbose=1)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                           factor=0.1,\n",
    "                                           patience=3,\n",
    "                                           min_lr=0.5e-6)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, metrics=['accuracy'])\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "batch_size = 64\n",
    "aug_ratio = 2\n",
    "epochs = 400\n",
    "steps_per_epoch = int(aug_ratio * X_train.shape[0] / batch_size)\n",
    "validation_steps = int(aug_ratio * X_valid.shape[0] / batch_size)\n",
    "model_history = model.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size),\n",
    "                                    epochs = epochs,\n",
    "                                    validation_data = (X_valid, y_valid),\n",
    "                                    callbacks = [checkpoint,earlystop],\n",
    "                                    steps_per_epoch=steps_per_epoch,\n",
    "                                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.plot(training_loss, 'b', label=\"training_loss\")\n",
    "plt.plot(val_loss, 'r', label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc = model_history.history['acc']\n",
    "val_acc = model_history.history['val_acc']\n",
    "\n",
    "plt.plot(training_acc, 'b', label=\"training_acc\")\n",
    "plt.plot(val_acc, 'r', label=\"validation_acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_id = load_test_data(Gray2RGB=True, img_size=360)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './saved_models/CNN_051401.h5'.format(model_name)\n",
    "model = load_model(model_path)\n",
    "\n",
    "#scores = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "#print('Validation loss:', scores[0])\n",
    "#print('Validation accuracy:', scores[1])\n",
    "\n",
    "y_test_pred = model.predict_classes(X_test)\n",
    "y_test_pred_df = pd.DataFrame({'id': np.array(X_id), 'class':y_test_pred}).sort_values(by='id')\n",
    "y_test_pred_df.to_csv('CNN_051101.csv'.format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
